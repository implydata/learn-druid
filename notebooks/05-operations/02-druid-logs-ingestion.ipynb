{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9fc0614-4eec-4c39-ad22-ea10afa00e9d",
   "metadata": {},
   "source": [
    "# Apache Druid and Log4j\n",
    "\n",
    "Apache Druid uses Log4J to emit information as it runs. They not only enable you to investigate issues and solve problems, but to understand how each of Druid's processes work in isolation and in collaboration with one another.\n",
    "\n",
    "In this learning module we will:\n",
    "\n",
    "* Identify the various Druid process log files.\n",
    "* Understand the role of the log files.\n",
    "* Review some task log files.\n",
    "\n",
    "The first step in making use of log files is to become aware of what logs are available. We'll see that the Druid processes each generate a couple of different files. In addition to the process log files, we will see that transient Druid worker tasks also generate log files.\n",
    "\n",
    "As Druid processes run, they write status information into files called log files. We can use these files to understand the Druid processes' behaviors and diagnose problems.\n",
    "\n",
    "Since Druid is a distributed system, we will find log files for each Druid process. In addition, Druid also captures the output written to the standard output.\n",
    "\n",
    "Some processes may spin off tasks to perform sub-processing. In Druid, a task is separate process that usually runs in its own JVM. Each of these tasks create their own log files.\n",
    "\n",
    "Many of the logs capture behavior during ingestion and other processing, but we can also configure Druid to capture specific query information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151ede96-348f-423c-adc7-0e23c6910b9e",
   "metadata": {},
   "source": [
    "# Installation\n",
    "\n",
    "To use this notebook, you will need to run Druid locally.\n",
    "\n",
    "You will also make extensive use of the terminal, which we suggest you place alongside this notebook.\n",
    "\n",
    ">  You must install Druid locally. When running this tutorial in the learn-druid docker image, opening a terminal window will open a terminal on the pod in which Jupyter Labs is running, and you will not be able to install Druid.\n",
    "\n",
    "## Install tools\n",
    "\n",
    "```bash\n",
    "brew install multitail && brew install wget\n",
    "curl https://raw.githubusercontent.com/halturin/multitail/master/multitail.conf > ~/.multitailrc\n",
    "```\n",
    "\n",
    "## Install and start Apache Druid\n",
    "\n",
    "> If you are running JupyterLab on your local machine, open a terminal window by clicking here.\n",
    "> \n",
    "> <button data-commandLinker-command=\"terminal:create-new\" href=\"#\">Open a terminal</button>\n",
    "> \n",
    "> Alternatively, start your local terminal in the usual way.\n",
    "\n",
    "Use the following commands to install Druid.\n",
    "\n",
    "Run the following to create a dedicated folder for learn-druid in your home directory:\n",
    "\n",
    "```bash\n",
    "cd && mkdir learn-druid-logs\n",
    "cd learn-druid-logs\n",
    "```\n",
    "\n",
    "Now pull a compatible version of Druid.\n",
    "\n",
    "> If you do not have wget on your Mac, you can install it with brew.\n",
    "\n",
    "```bash\n",
    "wget https://dlcdn.apache.org/druid/28.0.1/apache-druid-28.0.1-bin.tar.gz && tar -xzf apache-druid-28.0.1-bin.tar.gz &&\n",
    "cd apache-druid-28.0.1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65384957-3c3f-43fb-b296-7e5f7fddbcc5",
   "metadata": {},
   "source": [
    "## Ingestion logging\n",
    "\n",
    "When monitoring and troubleshooting [ingestion](https://druid.apache.org/docs/latest/ingestion/), including [SQL-based ingestion](https://druid.apache.org/docs/latest/multi-stage-query/concepts.html) the key processes are:\n",
    "\n",
    "* Router\n",
    "* Overlord\n",
    "* MiddleManager\n",
    "* Historical\n",
    "\n",
    "Recall that the MiddleManager spawns multiple other tasks (peons) that actually carry out the ingestion work.\n",
    "\n",
    "Typically, you would start with the overlord, then move to the middle manager, where information about individual ingestion tasks can be found. Then you can move on to look at the ingestion tasks themselves.\n",
    "\n",
    "According to the settings in the coordinator rules, ingested data may be pulled by historicals locally. These go on to be balanced over time. The processes involved in this are:\n",
    "\n",
    "* Coordinator\n",
    "* Historical\n",
    "\n",
    "Therefore if you have segment loading and availability issues, you would look at these two processes.\n",
    "\n",
    "### Process logs\n",
    "\n",
    "Use multitail to monitor all these log files. Notice that the command below includes a filter to hides some messages.\n",
    "\n",
    "```bash\n",
    "multitail --config multitail.conf -CS log4jnew -du -P a -s 2 -sn 1,2 \\\n",
    "    -e \"org.apache.druid.indexing\" -f coordinator-overlord.log \\\n",
    "    -f middleManager.log \\\n",
    "    -f historical.log\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02835e5a-9fc3-4240-8642-00294d4415e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HOW CAN THIS WORK INSIIIIDE THE DOCKER ENVIRONMENT?\n",
    "\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# Make sure you replace `your-instance`, and `port` with the values for your deployment.\n",
    "url = \"http://localhost:8888/druid/v2/sql/task/\"\n",
    "\n",
    "payload = json.dumps({\n",
    "  \"query\": \"INSERT INTO \\\"example-wikipedia-logs\\\"\\nSELECT\\n  TIME_PARSE(\\\"timestamp\\\") AS __time,\\n  *\\nFROM TABLE(\\n  EXTERN(\\n    '\\''{\\\"type\\\": \\\"http\\\", \\\"uris\\\": [\\\"https://druid.apache.org/data/wikipedia.json.gz\\\"]}'\\'',\\n    '\\''{\\\"type\\\": \\\"json\\\"}'\\'',\\n    '\\''[{\\\"name\\\": \\\"added\\\", \\\"type\\\": \\\"long\\\"}, {\\\"name\\\": \\\"channel\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"cityName\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"comment\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"commentLength\\\", \\\"type\\\": \\\"long\\\"}, {\\\"name\\\": \\\"countryIsoCode\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"countryName\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"deleted\\\", \\\"type\\\": \\\"long\\\"}, {\\\"name\\\": \\\"delta\\\", \\\"type\\\": \\\"long\\\"}, {\\\"name\\\": \\\"deltaBucket\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"diffUrl\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"flags\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"isAnonymous\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"isMinor\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"isNew\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"isRobot\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"isUnpatrolled\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"metroCode\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"namespace\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"page\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"regionIsoCode\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"regionName\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"timestamp\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"user\\\", \\\"type\\\": \\\"string\\\"}]'\\''\\n  )\\n)\\nPARTITIONED BY DAY\"\n",
    "})\n",
    "headers = {\n",
    "  'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, data=payload)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4099aa1-c9b8-40e4-87b6-cf61636a27d2",
   "metadata": {},
   "source": [
    "Whilst in the multitail window, type `shift+O` to clear the output of all windows. Then press 0, 1, and 2 in turn to add a line marker to all windows.\n",
    "\n",
    "In your second terminal window, run this command to start an ingestion.\n",
    "\n",
    "```bash\n",
    "curl --location --request POST 'http://localhost:8888/druid/v2/sql/task/' \\\n",
    "  --header 'Content-Type: application/json' \\\n",
    "  --data-raw '{\n",
    "    \"query\": \"INSERT INTO \\\"example-wikipedia-logs\\\"\\nSELECT\\n  TIME_PARSE(\\\"timestamp\\\") AS __time,\\n  *\\nFROM TABLE(\\n  EXTERN(\\n    '\\''{\\\"type\\\": \\\"http\\\", \\\"uris\\\": [\\\"https://druid.apache.org/data/wikipedia.json.gz\\\"]}'\\'',\\n    '\\''{\\\"type\\\": \\\"json\\\"}'\\'',\\n    '\\''[{\\\"name\\\": \\\"added\\\", \\\"type\\\": \\\"long\\\"}, {\\\"name\\\": \\\"channel\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"cityName\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"comment\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"commentLength\\\", \\\"type\\\": \\\"long\\\"}, {\\\"name\\\": \\\"countryIsoCode\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"countryName\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"deleted\\\", \\\"type\\\": \\\"long\\\"}, {\\\"name\\\": \\\"delta\\\", \\\"type\\\": \\\"long\\\"}, {\\\"name\\\": \\\"deltaBucket\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"diffUrl\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"flags\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"isAnonymous\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"isMinor\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"isNew\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"isRobot\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"isUnpatrolled\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"metroCode\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"namespace\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"page\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"regionIsoCode\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"regionName\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"timestamp\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"user\\\", \\\"type\\\": \\\"string\\\"}]'\\''\\n  )\\n)\\nPARTITIONED BY DAY\"\n",
    "  }'\n",
    "```\n",
    "\n",
    "Take note of the activity that is logged across the processes as they cooperate with one another to:\n",
    "\n",
    "* Plan and distribute the work to Middle Managers.\n",
    "* Spawn tasks to handle the ingest, optimization, and push to deep storage.\n",
    "* Load the data out of deep storage and into historicals.\n",
    "\n",
    "Feel free to repeat the steps above several times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b680cce2-652c-447c-b96e-6be0bc61ab54",
   "metadata": {},
   "source": [
    "### Task logs\n",
    "\n",
    "In the terminal monitoring the Middle Manager, you will see a number of log entries created, concluding in something similar to:\n",
    "\n",
    "```\n",
    "2024-02-07T12:55:56,434 INFO [WorkerTaskManager-NoticeHandler] org.apache.druid.indexing.worker.WorkerTaskManager - Task [query-58b4b3c6-617e-4201-b0a4-ef63af0ca39c] completed with status [SUCCESS].\n",
    "```\n",
    "\n",
    "Each task creates a separate log in a location you configure as an administrator.\n",
    "\n",
    "Use the Tasks API to list the available task logs.\n",
    "\n",
    "```bash\n",
    "curl http://localhost:8081/druid/indexer/v1/tasks | jq\n",
    "```\n",
    "\n",
    "The actual location of the log file is recorded in the middlemanager log for that task.\n",
    "\n",
    "Run this command to see the location:\n",
    "\n",
    "```bash\n",
    "more something blah location\n",
    "```\n",
    "\n",
    "Druid may migrate local log files to long-term storage, following the configuration at XXXXXX. This is an essential configuration task when you run more than one middlemanager.\n",
    "\n",
    "To get the log for a task, use the task log API, providing the ID and the log endpoint.\n",
    "\n",
    "In the following command, switch the ID for one of the IDs output above, and then run it to pull the log file of one of the tasks.\n",
    "\n",
    "```bash\n",
    "curl http://localhost:8888/druid/indexer/v1/task/<ID>/log\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29afa2e-1018-4ae8-9827-031430343f93",
   "metadata": {},
   "source": [
    "## Example 1: errors in ingestion\n",
    "\n",
    "In this part of the tutorial you will use the `less` and `grep` commands. For more information see their documentaiton.\n",
    "\n",
    "Run the following ingestion task.\n",
    "\n",
    "```bash\n",
    "curl --location --request POST 'http://localhost:8888/druid/v2/sql/task/' \\\n",
    "  --header 'Content-Type: application/json' \\\n",
    "  --data-raw '{\n",
    "    \"query\": \"INSERT INTO \\\"example-wikipedia-logs\\\"\\nSELECT\\n  TIME_PARSE(\\\"timestamp\\\") AS __time,\\n  *\\nFROM TABLE(\\n  EXTERN(\\n    '\\''{\\\"type\\\": \\\"http\\\", \\\"uris\\\": [\\\"https://druid.apache.org/data/wikipedia.json.gz\\\"]}'\\'',\\n    '\\''{\\\"type\\\": \\\"json\\\"}'\\'',\\n    '\\''[{\\\"name\\\": \\\"added\\\", \\\"type\\\": \\\"long\\\"}, {\\\"name\\\": \\\"channel\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"cityName\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"comment\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"commentLength\\\", \\\"type\\\": \\\"long\\\"}, {\\\"name\\\": \\\"countryIsoCode\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"countryName\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"deleted\\\", \\\"type\\\": \\\"long\\\"}, {\\\"name\\\": \\\"delta\\\", \\\"type\\\": \\\"long\\\"}, {\\\"name\\\": \\\"deltaBucket\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"diffUrl\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"flags\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"isAnonymous\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"isMinor\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"isNew\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"isRobot\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"isUnpatrolled\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"metroCode\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"namespace\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"page\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"regionIsoCode\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"regionName\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"timestamp\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"user\\\", \\\"type\\\": \\\"string\\\"}]'\\''\\n  )\\n)\\nPARTITIONED BY DAY\"\n",
    "  }'\n",
    "```\n",
    "\n",
    "This ingestion failed.\n",
    "\n",
    "Use this command to look at the middlemanager log:\n",
    "\n",
    "```bash\n",
    "less middleManager.log\n",
    "```\n",
    "\n",
    "Use the search feature of less to look for the failure:\n",
    "\n",
    "```\n",
    "/FAIL\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1023e5a3-cedc-435f-a448-30f8c3ae1535",
   "metadata": {},
   "source": [
    "# Stop Druid\n",
    "\n",
    "Run this command to stop Druid, replacing \"{pid}\" with the process Id you noted earlier.\n",
    "\n",
    "```bash\n",
    "kill {pid}\n",
    "```\n",
    "\n",
    "For example:\n",
    "\n",
    "```bash\n",
    "kill 9864\n",
    "```\n",
    "\n",
    "> If you do not remember your PID, use `ps` to look for the `supervise` process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d5921b-636e-4a85-ae4d-dc0239bfef0b",
   "metadata": {},
   "source": [
    "## Learn more\n",
    "\n",
    "In the lab you learned that you can turn on logging for query requests with the druid.startup.logging.logProperties setting. Read all the options - including other possible targets for these logs - in the documentation. An interesting configuration, for example, automatically filters query logging for you.\n",
    "\n",
    "* [Request logging](https://druid.apache.org/docs/latest/configuration/index.html#request-logging)\n",
    "* [Filtered request logging](https://druid.apache.org/docs/latest/configuration/index.html#filtered-request-logging)\n",
    "\n",
    "This information can be really powerful: watch this Druid Summit presentation by Amir Youssefi and Pawas Ranjan from Conviva that describes how useful this information can be to tuning Druid clusters.\n",
    "\n",
    "* [Druid optimizations for scaling customer facing analytics at Conviva](https://youtu.be/zkHXr-3GFJw?t=746)\n",
    "\n",
    "Take a few minutes to scan the official documentation for information about logging configuration. You may want to keep this page to hand throughout the course.\n",
    "\n",
    "* [Logging](https://druid.apache.org/docs/latest/configuration/logging.html)\n",
    "\n",
    "You're about to learn more about Apache Druid's use of Apache Logging Services in the form of Log4J™. Get insight into the background and benefits of Log4J on the official project website:\n",
    "\n",
    "* [Apache Logging Services](https://logging.apache.org/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

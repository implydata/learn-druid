{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9fc0614-4eec-4c39-ad22-ea10afa00e9d",
   "metadata": {},
   "source": [
    "# Apache Druid and Log4j\n",
    "\n",
    "Apache Druid uses Log4J to emit information as it runs. They not only enable you to investigate issues and solve problems, but to understand how each of Druid's processes work in isolation and in collaboration with one another.\n",
    "\n",
    "In this learning module we will:\n",
    "\n",
    "* Identify the various Druid process log files.\n",
    "* Understand the role of the log files.\n",
    "* Review some task log files.\n",
    "\n",
    "The first step in making use of log files is to become aware of what logs are available. We'll see that the Druid processes each generate a couple of different files. In addition to the process log files, we will see that transient Druid worker tasks also generate log files.\n",
    "\n",
    "As Druid processes run, they write status information into files called log files. We can use these files to understand the Druid processes' behaviors and diagnose problems.\n",
    "\n",
    "Since Druid is a distributed system, we will find log files for each Druid process. In addition, Druid also captures the output written to the standard output.\n",
    "\n",
    "Some processes may spin off tasks to perform sub-processing. In Druid, a task is separate process that usually runs in its own JVM. Each of these tasks create their own log files.\n",
    "\n",
    "Many of the logs capture behavior during ingestion and other processing, but we can also configure Druid to capture specific query information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151ede96-348f-423c-adc7-0e23c6910b9e",
   "metadata": {},
   "source": [
    "# Installation\n",
    "\n",
    "To use this notebook, you will need to run Druid locally.\n",
    "\n",
    "You will also make extensive use of the terminal, which we suggest you place alongside this notebook.\n",
    "\n",
    ">  You must install Druid locally. When running this tutorial in the learn-druid docker image, opening a terminal window will open a terminal on the pod in which Jupyter Labs is running, and you will not be able to install Druid.\n",
    "\n",
    "## Install multitail\n",
    "\n",
    "```bash\n",
    "brew install multitail\n",
    "```\n",
    "\n",
    "## Install and start Apache Druid\n",
    "\n",
    "> If you are running JupyterLab on your local machine, open a terminal window by clicking here.\n",
    "> \n",
    "> <button data-commandLinker-command=\"terminal:create-new\" href=\"#\">Open a terminal</button>\n",
    "> \n",
    "> Alternatively, start your local terminal in the usual way.\n",
    "\n",
    "Use the following commands to install Druid.\n",
    "\n",
    "Run the following to create a dedicated folder for learn-druid in your home directory:\n",
    "\n",
    "```bash\n",
    "cd && mkdir learn-druid-logs && cd learn-druid-logs\n",
    "```\n",
    "\n",
    "Now pull a compatible version of Druid:\n",
    "\n",
    "```bash\n",
    "wget https://dlcdn.apache.org/druid/28.0.1/apache-druid-28.0.1-bin.tar.gz && tar -xzf apache-druid-28.0.1-bin.tar.gz &&\n",
    "cd apache-druid-28.0.1\n",
    "```\n",
    "\n",
    "Run the following command to start Druid:\n",
    "\n",
    "```bash\n",
    "bin/start-druid\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d07feb7-92dd-42a9-ad6c-c89d5fdad8d5",
   "metadata": {},
   "source": [
    "# Process log files\n",
    "\n",
    "Open a second terminal window.\n",
    "\n",
    "> If you are running JupyterLab on your local machine, open a terminal window by clicking here.\n",
    "> \n",
    "> <button data-commandLinker-command=\"terminal:create-new\" href=\"#\">Open a terminal</button>\n",
    "> \n",
    "> Alternatively, start your local terminal in the usual way.\n",
    "\n",
    "The log file locations are set in the `log4j2.xml` alongside Druid's own configuration files.\n",
    "\n",
    "Run this command to view the configuration file that's used by the `learn-druid` script:\n",
    "\n",
    "```bash\n",
    "more ~/learn-druid-logs/apache-druid-28.0.1/conf/druid/auto/_common/log4j2.xml\n",
    "```\n",
    "\n",
    "* [`Properties`](https://logging.apache.org/log4j/2.x/manual/configuration.html#PropertySubstitution) provide key/values pairs that may be used throughout the configuration file.\n",
    "* [`Appenders`](https://logging.apache.org/log4j/2.x/manual/appenders.html) designate the format of log messages and determine the target for the messages.\n",
    "* [`Loggers`](https://logging.apache.org/log4j/2.x/manual/configuration.html#Loggers) filter the log messages and dispense them to Appenders. Loggers can filter messages based on the Java package and/or class and by message priority.\n",
    "\n",
    "In Druid, `Properties` are leveraged to set a location for all logs. This location is calculated when Druid stars, and passed as a parameter to the Java and then to Log4J for that process. By default, this location is a \"log\" folder at the root of your Druid installation, but [can be over-ridden]((https://druid.apache.org/docs/latest/configuration/logging#log-directory) by using the `DRUID_LOG_DIR` system variable.\n",
    "\n",
    "There are two `appenders`:\n",
    "\n",
    "* A `Console` appender for `SYSTEM_OUT`.\n",
    "* A `RollingRandomAccessFile` appender called \"FileAppender\" which is used for detailed process logs.\n",
    "\n",
    "Run the following command to see both these types of files in your running environment.\n",
    "\n",
    "```bash\n",
    "cd ~/learn-druid-logs/apache-druid-28.0.1/log\n",
    "ls\n",
    "```\n",
    "\n",
    "* `process name.stdout.log` file - which is the information written by the processes to stdout (i.e., the terminal)\n",
    "* `process name.log` - file containing various status, error, warning and debug messages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ae60c2-c05f-4a7e-8456-02eb88e5fdbb",
   "metadata": {},
   "source": [
    "## Console output (stdout)\n",
    "\n",
    "Take a look at the _standard out_ log files for the Broker service using the following command:\n",
    "\n",
    "```bash\n",
    "cat broker.stdout.log\n",
    "```\n",
    "\n",
    "A typical output will be:\n",
    "\n",
    "```\n",
    "Running [broker], logging to [/Users/yourname/learn-druid-logs/apache-druid-28.0.1/bin/../log/broker.log] if no changes made to log4j2.xml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c0fd31-7bb2-403d-a525-2ed694a4efdd",
   "metadata": {},
   "source": [
    "## Processing logs\n",
    "\n",
    "Use the following tail command to look at the last few lines of the Middle Manager's processing log:\n",
    "\n",
    "```bash\n",
    "tail 10 middleManager.log\n",
    "```\n",
    "\n",
    "If you are running JupyterLabs and Druid locally, run the following cell to start an ingestion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02835e5a-9fc3-4240-8642-00294d4415e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "# Make sure you replace `your-instance`, and `port` with the values for your deployment.\n",
    "url = \"http://localhost:8888/druid/v2/sql/task/\"\n",
    "\n",
    "payload = json.dumps({\n",
    "  \"query\": \"INSERT INTO \\\"example-wikipedia-logs\\\"\\nSELECT\\n  TIME_PARSE(\\\"timestamp\\\") AS __time,\\n  *\\nFROM TABLE(\\n  EXTERN(\\n    '\\''{\\\"type\\\": \\\"http\\\", \\\"uris\\\": [\\\"https://druid.apache.org/data/wikipedia.json.gz\\\"]}'\\'',\\n    '\\''{\\\"type\\\": \\\"json\\\"}'\\'',\\n    '\\''[{\\\"name\\\": \\\"added\\\", \\\"type\\\": \\\"long\\\"}, {\\\"name\\\": \\\"channel\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"cityName\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"comment\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"commentLength\\\", \\\"type\\\": \\\"long\\\"}, {\\\"name\\\": \\\"countryIsoCode\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"countryName\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"deleted\\\", \\\"type\\\": \\\"long\\\"}, {\\\"name\\\": \\\"delta\\\", \\\"type\\\": \\\"long\\\"}, {\\\"name\\\": \\\"deltaBucket\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"diffUrl\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"flags\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"isAnonymous\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"isMinor\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"isNew\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"isRobot\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"isUnpatrolled\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"metroCode\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"namespace\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"page\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"regionIsoCode\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"regionName\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"timestamp\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"user\\\", \\\"type\\\": \\\"string\\\"}]'\\''\\n  )\\n)\\nPARTITIONED BY DAY\"\n",
    "})\n",
    "headers = {\n",
    "  'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, data=payload)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4099aa1-c9b8-40e4-87b6-cf61636a27d2",
   "metadata": {},
   "source": [
    "In the terminal monitoring the Middle Manager, you will see a number of log entries created, concluding in something similar to:\n",
    "\n",
    "```\n",
    "2024-02-07T12:55:56,434 INFO [WorkerTaskManager-NoticeHandler] org.apache.druid.indexing.worker.WorkerTaskManager - Task [query-58b4b3c6-617e-4201-b0a4-ef63af0ca39c] completed with status [SUCCESS].\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aee5633-cc3f-4755-8682-23a87b06195e",
   "metadata": {},
   "source": [
    "## Reading the log files\n",
    "\n",
    "* Understand the format of individual log entries\n",
    "* Learn how to configure log entries in log4j2.xml\n",
    "* Learn about log entry severity levels and how to filter using them\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6e8716-621c-4c94-90f2-360f568629d1",
   "metadata": {},
   "source": [
    "### Druid log patterns\n",
    "\n",
    "Refer back to the log4j configuration, notice the `PatternLayout`.\n",
    "\n",
    "For the `FileAppender` this has a default of:\n",
    "\n",
    "`%d{ISO8601} %p [%t] %c -%notEmpty{ [%markerSimpleName]} %m%n`\n",
    "\n",
    "* Timestamp (`%d{ISO8601}`)\n",
    "* Message priority (`%p`)\n",
    "* Thread name (`[%t]`)\n",
    "* Class name (`%c`)\n",
    "* Message (`%m%n`)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8e5519-88d7-4da1-982d-c8ba6fe4e83c",
   "metadata": {},
   "source": [
    "### Message priority\n",
    "\n",
    "Community developers assign different log levels to different entries, indicating how severe an event is.\n",
    "\n",
    "* FATAL (system failure)\n",
    "* ERROR (functional failure)\n",
    "* WARN (non-fatal issue)\n",
    "* INFO (notable event)\n",
    "* DEBUG (program debugging messages)\n",
    "* TRACE (highly granular execution event)\n",
    "\n",
    "The base level of logging is set in the `Root` section within `Loggers` in the `log4j2.xml` configuration file for the `FileAppender`. By default, `INFO` is set as the base level.\n",
    "\n",
    "```xml\n",
    "    <Root level=\"info\">\n",
    "        <AppenderRef ref=\"FileAppender\"/>\n",
    "    </Root>\n",
    "```\n",
    "\n",
    "Other base levels are set at a class level, reducing log noise. For example:\n",
    "\n",
    "```xml\n",
    "    <!-- Quieter KafkaSupervisors -->\n",
    "    <Logger name=\"org.apache.kafka.clients.consumer.internals\" level=\"warn\" additivity=\"false\">\n",
    "        <Appender-ref ref=\"FileAppender\"/>\n",
    "    </Logger>\n",
    "```\n",
    "\n",
    "Run the following command to see `WARN`-level log messages in the Middle Manager log.\n",
    "\n",
    "```bash\n",
    "grep WARN middleManager.log\n",
    "```\n",
    "\n",
    "Run this command to amend the current logging level:\n",
    "\n",
    "something\n",
    "\n",
    "```<Root level=\"debug\">```\n",
    "\n",
    "something\n",
    "\n",
    "something"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4910e0d6-f4c0-43c9-9843-35c03aa77e99",
   "metadata": {},
   "source": [
    "### Threads\n",
    "\n",
    "Log files are generated by individual processes as they run. In a Druid cluster where multiple instances of the same process are running independently, it can be helpful to collate the same types of process log together. In this case, the thread name becomes especially important.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b395b2d-286f-42df-8988-db4c6c42bfd4",
   "metadata": {},
   "source": [
    "### Class names\n",
    "\n",
    "You can filter log events to specific classes in the underlying Druid code.\n",
    "\n",
    "A typical entry in a log file contains the package and the class name, for example:\n",
    "\n",
    "`org.apache.curator.utils.Compatibility`\n",
    "\n",
    "Here the package is `org.apache.curator.utils` and the class name is `Compatibility`.\n",
    "\n",
    "Run the following command to see events that have been emitted by the XXXX class:\n",
    "\n",
    "something\n",
    "\n",
    "something\n",
    "\n",
    "something"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b46708-5657-4900-aafc-372cc120665f",
   "metadata": {},
   "source": [
    "### Messages\n",
    "\n",
    "Developers include messages to describe what has happened, what the state of the process or some significant variable is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606ddf6e-a90e-4583-afc1-fba58a897c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Operational logging\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65384957-3c3f-43fb-b296-7e5f7fddbcc5",
   "metadata": {},
   "source": [
    "## Ingestion logging\n",
    "\n",
    "The key processes are:\n",
    "\n",
    "* Overlord\n",
    "* MiddleManager\n",
    "* Tasks\n",
    "* Historical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3a1b9f-419d-4ec7-8de6-d6d54737c7f4",
   "metadata": {},
   "source": [
    "### Watch logs while ingesting\n",
    "\n",
    "```bash\n",
    "multitail -du -P a \\\n",
    "    -f coordinator-overlord.log \\\n",
    "    -f middleManager.log \\\n",
    "    -f historical.log\n",
    "```\n",
    "\n",
    "Whilst in the multitail window, type `O` to clear the output and then hit enter to mark a line.\n",
    "\n",
    "In a new terminal window, run this command to start an ingestion.\n",
    "\n",
    "```bash\n",
    "curl --location --request POST 'http://localhost:8888/druid/v2/sql/task/' \\\n",
    "  --header 'Content-Type: application/json' \\\n",
    "  --data-raw '{\n",
    "    \"query\": \"INSERT INTO \\\"example-wikipedia-logs\\\"\\nSELECT\\n  TIME_PARSE(\\\"timestamp\\\") AS __time,\\n  *\\nFROM TABLE(\\n  EXTERN(\\n    '\\''{\\\"type\\\": \\\"http\\\", \\\"uris\\\": [\\\"https://druid.apache.org/data/wikipedia.json.gz\\\"]}'\\'',\\n    '\\''{\\\"type\\\": \\\"json\\\"}'\\'',\\n    '\\''[{\\\"name\\\": \\\"added\\\", \\\"type\\\": \\\"long\\\"}, {\\\"name\\\": \\\"channel\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"cityName\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"comment\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"commentLength\\\", \\\"type\\\": \\\"long\\\"}, {\\\"name\\\": \\\"countryIsoCode\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"countryName\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"deleted\\\", \\\"type\\\": \\\"long\\\"}, {\\\"name\\\": \\\"delta\\\", \\\"type\\\": \\\"long\\\"}, {\\\"name\\\": \\\"deltaBucket\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"diffUrl\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"flags\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"isAnonymous\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"isMinor\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"isNew\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"isRobot\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"isUnpatrolled\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"metroCode\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"namespace\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"page\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"regionIsoCode\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"regionName\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"timestamp\\\", \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"user\\\", \\\"type\\\": \\\"string\\\"}]'\\''\\n  )\\n)\\nPARTITIONED BY DAY\"\n",
    "  }'\n",
    "```\n",
    "\n",
    "Take note of the activity that is logged across the processes as they cooperate with one another to:\n",
    "\n",
    "* Plan and distribute the work to Middle Managers.\n",
    "* Spawn tasks to handle the ingest, optimization, and push to deep storage.\n",
    "* Load the data out of deep storage and into historicals.\n",
    "\n",
    "Feel free to repeat the steps above to watch what happens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b680cce2-652c-447c-b96e-6be0bc61ab54",
   "metadata": {},
   "source": [
    "### Task logs\n",
    "\n",
    "We will not see the task logs for the ingestion. Recall that each task creates a separate log, and that we use the API to retrieve the log. However, we will see (near the bottom of the middle manager log) the local location of the task log file. We can use the editor (or the less command) to peruse the task log file locally.\n",
    "\n",
    "Use the Tasks API to list the available task logs.\n",
    "\n",
    "```bash\n",
    "curl http://localhost:8081/druid/indexer/v1/tasks | jq\n",
    "```\n",
    "\n",
    "To get the log for a task, use the task log API, providing the ID and the log endpoint.\n",
    "\n",
    "In the following command, switch the ID for one of the IDs output above, and then run it to pull the log file of one of the tasks.\n",
    "\n",
    "```bash\n",
    "curl http://localhost:8888/druid/indexer/v1/task/<ID>/log\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3aeeec-a940-40ab-87d0-c7ed1687a909",
   "metadata": {},
   "source": [
    "## Query logging\n",
    "\n",
    "The key processes involved in interactive queries (>>> API <<<) are:\n",
    "\n",
    "* Broker\n",
    "* Historical\n",
    "* Tasks (for streaming ingestion)\n",
    "\n",
    "For non-interactive SQL queries, the processes are:\n",
    "\n",
    "* Broker\n",
    "* Overlord\n",
    "* Middle Manager\n",
    "* Tasks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bad8a7-8726-41ad-ab4c-d7470dd6b838",
   "metadata": {},
   "source": [
    "### Enable request logging\n",
    "\n",
    "Sometimes it may be helpful to understand what queries Druid is fielding as well as who is making the queries. [Request logs](https://druid.apache.org/docs/latest/operations/request-logging/) give us this information.\n",
    "\n",
    "By default, request logging is disabled. So, in the next couple of steps we enable query logging and restart Druid so that the configuration change takes effect.\n",
    "\n",
    "Run this script in your terminal to amend the `common.runtime.properties` file so that request logging is enabled.\n",
    "\n",
    "```bash\n",
    "sed -i '' 's/druid.startup.logging.logProperties=true/druid.startup.logging.logProperties=true\\ndruid.request.logging.type=slf4j/' \\\n",
    "  ~/learn-druid-logs/apache-druid-28.0.1/conf/druid/auto/_common/common.runtime.properties\n",
    "```\n",
    "\n",
    "Restart your Druid deployment for the change to take effect.\n",
    "\n",
    "Use CTRL+C to stop running processes, then repeat the druid-start above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd14aa41-271b-4dec-a1ee-fcff755311e3",
   "metadata": {},
   "source": [
    "### Monitor an interactive query\n",
    "\n",
    "```bash\n",
    "multitail -du -P a \\\n",
    "    -f broker.log \\\n",
    "    -f historical.log\n",
    "```\n",
    "\n",
    "Run this command to run a query:\n",
    "\n",
    "```bash\n",
    "curl \"http://localhost:8888/druid/v2/sql\" \\\n",
    "--header 'Content-Type: application/json' \\\n",
    "--data '{\n",
    "    \"query\": \"SELECT * FROM \\\"example-wikipedia-logs\\\" \",\n",
    "    \"context\" : {\"sqlQueryId\" : \"learn-druid-logs-sample-query\"},\n",
    "    \"header\" : true\n",
    "}'\n",
    "```\n",
    "\n",
    "Notice that the historical log entry for the query contains a JSON object which contains:\n",
    "* Metrics about how long it took to run.\n",
    "* An identifier for this query, as given in the query parameter context.\n",
    "* The SQL that was run.\n",
    "* Context parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0289d0ab-1462-446c-8cf3-4c9d639bdd85",
   "metadata": {},
   "source": [
    "### Monitor a non-interactive query\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d5921b-636e-4a85-ae4d-dc0239bfef0b",
   "metadata": {},
   "source": [
    "## Learn more\n",
    "\n",
    "In the lab you learned that you can turn on logging for query requests with the druid.startup.logging.logProperties setting. Read all the options - including other possible targets for these logs - in the documentation. An interesting configuration, for example, automatically filters query logging for you.\n",
    "\n",
    "* [Request logging](https://druid.apache.org/docs/latest/configuration/index.html#request-logging)\n",
    "* [Filtered request logging](https://druid.apache.org/docs/latest/configuration/index.html#filtered-request-logging)\n",
    "\n",
    "This information can be really powerful: watch this Druid Summit presentation by Amir Youssefi and Pawas Ranjan from Conviva that describes how useful this information can be to tuning Druid clusters.\n",
    "\n",
    "* [Druid optimizations for scaling customer facing analytics at Conviva](https://youtu.be/zkHXr-3GFJw?t=746)\n",
    "\n",
    "Take a few minutes to scan the official documentation for information about logging configuration. You may want to keep this page to hand throughout the course.\n",
    "\n",
    "* [Logging](https://druid.apache.org/docs/latest/configuration/logging.html)\n",
    "\n",
    "You're about to learn more about Apache Druid's use of Apache Logging Services in the form of Log4J™. Get insight into the background and benefits of Log4J on the official project website:\n",
    "\n",
    "* [Apache Logging Services](https://logging.apache.org/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

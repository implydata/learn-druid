{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cb3b009-ebde-4d56-9d59-a028d66d8309",
   "metadata": {},
   "source": [
    "# Run a query offline using the asynchronous query API\n",
    "<!--\n",
    "  ~ Licensed to the Apache Software Foundation (ASF) under one\n",
    "  ~ or more contributor license agreements.  See the NOTICE file\n",
    "  ~ distributed with this work for additional information\n",
    "  ~ regarding copyright ownership.  The ASF licenses this file\n",
    "  ~ to you under the Apache License, Version 2.0 (the\n",
    "  ~ \"License\"); you may not use this file except in compliance\n",
    "  ~ with the License.  You may obtain a copy of the License at\n",
    "  ~\n",
    "  ~   http://www.apache.org/licenses/LICENSE-2.0\n",
    "  ~\n",
    "  ~ Unless required by applicable law or agreed to in writing,\n",
    "  ~ software distributed under the License is distributed on an\n",
    "  ~ \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n",
    "  ~ KIND, either express or implied.  See the License for the\n",
    "  ~ specific language governing permissions and limitations\n",
    "  ~ under the License.\n",
    "  -->\n",
    "\n",
    "Druid provides two APIs to run SELECT queries - the interactive API and the asynchronous API.\n",
    "\n",
    "Whereas the interactive API uses data prefetched on historicals and arriving from event streams, the asynchronous accesses data in deep storage in combination with streaming data.\n",
    "\n",
    "This tutorial focuses on using the asynchronous API to access data in [deep storage](https://druid.apache.org/docs/latest/api-reference/sql-api#query-from-deep-storage). To see how to access real-time data, see the [full timeline queries](14-query-async-realtime.ipynb) notebook.\n",
    "\n",
    "You will perform the following tasks:\n",
    "\n",
    "- Ingest some data covering a long period of time.\n",
    "- Apply a retention rule set to the table so that some of the data is not loaded to historicals.\n",
    "- Execute a query using the asynchronous API.\n",
    "- Retrieve the results of your query.\n",
    "- Apply pagination to your results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdbf6ad-ca7b-40f5-8ca3-1070f4a3ee42",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "This tutorial works with Druid 30.0.0 or later.\n",
    "\n",
    "Launch this tutorial and all prerequisites using the `druid-jupyter` profile of the Docker Compose file for Jupyter-based Druid tutorials. For more information, see the Learn Druid repository [readme](https://github.com/implydata/learn-druid)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5007a243-b81a-4601-8f57-5b14940abbff",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "\n",
    "The following cells set up the notebook and learning environment ready for use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b769122-c5a4-404e-9ef8-9c0ebd97695a",
   "metadata": {},
   "source": [
    "### Set up a connection to Apache Druid\n",
    "\n",
    "Run the next cell to set up the Druid Python client's connection to Apache Druid.\n",
    "\n",
    "If successful, the Druid version number will be shown in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ec783b-df3f-4168-9be2-cdc6ad3e33c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import druidapi\n",
    "import os\n",
    "\n",
    "druid_headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "if 'DRUID_HOST' not in os.environ.keys():\n",
    "    druid_host=f\"http://localhost:8888\"\n",
    "else:\n",
    "    druid_host=f\"http://{os.environ['DRUID_HOST']}:8888\"\n",
    "\n",
    "print(f\"Opening a connection to {druid_host}.\")\n",
    "druid = druidapi.jupyter_client(druid_host)\n",
    "display = druid.display\n",
    "sql_client = druid.sql\n",
    "status_client = druid.status\n",
    "\n",
    "status_client.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3d6b39-6551-4b2a-bdfb-9606aa92c853",
   "metadata": {},
   "source": [
    "### Import additional modules\n",
    "\n",
    "Run the following cell to import additional Python modules that you will use to call some APIs directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4c2524-0eba-4bc6-84ed-da3a25aa5fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472589e4-1026-4b3b-bb79-eedabb2b44c4",
   "metadata": {},
   "source": [
    "## Create a table using batch ingestion\n",
    "\n",
    "<!-- Use these cells if you are using batch ingestion for your notebook. -->\n",
    "\n",
    "Run the following cell to create a table using batch ingestion. Notice {the use of X as a timestamp | only required columns are ingested | WHERE / expressions / GROUP BY are front-loaded | partitions on X period and clusters by Y}.\n",
    "\n",
    "When completed, you'll see a description of the final table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52a94fb-d2e4-403f-ab10-84d3af7bf2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = 'example-flights-querydeepstorage'\n",
    "\n",
    "sql='''\n",
    "REPLACE INTO \"''' + table_name + '''\" OVERWRITE ALL\n",
    "WITH \"ext\" AS (SELECT *\n",
    "FROM TABLE(\n",
    "  EXTERN(\n",
    "    '{\"type\":\"http\",\"uris\":[\"https://static.imply.io/example-data/flight_on_time/flights/On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2005_11.csv.zip\"]}',\n",
    "    '{\"type\":\"csv\",\"findColumnsFromHeader\":true}'\n",
    "  )\n",
    ") EXTEND (\"depaturetime\" VARCHAR, \"arrivalime\" VARCHAR, \"Year\" BIGINT, \"Quarter\" BIGINT, \"Month\" BIGINT, \"DayofMonth\" BIGINT, \"DayOfWeek\" BIGINT, \"FlightDate\" VARCHAR, \"Reporting_Airline\" VARCHAR, \"DOT_ID_Reporting_Airline\" BIGINT, \"IATA_CODE_Reporting_Airline\" VARCHAR, \"Tail_Number\" VARCHAR, \"Flight_Number_Reporting_Airline\" BIGINT, \"OriginAirportID\" BIGINT, \"OriginAirportSeqID\" BIGINT, \"OriginCityMarketID\" BIGINT, \"Origin\" VARCHAR, \"OriginCityName\" VARCHAR, \"OriginState\" VARCHAR, \"OriginStateFips\" BIGINT, \"OriginStateName\" VARCHAR, \"OriginWac\" BIGINT, \"DestAirportID\" BIGINT, \"DestAirportSeqID\" BIGINT, \"DestCityMarketID\" BIGINT, \"Dest\" VARCHAR, \"DestCityName\" VARCHAR, \"DestState\" VARCHAR, \"DestStateFips\" BIGINT, \"DestStateName\" VARCHAR, \"DestWac\" BIGINT, \"CRSDepTime\" BIGINT, \"DepTime\" BIGINT, \"DepDelay\" BIGINT, \"DepDelayMinutes\" BIGINT, \"DepDel15\" BIGINT, \"DepartureDelayGroups\" BIGINT, \"DepTimeBlk\" VARCHAR, \"TaxiOut\" BIGINT, \"WheelsOff\" BIGINT, \"WheelsOn\" BIGINT, \"TaxiIn\" BIGINT, \"CRSArrTime\" BIGINT, \"ArrTime\" BIGINT, \"ArrDelay\" BIGINT, \"ArrDelayMinutes\" BIGINT, \"ArrDel15\" BIGINT, \"ArrivalDelayGroups\" BIGINT, \"ArrTimeBlk\" VARCHAR, \"Cancelled\" BIGINT, \"CancellationCode\" VARCHAR, \"Diverted\" BIGINT, \"CRSElapsedTime\" BIGINT, \"ActualElapsedTime\" BIGINT, \"AirTime\" BIGINT, \"Flights\" BIGINT, \"Distance\" BIGINT, \"DistanceGroup\" BIGINT, \"CarrierDelay\" BIGINT, \"WeatherDelay\" BIGINT, \"NASDelay\" BIGINT, \"SecurityDelay\" BIGINT, \"LateAircraftDelay\" BIGINT, \"FirstDepTime\" VARCHAR, \"TotalAddGTime\" VARCHAR, \"LongestAddGTime\" VARCHAR, \"DivAirportLandings\" VARCHAR, \"DivReachedDest\" VARCHAR, \"DivActualElapsedTime\" VARCHAR, \"DivArrDelay\" VARCHAR, \"DivDistance\" VARCHAR, \"Div1Airport\" VARCHAR, \"Div1AirportID\" VARCHAR, \"Div1AirportSeqID\" VARCHAR, \"Div1WheelsOn\" VARCHAR, \"Div1TotalGTime\" VARCHAR, \"Div1LongestGTime\" VARCHAR, \"Div1WheelsOff\" VARCHAR, \"Div1TailNum\" VARCHAR, \"Div2Airport\" VARCHAR, \"Div2AirportID\" VARCHAR, \"Div2AirportSeqID\" VARCHAR, \"Div2WheelsOn\" VARCHAR, \"Div2TotalGTime\" VARCHAR, \"Div2LongestGTime\" VARCHAR, \"Div2WheelsOff\" VARCHAR, \"Div2TailNum\" VARCHAR, \"Div3Airport\" VARCHAR, \"Div3AirportID\" VARCHAR, \"Div3AirportSeqID\" VARCHAR, \"Div3WheelsOn\" VARCHAR, \"Div3TotalGTime\" VARCHAR, \"Div3LongestGTime\" VARCHAR, \"Div3WheelsOff\" VARCHAR, \"Div3TailNum\" VARCHAR, \"Div4Airport\" VARCHAR, \"Div4AirportID\" VARCHAR, \"Div4AirportSeqID\" VARCHAR, \"Div4WheelsOn\" VARCHAR, \"Div4TotalGTime\" VARCHAR, \"Div4LongestGTime\" VARCHAR, \"Div4WheelsOff\" VARCHAR, \"Div4TailNum\" VARCHAR, \"Div5Airport\" VARCHAR, \"Div5AirportID\" VARCHAR, \"Div5AirportSeqID\" VARCHAR, \"Div5WheelsOn\" VARCHAR, \"Div5TotalGTime\" VARCHAR, \"Div5LongestGTime\" VARCHAR, \"Div5WheelsOff\" VARCHAR, \"Div5TailNum\" VARCHAR, \"Unnamed: 109\" VARCHAR))\n",
    "SELECT\n",
    "  TIME_PARSE(\"depaturetime\") AS \"__time\",\n",
    "  \"Year\",\n",
    "  \"Reporting_Airline\",\n",
    "  \"Origin\",\n",
    "  \"Dest\",\n",
    "  \"Distance\"\n",
    "FROM \"ext\"\n",
    "WHERE \"depaturetime\" <> 0\n",
    "PARTITIONED BY DAY\n",
    "'''\n",
    "\n",
    "display.run_task(sql)\n",
    "sql_client.wait_until_ready(table_name)\n",
    "display.table(table_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c590f15-243d-48f3-a8dc-4ddfa13eb66a",
   "metadata": {},
   "source": [
    "Run the following cell to see how the table is currently loaded in the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecd00bb-a771-41b6-8190-6c6d442a63d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql=f'''\n",
    "SELECT\n",
    "  a.\"start\",\n",
    "  a.\"end\",\n",
    "  c.\"server\",\n",
    "  c.\"tier\",\n",
    "  \"num_rows\",\n",
    "  \"size\"\n",
    "FROM \"sys\".\"segments\" a\n",
    "LEFT JOIN \"sys\".\"server_segments\" b ON a.\"segment_id\" = b.\"segment_id\"\n",
    "LEFT JOIN \"sys\".\"servers\" c ON b.\"server\" = c.\"server\"\n",
    "WHERE \"datasource\" = '{table_name}'\n",
    "ORDER BY \"start\", \"tier\"\n",
    "'''\n",
    "\n",
    "display.sql(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d80aa3-2697-4873-9053-61eb870cb25e",
   "metadata": {},
   "source": [
    "Notice that, because the default set of retention rules (`_default`) has been applied to this new table, the entire set of segments are loaded to historicals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a92ffc2-856c-420f-b058-51042c7e6be0",
   "metadata": {},
   "source": [
    "## Apply retention rules\n",
    "\n",
    "Force some of the data to be left on deep storage by changing the retention load rules for a table.\n",
    "\n",
    "In the next cell, the retention rules ensure data after 11th November 2005 is picked to be loaded to historicals in the `_default_tier` tier. All other data is caught by the second rule, which ensures no data is cached on historicals.\n",
    "\n",
    "Run the cell to apply the rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109e0b41-0990-4549-8350-a886a83f7d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "retention_rules = [\n",
    "  {\n",
    "    \"type\": \"loadByInterval\",\n",
    "    \"interval\": \"2005-11-18/P10Y\",\n",
    "    \"tieredReplicants\": {\n",
    "      \"_default_tier\": 1\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"type\": \"loadForever\",\n",
    "    \"tieredReplicants\": {},\n",
    "    \"useDefaultTierForNull\": \"false\"\n",
    "  }\n",
    "]\n",
    "\n",
    "requests.post(f\"{druid_host}/druid/coordinator/v1/rules/{table_name}\", json.dumps(retention_rules), headers=druid_headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20db806c-abca-41cd-ab9e-0b88d655633f",
   "metadata": {},
   "source": [
    "Now run the next cell to confirm the change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34f80b4-601c-4a27-b0c2-6c495a262105",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql=f'''\n",
    "SELECT\n",
    "  a.\"start\",\n",
    "  a.\"end\",\n",
    "  c.\"server\",\n",
    "  c.\"tier\",\n",
    "  \"num_rows\",\n",
    "  \"size\"\n",
    "FROM \"sys\".\"segments\" a\n",
    "LEFT JOIN \"sys\".\"server_segments\" b ON a.\"segment_id\" = b.\"segment_id\"\n",
    "LEFT JOIN \"sys\".\"servers\" c ON b.\"server\" = c.\"server\"\n",
    "WHERE \"datasource\" = '{table_name}'\n",
    "ORDER BY \"start\", \"tier\"\n",
    "'''\n",
    "\n",
    "display.sql(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88e9033-f322-4c62-ab05-78db3dea5c45",
   "metadata": {},
   "source": [
    "Run the cell above until some segments are shown without a server and tier.\n",
    "\n",
    "Notice that, when you run the following query, results are limited to data fetched to a historical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4affc5-bfcd-49fb-84a7-40bb810b2b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql=f'''\n",
    "SELECT\n",
    "  TIME_FLOOR(\"__time\",'P1D') AS \"period\",\n",
    "  COUNT(*) as \"events\"\n",
    "FROM \"{table_name}\"\n",
    "GROUP BY 1\n",
    "'''\n",
    "display.sql(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6c9b88-837d-4c80-a28d-36184ba63355",
   "metadata": {},
   "source": [
    "## Execute an asynchronous query\n",
    "\n",
    "Use the `/druid/v2/sql/statements` API endpoint to run asynchronous queries using MSQ engine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045df49c-24ad-4eff-9b5f-0a30bfd47bf1",
   "metadata": {},
   "source": [
    "### Call the API using the druid_api package\n",
    "\n",
    "The `async_sql` method handles the [necessary steps](https://druid.apache.org/docs/latest/tutorials/tutorial-query-deep-storage#query-from-deep-storage) not only to submit the query, but to retrieve the results.\n",
    "\n",
    "Run the following cell, which uses the `async_sql` method of the `druid_api` package to call the API and return the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4120c74-a05a-47aa-8ec3-5b9b0030e046",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql=f'''\n",
    "SELECT\n",
    "  TIME_FLOOR(\"__time\",'P1D') AS \"period\",\n",
    "  COUNT(*) as \"events\"\n",
    "FROM \"{table_name}\"\n",
    "WHERE TIME_IN_INTERVAL(\"__time\",'2005-11-16/P1W')\n",
    "GROUP BY 1\n",
    "'''\n",
    "\n",
    "result = sql_client.async_sql(sql)\n",
    "result.wait_until_done()\n",
    "\n",
    "print(json.dumps(result.rows, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86d3ae2-277c-49b4-982b-31d6c630c022",
   "metadata": {},
   "source": [
    "Notice that the results cover an entire week, and are not limited to those periods loaded to historicals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2d3341-37a8-4eb1-80f4-6391b55b6b42",
   "metadata": {},
   "source": [
    "### Call the API directly\n",
    "\n",
    "Run the following cell to submit the query directly to the API.\n",
    "\n",
    "* The `request_json` object contains the query and the necessary context parameters.\n",
    "* The API is called using `requests.post` with the results stored in `response`.\n",
    "* A pretty print is made of the JSON response from the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67af770-eac1-4b7f-bb55-5176356fadeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_request_json = {\n",
    "    \"query\":f\"SELECT TIME_FLOOR(\\\"__time\\\",'P1D') AS \\\"period\\\", COUNT(*) as \\\"events\\\" FROM \\\"{table_name}\\\" WHERE TIME_IN_INTERVAL(\\\"__time\\\",'2005-11-16/P1W') GROUP BY 1\",\n",
    "    \"context\":{\n",
    "        \"executionMode\":\"ASYNC\"\n",
    "    }\n",
    "}\n",
    "\n",
    "query_response = requests.post(f\"{druid_host}/druid/v2/sql/statements\", json.dumps(query_request_json), headers=druid_headers)\n",
    "query_response_json = json.loads(query_response.text)\n",
    "\n",
    "print(json.dumps(query_response_json, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac7a4b5-c467-4304-8f06-d3eb5c5bf165",
   "metadata": {},
   "source": [
    "Notice the `queryId` in the response object.\n",
    "\n",
    "Run the next cell to use the API to see the status of the query as it executes. The cell captures the `queryId` and uses this to construct a GET to the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45535acf-07cc-489d-9b20-6bb2891deec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "queryId = query_response_json[\"queryId\"]\n",
    "\n",
    "job_result=requests.get(f\"{druid_host}/druid/v2/sql/statements/{queryId}\")\n",
    "job_result_json = json.loads(job_result.text)\n",
    "\n",
    "print(json.dumps(job_result_json, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2371778-e6e8-43ab-8bad-d808d7e6e28d",
   "metadata": {},
   "source": [
    "Once the status shows as \"SUCCESS\", retrieve the result by running the following cell.\n",
    "\n",
    "The Url is constructed from:\n",
    "* The Url to the API, appended with the query Id.\n",
    "* The page of the results to return.\n",
    "* The format of the results to return.\n",
    "  \n",
    "The results of the call to the API are captured in `results_response`, and then printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45047ab-a813-4b61-b429-36a074864408",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_resultFormat = \"objectLines\"\n",
    "results_page = \"0\"\n",
    "\n",
    "results_request_url = f'{druid_host}/druid/v2/sql/statements/{queryId}/results?page={results_page}&resultFormat={results_resultFormat}'\n",
    "\n",
    "results_response = requests.get(results_request_url, headers=druid_headers).text\n",
    "print (results_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8988cb6f-8e51-4cf9-bdd6-047272ca5dae",
   "metadata": {},
   "source": [
    "## Paginate results\n",
    "\n",
    "Use the `rowsPerPage` query context parameter to control the size of the results page.\n",
    "\n",
    "In the `query_request_json`, the page size is set by providing a parameter in the call to the Python API, and the destination of the query has been set to [`durableStorage`](https://druid.apache.org/docs/latest/operations/durable-storage).\n",
    "\n",
    "Durable Storage has been configured in the learning environment's [`environment`](https://github.com/implydata/learn-druid/blob/main/environment) file to point to a local volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1ebaeb-bb52-4de5-82cf-56eaa3291c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_request_json = {\n",
    "    \"query\":f\"SELECT TIME_FLOOR(\\\"__time\\\",'P1D') AS \\\"period\\\", COUNT(*) as \\\"events\\\" FROM \\\"{table_name}\\\" WHERE TIME_IN_INTERVAL(\\\"__time\\\",'2005-11-16/P1W') GROUP BY 1\",\n",
    "    \"context\":{\n",
    "        \"executionMode\":\"ASYNC\",\n",
    "        \"selectDestination\":\"durableStorage\",\n",
    "        \"rowsPerPage\":3\n",
    "    }\n",
    "}\n",
    "\n",
    "query_response = requests.post(f\"{druid_host}/druid/v2/sql/statements\", json.dumps(query_request_json), headers=druid_headers)\n",
    "query_response_json = json.loads(query_response.text)\n",
    "\n",
    "print(json.dumps(query_response_json, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a63990-67e6-4b7e-9682-693d2bdd7a05",
   "metadata": {},
   "source": [
    "Run the following cell to get the status of the query.\n",
    "\n",
    "Repeat until the `state` shows as success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc22c681-9a02-43dc-8f39-a1215824a92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "queryId = query_response_json[\"queryId\"]\n",
    "\n",
    "job_result=requests.get(f\"{druid_host}/druid/v2/sql/statements/{queryId}\")\n",
    "job_result_json = json.loads(job_result.text)\n",
    "\n",
    "print(json.dumps(job_result_json, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c1385a-6399-40ab-92ab-7cd639bed28e",
   "metadata": {},
   "source": [
    "Notice that there are now multiple `pages` to read from.\n",
    "\n",
    "Run the next cell to retrieve only one page of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4edab10-c234-48d9-8878-0d3a6700ef91",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_page = \"2\"\n",
    "\n",
    "results_request_url = f'{druid_host}/druid/v2/sql/statements/{queryId}/results?page={results_page}&resultFormat={results_resultFormat}'\n",
    "\n",
    "results_response = requests.get(results_request_url, headers=druid_headers).text\n",
    "print (results_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44738d6d-cec2-40ad-aaba-998c758c63f4",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "\n",
    "Run the following cell to reset the retention rules for the table, and then to drop it from the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8082b545-ba7f-4ede-bb6e-2a6dd62ba0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "retention_rules = []\n",
    "requests.post(f\"{druid_host}/druid/coordinator/v1/rules/{table_name}\", json.dumps(retention_rules), headers=druid_headers)\n",
    "print(f\"Drop table: [{druid.datasources.drop(table_name)}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b8d5fe-ba85-4b5b-9669-0dd47dfbccd1",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "* SELECTs can run online (interactive API) or offline (asynchronous API).\n",
    "* The offline API can access data that has not been prefetched to historicals.\n",
    "* Durable Storage can be used to hold results of queries.\n",
    "* Results can be paginated and can have different formats.\n",
    "\n",
    "## Learn more\n",
    "\n",
    "* Read about [using EXTERN to export data](https://druid.apache.org/docs/latest/multi-stage-query/reference#extern-to-export-to-a-destination).\n",
    "* See the [documenation](https://druid.apache.org/docs/latest/querying/query-deep-storage) and [tutorial](https://druid.apache.org/docs/latest/tutorials/tutorial-query-deep-storage) on querying from deep storage.\n",
    "* Read about [durable storage](https://druid.apache.org/docs/latest/multi-stage-query/reference#durable-storage) in the documentation, including how to [configure](https://druid.apache.org/docs/latest/operations/durable-storage) it.\n",
    "* See the [full timeline](14-sync-async-queries.ipynb) notebook to see how the asynchronous API can also incorporate real-time data.\n",
    "* See more retention load rules in the [load rules](20-tiering-historicals.ipynb) notebook."
   ]
  }
 ],
 "metadata": {
  "execution": {
   "allow_errors": true,
   "timeout": 300
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

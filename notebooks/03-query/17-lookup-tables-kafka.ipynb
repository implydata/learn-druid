{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cb3b009-ebde-4d56-9d59-a028d66d8309",
   "metadata": {},
   "source": [
    "# Enriching and updating data using Kafka lookup tables\n",
    "<!--\n",
    "  ~ Licensed to the Apache Software Foundation (ASF) under one\n",
    "  ~ or more contributor license agreements.  See the NOTICE file\n",
    "  ~ distributed with this work for additional information\n",
    "  ~ regarding copyright ownership.  The ASF licenses this file\n",
    "  ~ to you under the Apache License, Version 2.0 (the\n",
    "  ~ \"License\"); you may not use this file except in compliance\n",
    "  ~ with the License.  You may obtain a copy of the License at\n",
    "  ~\n",
    "  ~   http://www.apache.org/licenses/LICENSE-2.0\n",
    "  ~\n",
    "  ~ Unless required by applicable law or agreed to in writing,\n",
    "  ~ software distributed under the License is distributed on an\n",
    "  ~ \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n",
    "  ~ KIND, either express or implied.  See the License for the\n",
    "  ~ specific language governing permissions and limitations\n",
    "  ~ under the License.\n",
    "  -->\n",
    "\n",
    "[Lookups](https://druid.apache.org/docs/latest/querying/lookups) are [key/value-pair tables](https://druid.apache.org/docs/latest/querying/datasource#lookup) broadcast to query processes that can be updated regularly either manually or automatically. In this notebook you will extend your knowledge of these tables to lookups populated from an [Apache Kafka topic](https://druid.apache.org/docs/latest/querying/kafka-extraction-namespace) and walk through some simple queries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdbf6ad-ca7b-40f5-8ca3-1070f4a3ee42",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "This tutorial works with Druid 30.0.0 or later.\n",
    "\n",
    "Before running through this notebook, you may want to familiarise yourself with key concepts by running through the [general lookups notebook](./06-lookup-tables.ipynb).\n",
    "\n",
    "Launch this tutorial and all prerequisites using the `all-services` profile of the Docker Compose file for Jupyter-based Druid tutorials. For more information, see the Learn Druid repository [readme](https://github.com/implydata/learn-druid).\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5007a243-b81a-4601-8f57-5b14940abbff",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "\n",
    "The following cells set up the notebook and learning environment ready for use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b769122-c5a4-404e-9ef8-9c0ebd97695a",
   "metadata": {},
   "source": [
    "### Set up a connection to Apache Druid\n",
    "\n",
    "Run the next cell to set up the Druid Python client's connection to Apache Druid.\n",
    "\n",
    "If successful, the Druid version number will be shown in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1ec783b-df3f-4168-9be2-cdc6ad3e33c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening a connection to http://router:8888.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  .druid table {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "\n",
       "  .druid th, .druid td {\n",
       "    padding: 4px 1em ;\n",
       "    text-align: left;\n",
       "  }\n",
       "\n",
       "  td.druid-right, th.druid-right {\n",
       "    text-align: right;\n",
       "  }\n",
       "\n",
       "  td.druid-center, th.druid-center {\n",
       "    text-align: center;\n",
       "  }\n",
       "\n",
       "  .druid .druid-left {\n",
       "    text-align: left;\n",
       "  }\n",
       "\n",
       "  .druid-alert {\n",
       "    font-weight: bold;\n",
       "  }\n",
       "\n",
       "  .druid-error {\n",
       "    color: red;\n",
       "  }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'29.0.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import druidapi\n",
    "import os\n",
    "\n",
    "druid_headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "if 'DRUID_HOST' not in os.environ.keys():\n",
    "    druid_host=f\"http://localhost:8888\"\n",
    "else:\n",
    "    druid_host=f\"http://{os.environ['DRUID_HOST']}:8888\"\n",
    "\n",
    "print(f\"Opening a connection to {druid_host}.\")\n",
    "druid = druidapi.jupyter_client(druid_host)\n",
    "display = druid.display\n",
    "sql_client = druid.sql\n",
    "status_client = druid.status\n",
    "\n",
    "status_client.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efdbee0-62da-4fd3-84e1-f66b8c0150b3",
   "metadata": {},
   "source": [
    "### Set up a connection to Apache Kafka\n",
    "\n",
    "<!-- Include these cells if your notebook uses Kafka. -->\n",
    "\n",
    "Run the next cell to set up the connection to Apache Kafka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c075de81-04c9-4b23-8253-20a15d46252e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'KAFKA_HOST' not in os.environ.keys():\n",
    "   kafka_host=f\"http://localhost:9092\"\n",
    "else:\n",
    "    kafka_host=f\"{os.environ['KAFKA_HOST']}:9092\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472589e4-1026-4b3b-bb79-eedabb2b44c4",
   "metadata": {},
   "source": [
    "## Create a table using batch ingestion\n",
    "\n",
    "Run the following cell to create a table using batch ingestion.\n",
    "\n",
    "The same principles in this notebook also apply to tables receiving events from stream sources.\n",
    "\n",
    "When completed, you'll see a description of the final table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f52a94fb-d2e4-403f-ab10-84d3af7bf2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data, status:[SUCCESS]: 100%|██████████| 100.0/100.0 [00:20<00:00,  4.91it/s]            \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"druid\"><table>\n",
       "<tr><th>Position</th><th>Name</th><th>Type</th></tr>\n",
       "<tr><td>1</td><td>__time</td><td>TIMESTAMP</td></tr>\n",
       "<tr><td>2</td><td>Reporting_Airline</td><td>VARCHAR</td></tr>\n",
       "<tr><td>3</td><td>Tail_Number</td><td>VARCHAR</td></tr>\n",
       "<tr><td>4</td><td>Distance</td><td>BIGINT</td></tr>\n",
       "<tr><td>5</td><td>Origin</td><td>VARCHAR</td></tr>\n",
       "<tr><td>6</td><td>Dest</td><td>VARCHAR</td></tr>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table_name = 'example-flights-kafkalookup'\n",
    "\n",
    "sql='''\n",
    "REPLACE INTO \"''' + table_name + '''\" OVERWRITE ALL\n",
    "WITH \"ext\" AS (SELECT *\n",
    "FROM TABLE(\n",
    "  EXTERN(\n",
    "    '{\"type\":\"http\",\"uris\":[\"https://static.imply.io/example-data/flight_on_time/flights/On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2005_11.csv.zip\"]}',\n",
    "    '{\"type\":\"csv\",\"findColumnsFromHeader\":true}'\n",
    "  )\n",
    ") EXTEND (\"depaturetime\" VARCHAR, \"arrivalime\" VARCHAR, \"Year\" BIGINT, \"Quarter\" BIGINT, \"Month\" BIGINT, \"DayofMonth\" BIGINT, \"DayOfWeek\" BIGINT, \"FlightDate\" VARCHAR, \"Reporting_Airline\" VARCHAR, \"DOT_ID_Reporting_Airline\" BIGINT, \"IATA_CODE_Reporting_Airline\" VARCHAR, \"Tail_Number\" VARCHAR, \"Flight_Number_Reporting_Airline\" BIGINT, \"OriginAirportID\" BIGINT, \"OriginAirportSeqID\" BIGINT, \"OriginCityMarketID\" BIGINT, \"Origin\" VARCHAR, \"OriginCityName\" VARCHAR, \"OriginState\" VARCHAR, \"OriginStateFips\" BIGINT, \"OriginStateName\" VARCHAR, \"OriginWac\" BIGINT, \"DestAirportID\" BIGINT, \"DestAirportSeqID\" BIGINT, \"DestCityMarketID\" BIGINT, \"Dest\" VARCHAR, \"DestCityName\" VARCHAR, \"DestState\" VARCHAR, \"DestStateFips\" BIGINT, \"DestStateName\" VARCHAR, \"DestWac\" BIGINT, \"CRSDepTime\" BIGINT, \"DepTime\" BIGINT, \"DepDelay\" BIGINT, \"DepDelayMinutes\" BIGINT, \"DepDel15\" BIGINT, \"DepartureDelayGroups\" BIGINT, \"DepTimeBlk\" VARCHAR, \"TaxiOut\" BIGINT, \"WheelsOff\" BIGINT, \"WheelsOn\" BIGINT, \"TaxiIn\" BIGINT, \"CRSArrTime\" BIGINT, \"ArrTime\" BIGINT, \"ArrDelay\" BIGINT, \"ArrDelayMinutes\" BIGINT, \"ArrDel15\" BIGINT, \"ArrivalDelayGroups\" BIGINT, \"ArrTimeBlk\" VARCHAR, \"Cancelled\" BIGINT, \"CancellationCode\" VARCHAR, \"Diverted\" BIGINT, \"CRSElapsedTime\" BIGINT, \"ActualElapsedTime\" BIGINT, \"AirTime\" BIGINT, \"Flights\" BIGINT, \"Distance\" BIGINT, \"DistanceGroup\" BIGINT, \"CarrierDelay\" BIGINT, \"WeatherDelay\" BIGINT, \"NASDelay\" BIGINT, \"SecurityDelay\" BIGINT, \"LateAircraftDelay\" BIGINT, \"FirstDepTime\" VARCHAR, \"TotalAddGTime\" VARCHAR, \"LongestAddGTime\" VARCHAR, \"DivAirportLandings\" VARCHAR, \"DivReachedDest\" VARCHAR, \"DivActualElapsedTime\" VARCHAR, \"DivArrDelay\" VARCHAR, \"DivDistance\" VARCHAR, \"Div1Airport\" VARCHAR, \"Div1AirportID\" VARCHAR, \"Div1AirportSeqID\" VARCHAR, \"Div1WheelsOn\" VARCHAR, \"Div1TotalGTime\" VARCHAR, \"Div1LongestGTime\" VARCHAR, \"Div1WheelsOff\" VARCHAR, \"Div1TailNum\" VARCHAR, \"Div2Airport\" VARCHAR, \"Div2AirportID\" VARCHAR, \"Div2AirportSeqID\" VARCHAR, \"Div2WheelsOn\" VARCHAR, \"Div2TotalGTime\" VARCHAR, \"Div2LongestGTime\" VARCHAR, \"Div2WheelsOff\" VARCHAR, \"Div2TailNum\" VARCHAR, \"Div3Airport\" VARCHAR, \"Div3AirportID\" VARCHAR, \"Div3AirportSeqID\" VARCHAR, \"Div3WheelsOn\" VARCHAR, \"Div3TotalGTime\" VARCHAR, \"Div3LongestGTime\" VARCHAR, \"Div3WheelsOff\" VARCHAR, \"Div3TailNum\" VARCHAR, \"Div4Airport\" VARCHAR, \"Div4AirportID\" VARCHAR, \"Div4AirportSeqID\" VARCHAR, \"Div4WheelsOn\" VARCHAR, \"Div4TotalGTime\" VARCHAR, \"Div4LongestGTime\" VARCHAR, \"Div4WheelsOff\" VARCHAR, \"Div4TailNum\" VARCHAR, \"Div5Airport\" VARCHAR, \"Div5AirportID\" VARCHAR, \"Div5AirportSeqID\" VARCHAR, \"Div5WheelsOn\" VARCHAR, \"Div5TotalGTime\" VARCHAR, \"Div5LongestGTime\" VARCHAR, \"Div5WheelsOff\" VARCHAR, \"Div5TailNum\" VARCHAR, \"Unnamed: 109\" VARCHAR))\n",
    "SELECT\n",
    "  TIME_PARSE(\"depaturetime\") AS \"__time\",\n",
    "  \"Reporting_Airline\",\n",
    "  \"Tail_Number\",\n",
    "  \"Distance\",\n",
    "  \"Origin\",\n",
    "  \"Dest\"\n",
    "FROM \"ext\"\n",
    "PARTITIONED BY DAY\n",
    "'''\n",
    "\n",
    "display.run_task(sql)\n",
    "sql_client.wait_until_ready(f'{table_name}')\n",
    "display.table(f'{table_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6c9b88-837d-4c80-a28d-36184ba63355",
   "metadata": {},
   "source": [
    "## Create a lookup table\n",
    "\n",
    "Run the following cell to create some helper functions for using the lookup API.\n",
    "\n",
    "* You will use the `postLookup` function to call the [lookup configuration API](https://druid.apache.org/docs/latest/api-reference/lookups-api) to create and update lookup tables.\n",
    "* The `waitForLookup` function will be used to give you feedback on Druid's progress in [distributing](https://druid.apache.org/docs/latest/querying/lookups#configuration-propagation-behavior) the lookup table around the query-serving processes in Druid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4db15f0d-6305-43d1-bb2d-b927c62ae70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "def postLookup(definition):\n",
    "    x = requests.post(f\"{druid_host}/druid/coordinator/v1/lookups/config\", json=definition)\n",
    "\n",
    "    if \"error\" in x.text:\n",
    "        raise Exception('Not able to complete the request. \\n\\n'+x.text)\n",
    "    else:\n",
    "        print('Successfully submitted the lookup request.')\n",
    "\n",
    "def waitForLookup(tier, name, ticsMax):\n",
    "\n",
    "    # The default time period between checks of lookup definition changes (druid.manager.lookups.period)\n",
    "    # is two minutes. The notebook environment reduces this for learning purposes.\n",
    "    # \n",
    "    # https://druid.apache.org/docs/latest/configuration/#lookups-dynamic-configuration\n",
    "\n",
    "    tics = 0\n",
    "    ticsWait = 1    \n",
    "    ticsMax = min(ticsMax,360)\n",
    "    ticsSpinner = \"/-\\|\"\n",
    "    \n",
    "    apicall = f\"{druid_host}/druid/coordinator/v1/lookups/status/{tier}/{name}?detailed=true\"\n",
    "\n",
    "    x = requests.get(apicall)\n",
    "\n",
    "    while (x.text != '{\"loaded\":true,\"pendingNodes\":[]}' and tics < ticsMax):\n",
    "        print(f\"{x.text} {ticsSpinner[tics%len(ticsSpinner)]} [ {str(ticsMax-tics)} ]     \", end='\\r')\n",
    "        time.sleep(ticsWait)\n",
    "        tics += 1\n",
    "        x = requests.get(apicall) \n",
    "\n",
    "    if (tics == ticsMax):\n",
    "        raise Exception(f\"\\nTimeout waiting for Druid to load the {name} lookup to {tier} tier. Run the cell again.\")\n",
    "    else:\n",
    "        print(f\"\\nSuccess. {name} lookup in {tier} tier is fully available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2545ea68-9878-4c01-af81-c637e07e7031",
   "metadata": {},
   "source": [
    "### Initialize lookups\n",
    "\n",
    "Run the following cell, which posts an empty JSON object to the configuration API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d6d276c-0449-4590-aad3-09a203a8cdf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted the lookup request.\n"
     ]
    }
   ],
   "source": [
    "empty_post = {}\n",
    "postLookup(empty_post)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5a380f-8a84-4346-95e6-9f9551a13ed7",
   "metadata": {},
   "source": [
    "### Generate some lookup values in a Kafka topic\n",
    "\n",
    "Create a number of events that can be consumed by Druid into a lookup map.\n",
    "\n",
    "Send one event to a new topic, \"example-lookup-airportsize\". It will contain a binary key and value representing a key and value in the lookup map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae673c4f-6316-4389-a10d-970a384798c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaProducer\n",
    "\n",
    "kafka_producer = KafkaProducer(bootstrap_servers=kafka_host)\n",
    "kafka_topic = \"example-lookup-airportsize\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c886bc2-4b72-4a86-ada5-afd91ab03481",
   "metadata": {},
   "source": [
    "### Create a lookup table\n",
    "\n",
    "In this section, you will create a `lookup_post` object that can then be posted to the API as JSON. It will contain:\n",
    "\n",
    "* The [tier](https://druid.apache.org/docs/latest/querying/lookups#dynamic-configuration) to which the table belongs - this will be the standard '__default'.\n",
    "* A name for the table.\n",
    "* A definition of the lookup itself. In this case, a \"kafka\" type lookup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26606ff3-d706-4057-af61-02c570373ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted the lookup request.\n",
      "{\"loaded\":false,\"pendingNodes\":[\"172.19.0.10:8082\",\"172.19.0.11:8083\"]} | [ 1 ]      \r"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "\nTimeout waiting for Druid to load the example-flights-airportsizes lookup to __default tier. Run the cell again.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 22\u001b[0m\n\u001b[1;32m      8\u001b[0m lookup_post \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      9\u001b[0m   lookup_tier: {\n\u001b[1;32m     10\u001b[0m     lookup_name: {\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m   }\n\u001b[1;32m     19\u001b[0m }\n\u001b[1;32m     21\u001b[0m postLookup(lookup_post)\n\u001b[0;32m---> 22\u001b[0m \u001b[43mwaitForLookup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlookup_tier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 35\u001b[0m, in \u001b[0;36mwaitForLookup\u001b[0;34m(tier, name, ticsMax)\u001b[0m\n\u001b[1;32m     32\u001b[0m     x \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(apicall) \n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (tics \u001b[38;5;241m==\u001b[39m ticsMax):\n\u001b[0;32m---> 35\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTimeout waiting for Druid to load the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m lookup to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtier\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tier. Run the cell again.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSuccess. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m lookup in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtier\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tier is fully available.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mException\u001b[0m: \nTimeout waiting for Druid to load the example-flights-airportsizes lookup to __default tier. Run the cell again."
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "lookup_post_version = datetime.now().strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "lookup_tier = \"__default\"\n",
    "lookup_name = \"example-flights-airportsizes\"\n",
    "lookup_type = \"kafka\"\n",
    "\n",
    "lookup_post = {\n",
    "  lookup_tier: {\n",
    "    lookup_name: {\n",
    "      \"version\": lookup_post_version,  \n",
    "      \"lookupExtractorFactory\": {\n",
    "      \"type\": lookup_type,\n",
    "          \"kafkaTopic\":kafka_topic,\n",
    "          \"kafkaProperties\":{ \"bootstrap.servers\":kafka_host}\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "postLookup(lookup_post)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac503df-53d4-4526-a334-e334e4ebf93b",
   "metadata": {},
   "source": [
    "With the lookup posted and defined in Druid, run the next cell to send an event into the Kafka topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61c329fd-a918-4a99-ac02-e1fb8bcb8bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"loaded\":false,\"pendingNodes\":[\"172.19.0.10:8082\",\"172.19.0.11:8083\"]} | [ 1 ]      \r"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "\nTimeout waiting for Druid to load the example-flights-airportsizes lookup to __default tier. Run the cell again.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m kafka_producer\u001b[38;5;241m.\u001b[39msend(kafka_topic, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCLE\u001b[39m\u001b[38;5;124m\"\u001b[39m, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMedium Airport\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m kafka_producer\u001b[38;5;241m.\u001b[39mflush()\n\u001b[0;32m----> 4\u001b[0m \u001b[43mwaitForLookup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlookup_tier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 35\u001b[0m, in \u001b[0;36mwaitForLookup\u001b[0;34m(tier, name, ticsMax)\u001b[0m\n\u001b[1;32m     32\u001b[0m     x \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(apicall) \n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (tics \u001b[38;5;241m==\u001b[39m ticsMax):\n\u001b[0;32m---> 35\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTimeout waiting for Druid to load the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m lookup to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtier\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tier. Run the cell again.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSuccess. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m lookup in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtier\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tier is fully available.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mException\u001b[0m: \nTimeout waiting for Druid to load the example-flights-airportsizes lookup to __default tier. Run the cell again."
     ]
    }
   ],
   "source": [
    "kafka_producer.send(kafka_topic, key=b\"CLE\", value=b\"Medium Airport\")\n",
    "kafka_producer.flush()\n",
    "\n",
    "waitForLookup(lookup_tier, lookup_name, 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44738d6d-cec2-40ad-aaba-998c758c63f4",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "\n",
    "Run the following cell to remove the XXX used in this notebook from the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8082b545-ba7f-4ede-bb6e-2a6dd62ba0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this for batch ingested tables\n",
    "\n",
    "druid.datasources.drop(f\"{table_name}\")\n",
    "\n",
    "# Use this when doing streaming with the data generator\n",
    "\n",
    "print(f\"Stop streaming generator: [{requests.post(f'{datagen_host}/stop/{datagen_job}','')}]\")\n",
    "print(f'Pause streaming ingestion: [{requests.post(f\"{druid_host}/druid/indexer/v1/supervisor/{datagen_topic}/suspend\",\"\")}]')\n",
    "\n",
    "print(f'Shutting down running tasks ...')\n",
    "\n",
    "tasks = druid.tasks.tasks(state='running', table=table_name)\n",
    "while len(tasks)>0:\n",
    "    for task in tasks:\n",
    "        print(f\"...stopping task [{task['id']}]\")\n",
    "        druid.tasks.shut_down_task(task['id'])\n",
    "    tasks = druid.tasks.tasks(state='running', table=table_name)\n",
    "\n",
    "print(f'Reset offsets for re-runnability: [{requests.post(f\"{druid_host}/druid/indexer/v1/supervisor/{datagen_topic}/reset\",\"\")}]')\n",
    "print(f'Terminate streaming ingestion: [{requests.post(f\"{druid_host}/druid/indexer/v1/supervisor/{datagen_topic}/terminate\",\"\")}]')\n",
    "print(f\"Drop datasource: [{druid.datasources.drop(table_name)}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b8d5fe-ba85-4b5b-9669-0dd47dfbccd1",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "* You learned this\n",
    "* Remember this\n",
    "\n",
    "## Learn more\n",
    "\n",
    "* Try this out on your own data\n",
    "* Solve for problem X that is't covered here\n",
    "* Read docs pages\n",
    "* Watch or read something cool from the community\n",
    "* Do some exploratory stuff on your own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4d3362-b1a4-47a4-a782-9773c216b3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are some useful code elements that you can re-use.\n",
    "\n",
    "# When just wanting to display some SQL results\n",
    "sql = f'''SELECT * FROM \"{table_name}\" LIMIT 5'''\n",
    "display.sql(sql)\n",
    "\n",
    "# When ingesting data and wanting to describe the schema\n",
    "display.run_task(sql)\n",
    "sql_client.wait_until_ready('{table_name}')\n",
    "display.table('{table_name}')\n",
    "\n",
    "# When you want to show the native version of a SQL statement\n",
    "print(json.dumps(json.loads(sql_client.explain_sql(sql)['PLAN']), indent=2))\n",
    "\n",
    "# When you want a simple plot\n",
    "df = pd.DataFrame(sql_client.sql(sql))\n",
    "df.plot(x='x-axis', y='y-axis', marker='o')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.gca().get_legend().remove()\n",
    "plt.show()\n",
    "\n",
    "# When you want to add some query context parameters\n",
    "req = sql_client.sql_request(sql)\n",
    "req.add_context(\"useApproximateTopN\", \"false\")\n",
    "resp = sql_client.sql_query(req)\n",
    "\n",
    "# When you want to compare two different sets of results\n",
    "df3 = df1.compare(df2, keep_equal=True)\n",
    "df3\n",
    "\n",
    "# When you want to see some messages from a Kafka topic\n",
    "from kafka import KafkaConsumer\n",
    "\n",
    "consumer = KafkaConsumer(bootstrap_servers=kafka_host)\n",
    "consumer.subscribe(topics=datagen_topic)\n",
    "count = 0\n",
    "for message in consumer:\n",
    "    count += 1\n",
    "    if count == 5:\n",
    "        break\n",
    "    print (\"%d:%d: v=%s\" % (message.partition,\n",
    "                            message.offset,\n",
    "                            message.value))\n",
    "consumer.unsubscribe()"
   ]
  }
 ],
 "metadata": {
  "execution": {
   "allow_errors": true,
   "timeout": 300
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

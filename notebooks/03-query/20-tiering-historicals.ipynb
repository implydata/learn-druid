{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cb3b009-ebde-4d56-9d59-a028d66d8309",
   "metadata": {},
   "source": [
    "# Load table data to different historical tiers using retention rules\n",
    "<!--\n",
    "  ~ Licensed to the Apache Software Foundation (ASF) under one\n",
    "  ~ or more contributor license agreements.  See the NOTICE file\n",
    "  ~ distributed with this work for additional information\n",
    "  ~ regarding copyright ownership.  The ASF licenses this file\n",
    "  ~ to you under the Apache License, Version 2.0 (the\n",
    "  ~ \"License\"); you may not use this file except in compliance\n",
    "  ~ with the License.  You may obtain a copy of the License at\n",
    "  ~\n",
    "  ~   http://www.apache.org/licenses/LICENSE-2.0\n",
    "  ~\n",
    "  ~ Unless required by applicable law or agreed to in writing,\n",
    "  ~ software distributed under the License is distributed on an\n",
    "  ~ \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n",
    "  ~ KIND, either express or implied.  See the License for the\n",
    "  ~ specific language governing permissions and limitations\n",
    "  ~ under the License.\n",
    "  -->\n",
    "\n",
    "[Service tiering](https://druid.apache.org/docs/latest/operations/mixed-workloads#service-tiering) provides administrators the ability to provide cluster resources suited to different performance and storage requirements, such as isolating heavy queries involving complex subqueries or large result from high priority, interactive queries.\n",
    "\n",
    "This tutorial demonstrates how to work with [historical tiering](https://druid.apache.org/docs/latest/operations/mixed-workloads#historical-tiering) to load particular ages of data onto different processes. In turn, this causes queries to execute on different services depending on the period of time covered by a query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdbf6ad-ca7b-40f5-8ca3-1070f4a3ee42",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "This tutorial works with Druid 30.0.0 or later.\n",
    "\n",
    "This tutorial requires a deployment of Druid with multiple historicals, and presumes that the additional tier is called \"slow\".\n",
    "\n",
    "Launch this tutorial and all prerequisites using the `druid-jupyter-tiered-hist` profile of the Docker Compose file for Jupyter-based Druid tutorials to create a cluster with an additional historical.\n",
    "\n",
    "For more information, see the Learn Druid repository [readme](https://github.com/implydata/learn-druid)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5007a243-b81a-4601-8f57-5b14940abbff",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "\n",
    "The following cells set up the notebook and learning environment ready for use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b769122-c5a4-404e-9ef8-9c0ebd97695a",
   "metadata": {},
   "source": [
    "### Set up a connection to Apache Druid\n",
    "\n",
    "Run the next cell to set up the Druid Python client's connection to Apache Druid.\n",
    "\n",
    "If successful, the Druid version number will be shown in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c1ec783b-df3f-4168-9be2-cdc6ad3e33c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening a connection to http://router:8888.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'30.0.0'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import druidapi\n",
    "import os\n",
    "\n",
    "druid_headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "if 'DRUID_HOST' not in os.environ.keys():\n",
    "    druid_host=f\"http://localhost:8888\"\n",
    "else:\n",
    "    druid_host=f\"http://{os.environ['DRUID_HOST']}:8888\"\n",
    "\n",
    "print(f\"Opening a connection to {druid_host}.\")\n",
    "druid = druidapi.jupyter_client(druid_host)\n",
    "display = druid.display\n",
    "sql_client = druid.sql\n",
    "status_client = druid.status\n",
    "\n",
    "status_client.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3d6b39-6551-4b2a-bdfb-9606aa92c853",
   "metadata": {},
   "source": [
    "### Import additional modules\n",
    "\n",
    "Run the following cell to import additional Python modules that you will use to make direct calls to some APIs in Druid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "dc4c2524-0eba-4bc6-84ed-da3a25aa5fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472589e4-1026-4b3b-bb79-eedabb2b44c4",
   "metadata": {},
   "source": [
    "## Create a table using batch ingestion\n",
    "\n",
    "In this section, you will create a table that contains data spanning a few years using batch ingestion.\n",
    "\n",
    "Run the next cell to bring in the initial data. Only a subset of the columns that are available in the example dataset will be ingested.\n",
    "\n",
    "When completed, you'll see a description of the final table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f52a94fb-d2e4-403f-ab10-84d3af7bf2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data, status:[SUCCESS]: 100%|██████████| 100.0/100.0 [00:07<00:00, 14.05it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"druid\"><table>\n",
       "<tr><th>Position</th><th>Name</th><th>Type</th></tr>\n",
       "<tr><td>1</td><td>__time</td><td>TIMESTAMP</td></tr>\n",
       "<tr><td>2</td><td>isRobot</td><td>VARCHAR</td></tr>\n",
       "<tr><td>3</td><td>channel</td><td>VARCHAR</td></tr>\n",
       "<tr><td>4</td><td>isUnpatrolled</td><td>VARCHAR</td></tr>\n",
       "<tr><td>5</td><td>page</td><td>VARCHAR</td></tr>\n",
       "<tr><td>6</td><td>comment</td><td>VARCHAR</td></tr>\n",
       "<tr><td>7</td><td>commentLength</td><td>BIGINT</td></tr>\n",
       "<tr><td>8</td><td>user</td><td>VARCHAR</td></tr>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table_name = 'example-wikipedia-tiering'\n",
    "\n",
    "sql='''\n",
    "REPLACE INTO \"''' + table_name + '''\" OVERWRITE ALL\n",
    "WITH \"ext\" AS (\n",
    "  SELECT *\n",
    "  FROM TABLE(\n",
    "    EXTERN(\n",
    "      '{\"type\":\"http\",\"uris\":[\"https://druid.apache.org/data/wikipedia.json.gz\"]}',\n",
    "      '{\"type\":\"json\"}'\n",
    "    )\n",
    "  ) EXTEND (\"isRobot\" VARCHAR, \"channel\" VARCHAR, \"timestamp\" VARCHAR, \"flags\" VARCHAR, \"isUnpatrolled\" VARCHAR, \"page\" VARCHAR, \"diffUrl\" VARCHAR, \"added\" BIGINT, \"comment\" VARCHAR, \"commentLength\" BIGINT, \"isNew\" VARCHAR, \"isMinor\" VARCHAR, \"delta\" BIGINT, \"isAnonymous\" VARCHAR, \"user\" VARCHAR, \"deltaBucket\" BIGINT, \"deleted\" BIGINT, \"namespace\" VARCHAR, \"cityName\" VARCHAR, \"countryName\" VARCHAR, \"regionIsoCode\" VARCHAR, \"metroCode\" BIGINT, \"countryIsoCode\" VARCHAR, \"regionName\" VARCHAR)\n",
    ")\n",
    "SELECT\n",
    "  TIME_PARSE(\"timestamp\") AS \"__time\",\n",
    "  \"isRobot\",\n",
    "  \"channel\",\n",
    "  \"isUnpatrolled\",\n",
    "  \"page\",\n",
    "  \"comment\",\n",
    "  \"commentLength\",\n",
    "  \"user\"\n",
    "FROM \"ext\"\n",
    "PARTITIONED BY DAY\n",
    "'''\n",
    "\n",
    "display.run_task(sql)\n",
    "sql_client.wait_until_ready(table_name)\n",
    "display.table(table_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fc3ab3-548d-4b50-bf90-4d80c1c60020",
   "metadata": {},
   "source": [
    "Run another ingestion from the wikipedia example dataset.\n",
    "\n",
    "INSERT is used to append data instead of REPLACE INTO, and [TIME_PARSE](https://druid.apache.org/docs/latest/querying/sql-scalar#date-and-time-functions) function has been used to shift the timestamp back by a year. This will create some \"fake\" data in the table that is a year old.\n",
    "\n",
    "Run the next cell to append some data to ingest your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "dbd90368-7da5-4d2c-94b2-1bac4001291a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data, status:[SUCCESS]: 100%|██████████| 100.0/100.0 [00:07<00:00, 14.03it/s]\n"
     ]
    }
   ],
   "source": [
    "sql='''\n",
    "INSERT INTO \"''' + table_name + '''\"\n",
    "WITH \"ext\" AS (\n",
    "  SELECT *\n",
    "  FROM TABLE(\n",
    "    EXTERN(\n",
    "      '{\"type\":\"http\",\"uris\":[\"https://druid.apache.org/data/wikipedia.json.gz\"]}',\n",
    "      '{\"type\":\"json\"}'\n",
    "    )\n",
    "  ) EXTEND (\"isRobot\" VARCHAR, \"channel\" VARCHAR, \"timestamp\" VARCHAR, \"flags\" VARCHAR, \"isUnpatrolled\" VARCHAR, \"page\" VARCHAR, \"diffUrl\" VARCHAR, \"added\" BIGINT, \"comment\" VARCHAR, \"commentLength\" BIGINT, \"isNew\" VARCHAR, \"isMinor\" VARCHAR, \"delta\" BIGINT, \"isAnonymous\" VARCHAR, \"user\" VARCHAR, \"deltaBucket\" BIGINT, \"deleted\" BIGINT, \"namespace\" VARCHAR, \"cityName\" VARCHAR, \"countryName\" VARCHAR, \"regionIsoCode\" VARCHAR, \"metroCode\" BIGINT, \"countryIsoCode\" VARCHAR, \"regionName\" VARCHAR)\n",
    ")\n",
    "SELECT\n",
    "  TIME_SHIFT(TIME_PARSE(\"timestamp\"), 'P1Y', -1) AS \"__time\",\n",
    "  \"isRobot\",\n",
    "  \"channel\",\n",
    "  \"isUnpatrolled\",\n",
    "  \"page\",\n",
    "  \"comment\",\n",
    "  \"commentLength\",\n",
    "  \"user\"\n",
    "FROM \"ext\"\n",
    "PARTITIONED BY DAY\n",
    "'''\n",
    "\n",
    "display.run_task(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6c9b88-837d-4c80-a28d-36184ba63355",
   "metadata": {},
   "source": [
    "## Separate older data onto a different tier\n",
    "\n",
    "In this section you will change the retention [load rules](https://druid.apache.org/docs/latest/operations/rule-configuration#load-rules) for the table so that some of the data is loaded onto a different tier.\n",
    "\n",
    "You will see how a query like the one above will be parallelised across and executed on different processes depending on where the data has been cached."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0ad47b-c6f9-45af-9278-4c81a1aaf6bc",
   "metadata": {},
   "source": [
    "### Generate some statistics about the data\n",
    "\n",
    "Take a look at the distribution of your table across the years by running the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e77af65e-3596-454e-8dfb-5056546813dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"druid\"><table>\n",
       "<tr><th>year</th><th>rows</th><th>users</th><th>average_comment</th></tr>\n",
       "<tr><td>2014</td><td>24433</td><td>7923</td><td>62</td></tr>\n",
       "<tr><td>2015</td><td>24433</td><td>7923</td><td>62</td></tr>\n",
       "<tr><td>2016</td><td>24433</td><td>7923</td><td>62</td></tr>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sql = f'''\n",
    "SELECT\n",
    "  TIME_EXTRACT(__time, 'YEAR') AS \"year\",\n",
    "  COUNT(*) AS \"rows\",\n",
    "  COUNT(DISTINCT \"user\") AS \"users\",\n",
    "  CAST(AVG(\"commentLength\") AS INTEGER) AS \"average_comment\"\n",
    "FROM \"{table_name}\"\n",
    "GROUP BY 1\n",
    "'''\n",
    "\n",
    "display.sql(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3e3d61-46bc-4046-94f5-dc20a0c9a7b8",
   "metadata": {},
   "source": [
    "### Inspect the servers and current configuration\n",
    "\n",
    "Use a query against the servers system table to see what historicals are available, and the tiers that they are assigned to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "67de46b9-391d-41ed-9704-d3935d14fdf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"druid\"><table>\n",
       "<tr><th>server</th><th>tier</th><th>curr_size</th></tr>\n",
       "<tr><td>172.19.0.11:8083</td><td>slow</td><td>10484204</td></tr>\n",
       "<tr><td>172.19.0.10:8083</td><td>_default_tier</td><td>10484204</td></tr>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sql='''\n",
    "SELECT server, tier, curr_size\n",
    "FROM \"sys\".\"servers\"\n",
    "WHERE \"server_type\" = 'historical'\n",
    "'''\n",
    "\n",
    "display.sql(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3ac6bc-69ea-4d15-ace6-0063951caea0",
   "metadata": {},
   "source": [
    "You will see that there are multiple historical servers.\n",
    "\n",
    "- One server has the default of \"_default_tier\".\n",
    "- The \"_default_tier\" currently contains all the data for the table.\n",
    "- An additional tier currently contains no data.\n",
    "\n",
    "Use the coordinator API to inspect and manage retention rules.\n",
    "\n",
    "Run the following cell to call the API and get a list of all rules that currently apply. You will store these in a variable for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "69ac786f-f27c-46ca-9f85-25b77798efd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"_default\": [\n",
      "    {\n",
      "      \"tieredReplicants\": {\n",
      "        \"_default_tier\": 2\n",
      "      },\n",
      "      \"useDefaultTierForNull\": true,\n",
      "      \"type\": \"loadForever\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(json.loads(requests.get(f'{druid_host}/druid/coordinator/v1/rules').text), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e597661-e6a8-4a3b-98cc-c1fc7e3bafa4",
   "metadata": {},
   "source": [
    "In a clean deployment, only one set of rules is configured, called `_default`.\n",
    "\n",
    "By default, the `_default` rules set contains only one rule - a [load forever](https://druid.apache.org/docs/latest/operations/rule-configuration#forever-load-rule) rule (`loadForever`) with a replication factor (`tieredReplicants`) of 2 across servers in the `_default_tier`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f976ca5-24c3-4062-a77d-72b535aaf1e3",
   "metadata": {},
   "source": [
    "### Load data onto the additional tier\n",
    "\n",
    "Since we have two tiers of historicals, create a load rule loads all data onto the additional tier.\n",
    "\n",
    "Run the next cell to create a JSON object for us to store the amended rule in, and to send that to the Coordinator API.\n",
    "\n",
    "- Historicals in the `slow` tier have been added to the replication rules (`tieredReplicants`).\n",
    "- The `slow` tier will receive one replica of the data.\n",
    "- The `_default_tier` tier will receive one replica of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e22d9c43-838c-43e5-b885-fb980d9465fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retention_rules = [\n",
    "  {\n",
    "    \"type\": \"loadForever\",\n",
    "    \"tieredReplicants\": {\n",
    "      \"_default_tier\": 1,\n",
    "      \"slow\": 1\n",
    "    }\n",
    "  }\n",
    "]\n",
    "\n",
    "requests.post(f\"{druid_host}/druid/coordinator/v1/rules/{table_name}\", json.dumps(retention_rules), headers=druid_headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19819547-f069-4bfc-be2a-4f28509a0bf1",
   "metadata": {},
   "source": [
    "Inspect the current distribution of data by running a query against the system tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c6c9f83e-eb2d-40c0-b35a-c765bf781634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"druid\"><table>\n",
       "<tr><th>server</th><th>tier</th><th>start</th><th>end</th><th>Count</th><th>rows</th></tr>\n",
       "<tr><td>172.19.0.10:8083</td><td>_default_tier</td><td>2014-06-27T00:00:00.000Z</td><td>2014-06-28T00:00:00.000Z</td><td>3</td><td>48866</td></tr>\n",
       "<tr><td>172.19.0.11:8083</td><td>slow</td><td>2014-06-27T00:00:00.000Z</td><td>2014-06-28T00:00:00.000Z</td><td>3</td><td>48866</td></tr>\n",
       "<tr><td>172.19.0.10:8083</td><td>_default_tier</td><td>2015-06-27T00:00:00.000Z</td><td>2015-06-28T00:00:00.000Z</td><td>3</td><td>48866</td></tr>\n",
       "<tr><td>172.19.0.11:8083</td><td>slow</td><td>2015-06-27T00:00:00.000Z</td><td>2015-06-28T00:00:00.000Z</td><td>3</td><td>48866</td></tr>\n",
       "<tr><td>172.19.0.10:8083</td><td>_default_tier</td><td>2016-06-27T00:00:00.000Z</td><td>2016-06-28T00:00:00.000Z</td><td>2</td><td>48866</td></tr>\n",
       "<tr><td>172.19.0.11:8083</td><td>slow</td><td>2016-06-27T00:00:00.000Z</td><td>2016-06-28T00:00:00.000Z</td><td>2</td><td>48866</td></tr>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sql='''\n",
    "SELECT\n",
    "  a.\"server\",\n",
    "  b.\"tier\",\n",
    "  c.\"start\",\n",
    "  c.\"end\",\n",
    "  COUNT(*) AS \"Count\",\n",
    "  SUM(c.\"num_rows\") AS \"rows\"\n",
    "FROM \"sys\".\"server_segments\" a\n",
    "LEFT JOIN \"sys\".\"servers\" b ON a.\"server\" = b.\"server\"\n",
    "LEFT JOIN \"sys\".\"segments\" c ON a.\"segment_id\" = c.\"segment_id\"\n",
    "GROUP BY 1, 2, 3, 4\n",
    "ORDER BY \"start\", \"tier\"\n",
    "'''\n",
    "\n",
    "display.sql(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9165b5-034f-4189-9d7b-7b6349b085ab",
   "metadata": {},
   "source": [
    "For each year in the table, once rules have been applied to your deployment, there will be a replica on the `slow` tier and an additional replica on the `_default_tier` tier.\n",
    "\n",
    "Run the cell above until you see this applied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb149f58-afcc-4972-a667-197351f8a8a5",
   "metadata": {},
   "source": [
    "### Split table data across tiers according to age\n",
    "\n",
    "Using [period load rules](https://druid.apache.org/docs/latest/operations/rule-configuration/#period-load-rule) your table can be split across different historical tiers according to the timestamp.\n",
    "\n",
    "Review the following default retention rule:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6d5b78c0-22a0-4738-907c-10ac53996d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retention_rules = [\n",
    "  {\n",
    "    \"type\": \"loadByPeriod\",\n",
    "    \"period\": \"P1Y\",\n",
    "    \"tieredReplicants\": {\n",
    "      \"_default_tier\": 1,\n",
    "      \"slow\": 1\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"type\": \"loadForever\",\n",
    "    \"tieredReplicants\": {\n",
    "      \"slow\": 1\n",
    "    }\n",
    "  }\n",
    "]\n",
    "\n",
    "requests.post(f\"{druid_host}/druid/coordinator/v1/rules/_default\", json.dumps(retention_rules), headers=druid_headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0923ca-d869-4f11-a523-cbdaa3e049ef",
   "metadata": {},
   "source": [
    "There are now two rules.\n",
    "\n",
    "- `loadByPeriod`, covering the last year, which sets one cached replica on both the `_default_tier` and `slow` tiers.\n",
    "- `loadForever`, requesting all data to be cached on the `slow` tier.\n",
    "\n",
    "Run the following cell to see the resulting distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "39e021c4-4619-4ef3-b4b9-41d3ab56dfcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"druid\"><table>\n",
       "<tr><th>server</th><th>tier</th><th>start</th><th>end</th><th>Count</th><th>rows</th></tr>\n",
       "<tr><td>172.19.0.11:8083</td><td>slow</td><td>2014-06-27T00:00:00.000Z</td><td>2014-06-28T00:00:00.000Z</td><td>3</td><td>48866</td></tr>\n",
       "<tr><td>172.19.0.11:8083</td><td>slow</td><td>2015-06-27T00:00:00.000Z</td><td>2015-06-28T00:00:00.000Z</td><td>3</td><td>48866</td></tr>\n",
       "<tr><td>172.19.0.11:8083</td><td>slow</td><td>2016-06-27T00:00:00.000Z</td><td>2016-06-28T00:00:00.000Z</td><td>2</td><td>48866</td></tr>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sql='''\n",
    "SELECT\n",
    "  a.\"server\",\n",
    "  b.\"tier\",\n",
    "  c.\"start\",\n",
    "  c.\"end\",\n",
    "  COUNT(*) AS \"Count\",\n",
    "  SUM(c.\"num_rows\") AS \"rows\"\n",
    "FROM \"sys\".\"server_segments\" a\n",
    "LEFT JOIN \"sys\".\"servers\" b ON a.\"server\" = b.\"server\"\n",
    "LEFT JOIN \"sys\".\"segments\" c ON a.\"segment_id\" = c.\"segment_id\"\n",
    "GROUP BY 1, 2, 3, 4\n",
    "ORDER BY \"start\", \"tier\"\n",
    "'''\n",
    "\n",
    "display.sql(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd75180-c2f2-4c07-8d7c-9a0925c8b5b7",
   "metadata": {},
   "source": [
    "Remembering that rules are processed in order, and that our data is _older_ than one year, only the `slow` tier receives any data.\n",
    "\n",
    "Run the cell below to ingest some data for the current year. The TIME_EXTRACT function is used to fake data for this year by calculating what the shift should be between the timetamp of the example data and today's date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c3ccb4e5-0845-4985-a427-1dc1381afa7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data, status:[SUCCESS]: 100%|██████████| 100.0/100.0 [00:07<00:00, 14.01it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"druid\"><table>\n",
       "<tr><th>Position</th><th>Name</th><th>Type</th></tr>\n",
       "<tr><td>1</td><td>__time</td><td>TIMESTAMP</td></tr>\n",
       "<tr><td>2</td><td>isRobot</td><td>VARCHAR</td></tr>\n",
       "<tr><td>3</td><td>channel</td><td>VARCHAR</td></tr>\n",
       "<tr><td>4</td><td>isUnpatrolled</td><td>VARCHAR</td></tr>\n",
       "<tr><td>5</td><td>page</td><td>VARCHAR</td></tr>\n",
       "<tr><td>6</td><td>comment</td><td>VARCHAR</td></tr>\n",
       "<tr><td>7</td><td>commentLength</td><td>BIGINT</td></tr>\n",
       "<tr><td>8</td><td>user</td><td>VARCHAR</td></tr>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sql='''\n",
    "INSERT INTO \"''' + table_name + '''\"\n",
    "WITH \"ext\" AS (\n",
    "  SELECT *\n",
    "  FROM TABLE(\n",
    "    EXTERN(\n",
    "      '{\"type\":\"http\",\"uris\":[\"https://druid.apache.org/data/wikipedia.json.gz\"]}',\n",
    "      '{\"type\":\"json\"}'\n",
    "    )\n",
    "  ) EXTEND (\"isRobot\" VARCHAR, \"channel\" VARCHAR, \"timestamp\" VARCHAR, \"flags\" VARCHAR, \"isUnpatrolled\" VARCHAR, \"page\" VARCHAR, \"diffUrl\" VARCHAR, \"added\" BIGINT, \"comment\" VARCHAR, \"commentLength\" BIGINT, \"isNew\" VARCHAR, \"isMinor\" VARCHAR, \"delta\" BIGINT, \"isAnonymous\" VARCHAR, \"user\" VARCHAR, \"deltaBucket\" BIGINT, \"deleted\" BIGINT, \"namespace\" VARCHAR, \"cityName\" VARCHAR, \"countryName\" VARCHAR, \"regionIsoCode\" VARCHAR, \"metroCode\" BIGINT, \"countryIsoCode\" VARCHAR, \"regionName\" VARCHAR)\n",
    ")\n",
    "SELECT\n",
    "  TIME_SHIFT(TIME_PARSE(\"timestamp\"), 'P1Y', (TIME_EXTRACT(CURRENT_TIMESTAMP,'YEAR') - TIME_EXTRACT(TIME_PARSE(\"timestamp\"),'YEAR'))) AS \"__time\",\n",
    "  \"isRobot\",\n",
    "  \"channel\",\n",
    "  \"isUnpatrolled\",\n",
    "  \"page\",\n",
    "  \"comment\",\n",
    "  \"commentLength\",\n",
    "  \"user\"\n",
    "FROM \"ext\"\n",
    "PARTITIONED BY DAY\n",
    "'''\n",
    "\n",
    "display.run_task(sql)\n",
    "sql_client.wait_until_ready(table_name)\n",
    "display.table(table_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe59e689-d792-4e64-87ca-b6232cb6a862",
   "metadata": {},
   "source": [
    "Run the next cell to see how the default load rule has now been applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d7d14936-bd3a-43fe-b064-e4161ba8cc6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"druid\"><table>\n",
       "<tr><th>server</th><th>tier</th><th>start</th><th>end</th><th>Count</th><th>rows</th></tr>\n",
       "<tr><td>172.19.0.11:8083</td><td>slow</td><td>2014-06-27T00:00:00.000Z</td><td>2014-06-28T00:00:00.000Z</td><td>3</td><td>48866</td></tr>\n",
       "<tr><td>172.19.0.11:8083</td><td>slow</td><td>2015-06-27T00:00:00.000Z</td><td>2015-06-28T00:00:00.000Z</td><td>3</td><td>48866</td></tr>\n",
       "<tr><td>172.19.0.11:8083</td><td>slow</td><td>2016-06-27T00:00:00.000Z</td><td>2016-06-28T00:00:00.000Z</td><td>2</td><td>48866</td></tr>\n",
       "<tr><td>172.19.0.10:8083</td><td>_default_tier</td><td>2024-06-27T00:00:00.000Z</td><td>2024-06-28T00:00:00.000Z</td><td>1</td><td>24433</td></tr>\n",
       "<tr><td>172.19.0.11:8083</td><td>slow</td><td>2024-06-27T00:00:00.000Z</td><td>2024-06-28T00:00:00.000Z</td><td>1</td><td>24433</td></tr>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sql='''\n",
    "SELECT\n",
    "  a.\"server\",\n",
    "  b.\"tier\",\n",
    "  c.\"start\",\n",
    "  c.\"end\",\n",
    "  COUNT(*) AS \"Count\",\n",
    "  SUM(c.\"num_rows\") AS \"rows\"\n",
    "FROM \"sys\".\"server_segments\" a\n",
    "LEFT JOIN \"sys\".\"servers\" b ON a.\"server\" = b.\"server\"\n",
    "LEFT JOIN \"sys\".\"segments\" c ON a.\"segment_id\" = c.\"segment_id\"\n",
    "GROUP BY 1, 2, 3, 4\n",
    "ORDER BY \"start\", \"tier\"\n",
    "'''\n",
    "\n",
    "display.sql(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44738d6d-cec2-40ad-aaba-998c758c63f4",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "\n",
    "Run the following cell to remove the table used in this notebook from the database and delete your additional ruleset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8082b545-ba7f-4ede-bb6e-2a6dd62ba0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drop table: [None]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Drop table: [{druid.datasources.drop(table_name)}]\")\n",
    "retention_rules = []\n",
    "requests.post(f\"{druid_host}/druid/coordinator/v1/rules/{table_name}\", json.dumps(retention_rules), headers=druid_headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b8d5fe-ba85-4b5b-9669-0dd47dfbccd1",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "* You learned this\n",
    "* Remember this\n",
    "\n",
    "## Learn more\n",
    "\n",
    "* Try this out on your own data\n",
    "* Solve for problem X that is't covered here\n",
    "* Read docs pages\n",
    "* Watch or read something cool from the community\n",
    "* Do some exploratory stuff on your own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4d3362-b1a4-47a4-a782-9773c216b3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are some useful code elements that you can re-use.\n",
    "\n",
    "# When just wanting to display some SQL results\n",
    "sql = f'''SELECT * FROM \"{table_name}\" LIMIT 5'''\n",
    "display.sql(sql)\n",
    "\n",
    "# When ingesting data and wanting to describe the schema\n",
    "display.run_task(sql)\n",
    "sql_client.wait_until_ready('{table_name}')\n",
    "display.table('{table_name}')\n",
    "\n",
    "# When you want to show the native version of a SQL statement\n",
    "print(json.dumps(json.loads(sql_client.explain_sql(sql)['PLAN']), indent=2))\n",
    "\n",
    "# When you want a simple plot\n",
    "df = pd.DataFrame(sql_client.sql(sql))\n",
    "df.plot(x='x-axis', y='y-axis', marker='o')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.gca().get_legend().remove()\n",
    "plt.show()\n",
    "\n",
    "# When you want to add some query context parameters\n",
    "req = sql_client.sql_request(sql)\n",
    "req.add_context(\"useApproximateTopN\", \"false\")\n",
    "resp = sql_client.sql_query(req)\n",
    "\n",
    "# When you want to compare two different sets of results\n",
    "df3 = df1.compare(df2, keep_equal=True)\n",
    "df3\n",
    "\n",
    "# When you want to see some messages from a Kafka topic\n",
    "from kafka import KafkaConsumer\n",
    "\n",
    "consumer = KafkaConsumer(bootstrap_servers=kafka_host)\n",
    "consumer.subscribe(topics=datagen_topic)\n",
    "count = 0\n",
    "for message in consumer:\n",
    "    count += 1\n",
    "    if count == 5:\n",
    "        break\n",
    "    print (\"%d:%d: v=%s\" % (message.partition,\n",
    "                            message.offset,\n",
    "                            message.value))\n",
    "consumer.unsubscribe()"
   ]
  }
 ],
 "metadata": {
  "execution": {
   "allow_errors": true,
   "timeout": 300
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

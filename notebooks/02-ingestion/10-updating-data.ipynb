{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cb3b009-ebde-4d56-9d59-a028d66d8309",
   "metadata": {},
   "source": [
    "# Handling updates and upserts in Druid \n",
    "<!--\n",
    "  ~ Licensed to the Apache Software Foundation (ASF) under one\n",
    "  ~ or more contributor license agreements.  See the NOTICE file\n",
    "  ~ distributed with this work for additional information\n",
    "  ~ regarding copyright ownership.  The ASF licenses this file\n",
    "  ~ to you under the Apache License, Version 2.0 (the\n",
    "  ~ \"License\"); you may not use this file except in compliance\n",
    "  ~ with the License.  You may obtain a copy of the License at\n",
    "  ~\n",
    "  ~   http://www.apache.org/licenses/LICENSE-2.0\n",
    "  ~\n",
    "  ~ Unless required by applicable law or agreed to in writing,\n",
    "  ~ software distributed under the License is distributed on an\n",
    "  ~ \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n",
    "  ~ KIND, either express or implied.  See the License for the\n",
    "  ~ specific language governing permissions and limitations\n",
    "  ~ under the License.\n",
    "  -->\n",
    "\n",
    "Druid ingests data in batch or real-time and as a result, it builds immutable segment files which are published to Deep Storage. The key word here is _immutable_, meaning that once they're created, the segment files cannot change. So how do you go about updating data?\n",
    "\n",
    "The answer is that segments need to be rebuilt and republished. This tutorial demonstrates how to work with REPLACE SQL to execute data updates. \n",
    "\n",
    "In this tutorial you perform the following tasks:\n",
    "\n",
    "- Ingest some data with some relevant amount of history.\n",
    "- Update specific rows.\n",
    "- Delete rows.\n",
    "- Replace a whole timeframe of data with a new set of data.\n",
    "- Perform upserts from a change data set that includes updates to existing rows and new rows.\n",
    "- Replace the history of events for one entity in a multi-entity dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdbf6ad-ca7b-40f5-8ca3-1070f4a3ee42",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "This tutorial works with Druid 28.0.0 or later.\n",
    "\n",
    "#### Run with Docker\n",
    "\n",
    "\n",
    "Launch this tutorial and all prerequisites using the `druid-jupyter` profile of the Docker Compose file for Jupyter-based Druid tutorials. For more information, see the Learn Druid repository [readme](https://github.com/implydata/learn-druid).\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5007a243-b81a-4601-8f57-5b14940abbff",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "\n",
    "The following cells set up the notebook and learning environment ready for use.\n",
    "\n",
    "### Set up and connect to the learning environment\n",
    "\n",
    "Run the next cell to set up the Druid Python client's connection to Apache Druid.\n",
    "\n",
    "If successful, the Druid version number will be shown in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ec783b-df3f-4168-9be2-cdc6ad3e33c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import druidapi\n",
    "import os\n",
    "import json\n",
    "\n",
    "if 'DRUID_HOST' not in os.environ.keys():\n",
    "    druid_host=f\"http://localhost:8888\"\n",
    "else:\n",
    "    druid_host=f\"http://{os.environ['DRUID_HOST']}:8888\"\n",
    "    \n",
    "print(f\"Opening a connection to {druid_host}.\")\n",
    "druid = druidapi.jupyter_client(druid_host)\n",
    "\n",
    "\n",
    "# Datagen client \n",
    "datagen = druidapi.rest.DruidRestClient(\"http://datagen:9999\")\n",
    "\n",
    "\n",
    "display = druid.display\n",
    "sql_client = druid.sql\n",
    "status_client = druid.status\n",
    "\n",
    "status_client.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472589e4-1026-4b3b-bb79-eedabb2b44c4",
   "metadata": {},
   "source": [
    "### Load History\n",
    "\n",
    "Druid stores data in immutable segment files. Data updates come in two forms:\n",
    "\n",
    "- Rewriting existing segment files with the changes applied.\n",
    "- Creation of segment files that overlay small portions of a larger time chunk.\n",
    "\n",
    "Run the following cells to create a table called `example-flights-updates` which holds 30 days of `flights` data. The \"departuretime\" column is mapped to Druid __time field. In the resulting table, invididual rows are uniquely identified by __time, airline and flight\\_ number.\n",
    "When completed, you'll see a description of the final table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52a94fb-d2e4-403f-ab10-84d3af7bf2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql='''\n",
    "REPLACE INTO \"example-flights-updates\" OVERWRITE ALL\n",
    "WITH \"ext\" AS (SELECT *\n",
    "FROM TABLE(\n",
    "  EXTERN(\n",
    "    '{\"type\":\"http\",\"uris\":[\"https://static.imply.io/example-data/flight_on_time/flights/On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2005_11.csv.zip\"]}',\n",
    "    '{\"type\":\"csv\",\"findColumnsFromHeader\":true}'\n",
    "  )\n",
    ") EXTEND (\"depaturetime\" VARCHAR, \"arrivalime\" VARCHAR, \"Year\" BIGINT, \"Quarter\" BIGINT, \"Month\" BIGINT, \"DayofMonth\" BIGINT, \"DayOfWeek\" BIGINT, \"FlightDate\" VARCHAR, \"Reporting_Airline\" VARCHAR, \"DOT_ID_Reporting_Airline\" BIGINT, \"IATA_CODE_Reporting_Airline\" VARCHAR, \"Tail_Number\" VARCHAR, \"Flight_Number_Reporting_Airline\" BIGINT, \"OriginAirportID\" BIGINT, \"OriginAirportSeqID\" BIGINT, \"OriginCityMarketID\" BIGINT, \"Origin\" VARCHAR, \"OriginCityName\" VARCHAR, \"OriginState\" VARCHAR, \"OriginStateFips\" BIGINT, \"OriginStateName\" VARCHAR, \"OriginWac\" BIGINT, \"DestAirportID\" BIGINT, \"DestAirportSeqID\" BIGINT, \"DestCityMarketID\" BIGINT, \"Dest\" VARCHAR, \"DestCityName\" VARCHAR, \"DestState\" VARCHAR, \"DestStateFips\" BIGINT, \"DestStateName\" VARCHAR, \"DestWac\" BIGINT, \"CRSDepTime\" BIGINT, \"DepTime\" BIGINT, \"DepDelay\" BIGINT, \"DepDelayMinutes\" BIGINT, \"DepDel15\" BIGINT, \"DepartureDelayGroups\" BIGINT, \"DepTimeBlk\" VARCHAR, \"TaxiOut\" BIGINT, \"WheelsOff\" BIGINT, \"WheelsOn\" BIGINT, \"TaxiIn\" BIGINT, \"CRSArrTime\" BIGINT, \"ArrTime\" BIGINT, \"ArrDelay\" BIGINT, \"ArrDelayMinutes\" BIGINT, \"ArrDel15\" BIGINT, \"ArrivalDelayGroups\" BIGINT, \"ArrTimeBlk\" VARCHAR, \"Cancelled\" BIGINT, \"CancellationCode\" VARCHAR, \"Diverted\" BIGINT, \"CRSElapsedTime\" BIGINT, \"ActualElapsedTime\" BIGINT, \"AirTime\" BIGINT, \"Flights\" BIGINT, \"Distance\" BIGINT, \"DistanceGroup\" BIGINT, \"CarrierDelay\" BIGINT, \"WeatherDelay\" BIGINT, \"NASDelay\" BIGINT, \"SecurityDelay\" BIGINT, \"LateAircraftDelay\" BIGINT, \"FirstDepTime\" VARCHAR, \"TotalAddGTime\" VARCHAR, \"LongestAddGTime\" VARCHAR, \"DivAirportLandings\" VARCHAR, \"DivReachedDest\" VARCHAR, \"DivActualElapsedTime\" VARCHAR, \"DivArrDelay\" VARCHAR, \"DivDistance\" VARCHAR, \"Div1Airport\" VARCHAR, \"Div1AirportID\" VARCHAR, \"Div1AirportSeqID\" VARCHAR, \"Div1WheelsOn\" VARCHAR, \"Div1TotalGTime\" VARCHAR, \"Div1LongestGTime\" VARCHAR, \"Div1WheelsOff\" VARCHAR, \"Div1TailNum\" VARCHAR, \"Div2Airport\" VARCHAR, \"Div2AirportID\" VARCHAR, \"Div2AirportSeqID\" VARCHAR, \"Div2WheelsOn\" VARCHAR, \"Div2TotalGTime\" VARCHAR, \"Div2LongestGTime\" VARCHAR, \"Div2WheelsOff\" VARCHAR, \"Div2TailNum\" VARCHAR, \"Div3Airport\" VARCHAR, \"Div3AirportID\" VARCHAR, \"Div3AirportSeqID\" VARCHAR, \"Div3WheelsOn\" VARCHAR, \"Div3TotalGTime\" VARCHAR, \"Div3LongestGTime\" VARCHAR, \"Div3WheelsOff\" VARCHAR, \"Div3TailNum\" VARCHAR, \"Div4Airport\" VARCHAR, \"Div4AirportID\" VARCHAR, \"Div4AirportSeqID\" VARCHAR, \"Div4WheelsOn\" VARCHAR, \"Div4TotalGTime\" VARCHAR, \"Div4LongestGTime\" VARCHAR, \"Div4WheelsOff\" VARCHAR, \"Div4TailNum\" VARCHAR, \"Div5Airport\" VARCHAR, \"Div5AirportID\" VARCHAR, \"Div5AirportSeqID\" VARCHAR, \"Div5WheelsOn\" VARCHAR, \"Div5TotalGTime\" VARCHAR, \"Div5LongestGTime\" VARCHAR, \"Div5WheelsOff\" VARCHAR, \"Div5TailNum\" VARCHAR, \"Unnamed: 109\" VARCHAR))\n",
    "SELECT\n",
    "  TIME_PARSE(\"depaturetime\") AS \"__time\",\n",
    "  \"IATA_CODE_Reporting_Airline\" as \"airline\", \n",
    "  \"Flight_Number_Reporting_Airline\" as \"flight_number\", \n",
    "  \"arrivalime\" as \"arrival_time\", \n",
    "  \"Tail_Number\" as \"tail_number\", \n",
    "  \"Origin\" as \"origin\", \n",
    "  \"Dest\" as \"destination\", \n",
    "  \"DepDelayMinutes\" as \"departure_delay\"\n",
    "FROM \"ext\"\n",
    "WHERE \"Cancelled\" = 0  -- only interested in flown flights\n",
    "PARTITIONED BY DAY'''\n",
    "\n",
    "display.run_task(sql)\n",
    "sql_client.wait_until_ready('example-flights-updates')\n",
    "display.table('example-flights-updates')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadd930f-0180-4101-9573-7984ead62390",
   "metadata": {},
   "source": [
    "Run the following cell to see the the segment stats. Columns like num_rows are populated asynchronously in the metadata, so you may need to run this a few times to see the correct values for each of the segments.\n",
    "\n",
    "Given that the data is partitioned by day, you will see 30 1-day segments spanning 11/1/2005 to 11/30/2005."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdca497-0100-43f6-a64a-1e938fcb09c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql='''\n",
    "SELECT \"start\", \"end\", \"num_rows\", \"version\" \n",
    "FROM sys.segments \n",
    "WHERE datasource='example-flights-updates'\n",
    "'''\n",
    "display.sql(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2457fc9-aca7-4bca-b596-d915460a1d42",
   "metadata": {},
   "source": [
    "## Updating a single row\n",
    "\n",
    "\n",
    "You can update a single row in a table by using a [REPLACE statement](https://druid.apache.org/docs/28.0.0/multi-stage-query/reference#replace) that combines the existing rows with the changed row, resulting in a new set of rows that cover a small portion of time. The new segment that is created overshadows that portion of time when the time interval is queried.  \n",
    "\n",
    "As an example, update a row that has an incorrect tail_number because the aircraft was replaced.\n",
    "- The flight was incorrectly recorded as using the plane with Tail_Number 'N063AA' \n",
    "- There was a change of aircraft to Tail_Number 'N073AA' \n",
    "- The unique key in this table involves __time (departure time), airline and flight_number\n",
    "- The flight in question was the `AA` `513` flight that left at `2005-11-01T00:15:00.000Z`\n",
    "\n",
    "In a traditional SQL database you would do something like:\n",
    "```\n",
    "UPDATE \"example-flights-updates\"\n",
    "    SET \"tail_number\"='N073AA'\n",
    "  WHERE \"__time\"= '2005-11-01T00:15:00.000Z' \n",
    "        AND \"airline\"='AA' \n",
    "        AND \"flight_number\"=513\n",
    "```\n",
    "\n",
    "Run the following cell to look at that row as it exists in the table before an update:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d5f243-63f2-4edb-9a29-2c80ec42f723",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sql='''\n",
    "SELECT * FROM \"example-flights-updates\" \n",
    "WHERE \"__time\"='2005-11-01T00:15:00.000Z' \n",
    "  AND \"airline\"='AA' \n",
    "  AND \"flight_number\"=513\n",
    "'''\n",
    "display.sql(sql)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13e5c40-89d1-4f3d-b8f9-f5e3e1f33a3e",
   "metadata": {},
   "source": [
    "### Update rows using partial segment overshadowing\n",
    "\n",
    "At query time Druid selects the segments that are relevant to a query. Typically this involves a set of segment files that cover regular time intervals based on the segment granularity that was ingested. Up to this point you have ingested the data into DAY partitions. \n",
    "\n",
    "One of the lesser known capabilities in Druid is the ability to overlay segments of different granularity. This capability allows you to change the contents of a portion of the timeline within a particular segment partition by adding a smaller time granularity segment on top of existing data. \n",
    "\n",
    "![](assets/partial-overshadow.png)\n",
    "\n",
    "The functionality is general is called [overshadowing](https://druid.apache.org/docs/28.0.0/ingestion/tasks#overshadowing-between-segments). In this case we are taking advantage of partial segment overshadowing at query time which uses the existing segment for most of the data and the new one for a small portion of the time interval. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b2aff3-b485-42ac-868a-a75ce893deb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The smallest slice of a time chunk that can be updated is 1 second\n",
    "# Druid's segment overlapping and versioning strategy requires that the new segment include\n",
    "# all of the rows in the time interval where a row is going to be changed. \n",
    "# This SQL shows what other rows occur in the same second? \n",
    "sql='''\n",
    "SELECT * FROM \"example-flights-updates\" \n",
    "WHERE TIME_IN_INTERVAL(\"__time\", '2005-11-01T00:15:00.000Z/PT1S') \n",
    "'''\n",
    "display.sql(sql)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c99123-3092-4102-b3f4-20bb804227cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#before updating anything, get a count and a checksum so we can validate data consistency\n",
    "sql='''\n",
    "SELECT count(*) \"total_flights_day\", SUM(\"departure_delay\") \"total_time_lost\" \n",
    "FROM \"example-flights-updates\"\n",
    "WHERE TIME_IN_INTERVAL(\"__time\", '2005-11-01T00:00:00.000Z/P1D')  -- totals for the day\n",
    "'''\n",
    "display.sql(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97796d23-da51-4aca-ae28-5a8fbedb7ed0",
   "metadata": {},
   "source": [
    "For this update, given that it is a single row, you can get away with creating a segment that only covers 1 second of time.\n",
    "Like you can see above, besides the record that needs updating, there is only one other record during that second that we will need to include. \n",
    "\n",
    "A few important points on how to use this method:\n",
    "\n",
    "- Use a SQL REPLACE statement that overwrites the minimum timeframe where this update occurs. That's `00:15:00 <= t < 00:15:01` of `2005-11-01` of the timeline as expressed in the OVERWRITE WHERE clause in the SQL below. \n",
    "- The SELECT portion of the request, must read the data for the target timeframe, including the row that is being updated and any other rows that exist in the same timeframe. In the SQL below it is: `WHERE TIME_IN_INTERVAL(\"__time\", '2005-11-01T00:15:00.000Z/PT1S')`\n",
    "- The `PARTITIONED BY` clause must fit exactly within the overwrite timeframe. The SQL below uses `FLOOR(__time TO SECOND)` which creates second level partitions.\n",
    "- The update columns can be expressed as conditional CASE expressions that change the value of the column when the key columns match the target update (rows). The expression used in the SQL below is:\n",
    "  \n",
    "  ```\n",
    "      CASE \n",
    "         WHEN \"__time\"= '2005-11-01 00:15:00.000Z' \n",
    "                AND \"airline\"='AA' \n",
    "                AND \"flight_number\"=513 \n",
    "         THEN 'N073AA' \n",
    "      ELSE \n",
    "         \"tail_number\" \n",
    "      END as \"tail_number\"\n",
    "  ```\n",
    "  This expression will specify the value `N073AA` as the tail number for the `AA 513` flight that left at `2005-11-01 00:15:00`. For all other rows, it leaves the values as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6258a644-6da2-4597-844e-505f6afb3246",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = '''\n",
    "REPLACE INTO \"example-flights-updates\" \n",
    "   OVERWRITE -- only overwrite the second for the __time of the updated row\n",
    "       WHERE \"__time\" >= TIMESTAMP'2005-11-01 00:15:00' AND \"__time\" < TIMESTAMP'2005-11-01 00:15:01'\n",
    "SELECT \n",
    "   \"__time\", \n",
    "   \"airline\", \n",
    "   \"flight_number\",  \n",
    "   \"arrival_time\", \n",
    "      \n",
    "      -- the following expression only makes the change to the row with the correct key\n",
    "      -- any columns being updated require a similar expression\n",
    "      CASE \n",
    "         WHEN \"__time\"= '2005-11-01 00:15:00.000Z' \n",
    "                AND \"airline\"='AA' \n",
    "                AND \"flight_number\"=513 \n",
    "         THEN 'N073AA' \n",
    "      ELSE \n",
    "         \"tail_number\" \n",
    "      END as \"tail_number\",\n",
    "    \n",
    "  \"origin\", \n",
    "  \"destination\", \n",
    "  \"departure_delay\"\n",
    "FROM \"example-flights-updates\" \n",
    "WHERE TIME_IN_INTERVAL(\"__time\", '2005-11-01T00:15:00.000Z/PT1S')\n",
    "PARTITIONED BY FLOOR(__time TO SECOND) \n",
    "'''\n",
    "display.run_task(sql)\n",
    "sql_client.wait_until_ready('example-flights-updates')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181d7ae7-be67-4e2b-8d1a-7a89dcc11f2b",
   "metadata": {},
   "source": [
    "Redoing the query for the time interval we should still see two rows and the updated tail_number on the American Airlines flight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafea4c2-5e17-42e2-94df-10e74c3858f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql='''\n",
    "SELECT * FROM \"example-flights-updates\" \n",
    "WHERE TIME_IN_INTERVAL(\"__time\", '2005-11-01T00:15:00.000Z/PT1M') \n",
    "'''\n",
    "display.sql(sql)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2e9b6a-85fc-4675-9330-ab2c9c0c77ff",
   "metadata": {},
   "source": [
    "Take a look at the segments for the whole day at this point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3941a7aa-7f45-460b-a7ce-a96d9900506d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how did the segments change for the 1 day timeframe for 11/01/2005 <= t < 11/02/2005\n",
    "sql='''\n",
    "SELECT \"start\", \"end\", \"num_rows\", \"version\" \n",
    "FROM sys.segments \n",
    "WHERE datasource='example-flights-updates'\n",
    "  AND \"start\" >=  '2005-11-01T00:00:00.000Z' AND \"start\" < '2005-11-02T00:00:00.000Z'\n",
    "'''\n",
    "display.sql(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56bd13a-54b7-43f7-a2a9-6cb30e58f93b",
   "metadata": {},
   "source": [
    "The full day segment with a timeframe of `2005-11-01 00:00:00` <= t < `2005-11-02 00:00:00` is still the same immutable file it was before the update. But now there is a second segment with only 2 rows that covers the one second timeframe `2005-11-01 00:15:00` <= t < `2005-11-01 00:15:01`. At query time, since the new segment has a newer version, it overshadows any rows within the larger segment that fall into that second.\n",
    "\n",
    "Check that the count and checksum still match with the following SQL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80c75aa-7b52-4e39-a49f-e8010105f535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify the checksums\n",
    "sql='''\n",
    "SELECT count(*) \"total_flights_day\", SUM(\"departure_delay\") \"total_time_lost\" \n",
    "FROM \"example-flights-updates\"\n",
    "WHERE TIME_IN_INTERVAL(\"__time\", '2005-11-01T00:00:00.000Z/P1D')  -- totals for the day\n",
    "'''\n",
    "display.sql(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be817277-254e-44f4-97d2-356418540888",
   "metadata": {},
   "source": [
    "## Delete rows using partial segment overshadowing\n",
    "Multiple layers of segment overlays can occur. The newest version is always used.\n",
    "\n",
    "To delete the same row in a traditional SQL database, you would use:\n",
    "   ```\n",
    "   DELETE \"example-flights-updates\"\n",
    "   WHERE \"__time\"= '2005-11-01 00:15:00.000Z' \n",
    "     AND \"airline\"='AA' \n",
    "     AND \"flight_number\"=513\n",
    "   ```\n",
    "Run the following cell to achieve the same result by using a REPLACE statement. Again it is important to:\n",
    "- Use a SQL REPLACE statement that overwrites the minimum timeframe where this delete occurs. That's `00:15:00 <= t < 00:15:01` of `2005-11-01` of the timeline as expressed in the OVERWRITE WHERE clause in the SQL below. \n",
    "- The SELECT portion of the request, must read the data for the target timeframe including all the rows that that exist in that time interval except for the row(s) being deleted. In the SQL below that is:\n",
    "   ```\n",
    "   WHERE TIME_IN_INTERVAL(\"__time\", '2005-11-01T00:15:00.000Z/PT1S')\n",
    "         AND\n",
    "            NOT (                                        -- exclude row for the key\n",
    "                \"__time\"= '2005-11-01 00:15:00.000Z' \n",
    "                AND \"airline\"='AA' \n",
    "                AND \"flight_number\"=513\n",
    "                 )\n",
    "   ```\n",
    "- The `PARTITIONED BY` clause must fit exactly within the overwrite timeframe. The SQL below uses `FLOOR(__time TO SECOND)` which creates partitions that are one second long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b0c200-b17c-47de-a1d0-d83f0d454320",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = '''\n",
    "REPLACE INTO \"example-flights-updates\" \n",
    "   OVERWRITE                                       -- only overwrite the second for the __time of the the deleted row\n",
    "       WHERE \"__time\" >= TIMESTAMP'2005-11-01 00:15:00' AND \"__time\" < TIMESTAMP'2005-11-01 00:15:01'\n",
    "SELECT \n",
    "   \"__time\", \n",
    "   \"airline\", \n",
    "   \"flight_number\",  \n",
    "   \"arrival_time\", \n",
    "   \"tail_number\",    \n",
    "   \"origin\", \n",
    "   \"destination\", \n",
    "   \"departure_delay\"\n",
    "FROM \"example-flights-updates\" \n",
    "WHERE TIME_IN_INTERVAL(\"__time\", '2005-11-01T00:15:00.000Z/PT1S')\n",
    "  AND NOT ( \"__time\"= '2005-11-01 00:15:00.000Z'                   -- exclude the row being deleted\n",
    "                AND \"airline\"='AA' \n",
    "                AND \"flight_number\"=513 )\n",
    "PARTITIONED BY FLOOR(__time TO SECOND) \n",
    "'''\n",
    "display.run_task(sql)\n",
    "sql_client.wait_until_ready('example-flights-updates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c04dcc-45c7-49c7-bae7-314bd900b12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how did the segments change for the 1 day timeframe for 11/01/2005 <= t < 11/02/2005\n",
    "sql='''\n",
    "SELECT \"start\", \"end\", \"num_rows\", \"version\" \n",
    "FROM sys.segments \n",
    "WHERE datasource='example-flights-updates'\n",
    "  AND \"start\" >=  '2005-11-01T00:00:00.000Z' AND \"start\" < '2005-11-02T00:00:00.000Z'\n",
    "'''\n",
    "display.sql(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b668f50e-9817-4a3b-b6c6-36fc533c591d",
   "metadata": {},
   "source": [
    "The 1-second segment was overshadowed by the new 1-second segment. Examine the version you see here and compare it to the version in the prior 1-second segment shown earlier in the notebook. The version is a newer timestamp and the new segment completely covers the time-frame of the prior segment. Since the prior segment is overshadowed and no longer needed, Druid removes it.\n",
    "\n",
    "Notice that the new 1-second segment only contains one row, if you query the checksums now, you can see the change:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f725acc-ba37-4e49-b0e1-b9f156bd4087",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql='''\n",
    "SELECT count(*) \"total_flights_day\", SUM(\"departure_delay\") \"total_time_lost\" \n",
    "FROM \"example-flights-updates\"\n",
    "WHERE TIME_IN_INTERVAL(\"__time\", '2005-11-01T00:00:00.000Z/P1D')  -- totals for the day\n",
    "'''\n",
    "display.sql(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce16895-ecac-45f0-b643-8b90fe9f5766",
   "metadata": {},
   "source": [
    "## Replacing a complete time interval with new data \n",
    "Sometimes a full set of the data is delivered as an updated batch file that covers a known timeframe. For example, a whole day.\n",
    "\n",
    "Since the flight sample data we loaded does not come with a change set, the following cell simulates one by writing a day's worth of flights to another table while introducing a change to the `departure_delay` values. The generated table only includes the data for the day `2005-11-02` as expressed in the following SQL `WHERE TIME_IN_INTERVAL(\"__time\", '2005-11-02T00:00:00.000Z/P1D')`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04796f6f-6665-43c0-b5cb-1c4c7412bc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql='''\n",
    "REPLACE INTO \"example-changeset-day\" \n",
    "   OVERWRITE ALL\n",
    "SELECT\n",
    "  \"__time\", \n",
    "  \"airline\", \n",
    "  \"flight_number\", \n",
    "  \"arrival_time\", \n",
    "  \"tail_number\", \n",
    "  \"origin\", \n",
    "  \"destination\", \n",
    "   0 \"departure_delay\" -- setting all delays to zero to show the change\n",
    "FROM \"example-flights-updates\"\n",
    "WHERE TIME_IN_INTERVAL(\"__time\", '2005-11-02T00:00:00.000Z/P1D') \n",
    "PARTITIONED BY DAY    -- replacing a whole day so partition by day\n",
    "'''\n",
    "display.run_task(sql)\n",
    "sql_client.wait_until_ready('example-changeset-day')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eedcfc7-78fe-466d-86e9-41a16abff3b8",
   "metadata": {},
   "source": [
    "Calculate a checksum for `2005-11-02` with the following SQL to see the data before the change:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b2e068-fb8c-4789-9db8-775421e49c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql='''\n",
    "SELECT count(*) \"total_flights_day\", SUM(\"departure_delay\") \"total_time_lost\" \n",
    "FROM \"example-flights-updates\"\n",
    "WHERE TIME_IN_INTERVAL(\"__time\", '2005-11-02T00:00:00.000Z/P1D')  -- totals for the day\n",
    "'''\n",
    "display.sql(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3207c9-e5a9-4891-87e2-1aceaed35787",
   "metadata": {},
   "source": [
    "The next cell ingests the generated data overwriting the existing data for `2005-11-02`.\n",
    "In traditional SQL this would be:\n",
    "   ```\n",
    "   DELETE \"example-flights-updates\"\n",
    "    WHERE \"__time\" >= '2005-11-02T00:00:00.000Z' AND \"__time\" < '2005-11-03T00:00:00.000Z'\n",
    "   ;\n",
    "\n",
    "   INSERT INTO \"example-flights-updates\"\n",
    "     SELECT * FROM \"example-changeset-day\"\n",
    "   ;\n",
    "   ```\n",
    "\n",
    "We can achieve this in Druid with a SQL REPLACE by:\n",
    "- Use a REPLACE statement that overwrites the whole day. In the SQL below that is:\n",
    "   ```\n",
    "   OVERWRITE \n",
    "   WHERE \"__time\" >= TIMESTAMP'2005-11-02 00:00:00' AND \"__time\" < TIMESTAMP'2005-11-03 00:00:00'\n",
    "   ```\n",
    "- The SELECT portion of the request, just needs to read the data from the changeset table because it only contains data for the day being replaced. \n",
    "- Since it is meant to replace the whole day `PARTITIONED BY` clause uses `DAY`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de5b28c-ff91-4c9f-a32a-e2d5ca071ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql='''\n",
    "REPLACE INTO \"example-flights-updates\" \n",
    "   OVERWRITE \n",
    "   WHERE \"__time\" >= TIMESTAMP'2005-11-02 00:00:00' AND \"__time\" < TIMESTAMP'2005-11-03 00:00:00'\n",
    "SELECT\n",
    "  \"__time\", \n",
    "  \"airline\", \n",
    "  \"flight_number\", \n",
    "  \"arrival_time\", \n",
    "  \"tail_number\", \n",
    "  \"origin\", \n",
    "  \"destination\", \n",
    "  \"departure_delay\"\n",
    "FROM \"example-changeset-day\"\n",
    "PARTITIONED BY DAY    -- replacing a whole day so partition by day\n",
    "'''\n",
    "display.run_task(sql)\n",
    "sql_client.wait_until_ready('example-flights-updates')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d866b9-1c7a-495f-9192-62369ebb8a53",
   "metadata": {},
   "source": [
    "Take a look at the segments for that day now with the following sql.\n",
    "Notice that the version has changed and the number of rows are still the same because the change set had the same number of rows.\n",
    "\n",
    "The ingestion fully replaced the segment for that day with the new set of data, deleting the old rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62d1234-7cf4-4974-b657-e962e76c6d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql='''\n",
    "SELECT \"start\", \"end\", \"num_rows\", \"version\" \n",
    "FROM sys.segments \n",
    "WHERE datasource='example-flights-updates'\n",
    "  AND \"start\" >=  '2005-11-02T00:00:00.000Z' AND \"start\" < '2005-11-03T00:00:00.000Z'\n",
    "'''\n",
    "display.sql(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5c9bc2-332c-47ee-acab-034ac1fdefe8",
   "metadata": {},
   "source": [
    "Calculate the checksum again and notice that while the row count is still consistent, the checksum `total_time_lost` has changed to reflect the changes in the `departure_delay`, it's zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43559227-12cf-4232-9c30-7df50f6e8829",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql='''\n",
    "SELECT count(*) \"total_flights_day\", SUM(\"departure_delay\") \"total_time_lost\" \n",
    "FROM \"example-flights-updates\"\n",
    "WHERE TIME_IN_INTERVAL(\"__time\", '2005-11-02T00:00:00.000Z/P1D')  -- totals for the day\n",
    "'''\n",
    "display.sql(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ac8799-c59a-4376-9eed-c3a44b46d053",
   "metadata": {},
   "source": [
    "## UPSERTs \n",
    "\n",
    "A more common change data set is one that doesn't have all the rows in the time interval, instead it only includes changed rows and new rows but it does not contain all rows for the time period, just the change. \n",
    "In traditional SQL this would be done using a MERGE like:\n",
    "   ```\n",
    "   MERGE INTO \"example-flights-updates\" t\n",
    "   USING \"example-upsert-changeset\" s\n",
    "      ON t.\"__time\"=s.\"__time\"\n",
    "     AND t.\"airline\"=s.\"airline\"\n",
    "     AND s.\"flight_number\"=t.\"flight_number\" \n",
    "   WHEN MATCHED THEN\n",
    "        UPDATE SET \"origin\"=s.\"origin\", \"destination\"=s.\"destination\", \"departure_delay\"=s.\"departure_delay\"\n",
    "   WHEN NOT MATCHED THEN\n",
    "        INSERT (  \"__time\",  \"airline\",  \"flight_number\",  \"origin\",  \"destination\", \"departure_delay\")\n",
    "        VALUES (s.\"__time\",s.\"airline\",s.\"flight_number\",s.\"origin\",s.\"destination\",s.\"departure_delay\")\n",
    "   ```\n",
    "In Druid you can do the same operation using a REPLACE statement.\n",
    "\n",
    "Create another change set that contains some updated rows and some new rows with the following SQL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d4488d-ccbd-4cac-b62f-384fb440c17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql='''\n",
    "REPLACE INTO \"example-upsert-changeset\" \n",
    "   OVERWRITE ALL\n",
    "SELECT\n",
    "  \"__time\", \n",
    "  \"airline\", \n",
    "  \n",
    "   -- create some new rows by changing one of the key values only in rows with flight_number > 4900 \n",
    "  CASE       \n",
    "     WHEN \"flight_number\">4900 THEN 5000 \n",
    "     ELSE \"flight_number\" \n",
    "  END as \"flight_number\", \n",
    "  \n",
    "  \"arrival_time\", \n",
    "  \"tail_number\", \n",
    "  \"origin\", \n",
    "  \"destination\", \n",
    "  \n",
    "  -- set departure_delay to zero so we can see updates with the checksum \n",
    "  0 \"departure_delay\"                              \n",
    "  \n",
    "FROM \"example-flights-updates\"\n",
    "WHERE TIME_IN_INTERVAL(\"__time\", '2005-11-03T00:00:00.000Z/P1D') \n",
    "\n",
    "  -- only use some of the rows for the day to demonstrate upsert\n",
    "  AND \"airline\"='TZ'                                   \n",
    "PARTITIONED BY DAY                                     \n",
    "'''\n",
    "display.run_task(sql)\n",
    "sql_client.wait_until_ready('example-upsert-changeset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a7955e-261c-4129-918b-38a45582e189",
   "metadata": {},
   "source": [
    "Take a look at the data before applying the changes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019570ea-5c6f-49cd-8fe1-b7f649b35ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql='''\n",
    "SELECT min(\"flight_number\") as \"min_flight\", max(\"flight_number\") as \"max_flight\", \n",
    "       count(*) \"total_flights_day\", \n",
    "       SUM(\"departure_delay\") \"total_time_lost\" \n",
    "FROM \"example-flights-updates\"\n",
    "WHERE TIME_IN_INTERVAL(\"__time\", '2005-11-03T00:00:00.000Z/P1D')  \n",
    "  AND \"airline\"='TZ'\n",
    "'''\n",
    "display.sql(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dbbca0-2aa5-4301-bf7d-795baf09458b",
   "metadata": {},
   "source": [
    "You can achieve an UPSERT operation using a REPLACE statement, you can use the existing data combined with the new data to replace the portion of time affected by the updated and new rows :\n",
    "- Given that the change set spans a day use a REPLACE statement that overwrites that day. In the SQL below that is:\n",
    "\n",
    "   ```\n",
    "   OVERWRITE \n",
    "   WHERE \"__time\" >= TIMESTAMP'2005-11-03 00:00:00' AND \"__time\" < TIMESTAMP'2005-11-04 00:00:00'\n",
    "   ```\n",
    "   \n",
    "- The SELECT portion of the request uses a FULL OUTER JOIN between the target table and the change set so that we can include existing rows which are not modified, update rows that exist in both tables and insert new rows. In the following SQL that is:\n",
    "\n",
    "   ```\n",
    "   FROM \"example-flights-updates\" t \n",
    "     FULL OUTER JOIN\n",
    "       \"example-upsert-changeset\" s\n",
    "     ON t.\"__time\"=s.\"__time\"\n",
    "    AND t.\"airline\"=s.\"airline\"\n",
    "    AND t.\"flight_number\"=s.\"flight_number\" \n",
    "   ```\n",
    "   \n",
    "- The column expressions for the key columns in the SELECT use a COALESCE to select the existing value for updated or untouched rows, and the new value for new rows being inserted:\n",
    "\n",
    "   ```\n",
    "   COALESCE(t.\"__time\", s.\"__time\") as \"__time\",\n",
    "   COALESCE(t.\"airline\", s.\"airline\") as \"airline\",\n",
    "   COALESCE(t.\"flight_number\", s.\"flight_number\") as \"flight_number\"\n",
    "   ```\n",
    "   \n",
    "- Given that the values for non-key columns in either the target or source tables could be NULL and we need to address values for new rows, updated rows and untouched rows use a CASE expression that checks for these conditions and applies the correct value:\n",
    "\n",
    "   ```\n",
    "   CASE WHEN (t.\"__time\" IS NULL OR t.\"__time\"=s.\"__time\") -- new  and update rows get new value\n",
    "             THEN s.\"arrival_time\"                       \n",
    "        ELSE t.\"arrival_time                               -- existing untouched rows, get existing value   \n",
    "   END AS \"arrival_time\" \n",
    "   ```\n",
    "   \n",
    "- Only include the rows from the existing table that fall into the update timeframe and new rows where the join results in NULL for the `t.\"__time\"` column:\n",
    "\n",
    "   ```\n",
    "   WHERE t.\"__time\" IS NULL OR TIME_IN_INTERVAL(t.\"__time\", '2005-11-03T00:00:00.000Z/P1D')  \n",
    "   ```\n",
    "- Since it the operation is covering a whole day use PARTITIONED BY clause uses DAY.\n",
    "- Set the context parameter to use `joinAlgorithm=sortMerge`.\n",
    "\n",
    "Run the following SQL to apply the upsert operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62394515-4baa-4766-b57f-6b071c6ddadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql='''\n",
    "REPLACE INTO \"example-flights-updates\" \n",
    "   OVERWRITE \n",
    "   WHERE \"__time\" >= TIMESTAMP'2005-11-03 00:00:00' AND \"__time\" < TIMESTAMP'2005-11-04 00:00:00'\n",
    "SELECT\n",
    "  COALESCE(t.\"__time\", s.\"__time\") as \"__time\",\n",
    "  COALESCE(t.\"airline\", s.\"airline\") as \"airline\",\n",
    "  COALESCE(t.\"flight_number\", s.\"flight_number\") as \"flight_number\",\n",
    "  CASE WHEN (t.\"__time\" IS NULL OR t.\"__time\" = s.\"__time\") THEN s.\"arrival_time\"       \n",
    "       ELSE t.\"arrival_time\"                                  \n",
    "  END AS \"arrival_time\",\n",
    "  CASE WHEN (t.\"__time\" IS NULL OR t.\"__time\" = s.\"__time\") THEN s.\"tail_number\"\n",
    "       ELSE t.\"tail_number\"    \n",
    "  END AS \"tail_number\", \n",
    "  CASE WHEN (t.\"__time\" IS NULL OR t.\"__time\" = s.\"__time\") THEN s.\"origin\"\n",
    "       ELSE t.\"origin\"          \n",
    "  END AS \"origin\", \n",
    "  CASE WHEN (t.\"__time\" IS NULL OR t.\"__time\" = s.\"__time\") THEN s.\"destination\"\n",
    "       ELSE t.\"destination\"     \n",
    "  END AS \"destination\", \n",
    "  CASE WHEN (t.\"__time\" IS NULL OR t.\"__time\" = s.\"__time\") THEN s.\"departure_delay\"\n",
    "       ELSE t.\"departure_delay\" \n",
    "  END AS \"departure_delay\"\n",
    "FROM \"example-flights-updates\" t \n",
    "  FULL OUTER JOIN\n",
    "    \"example-upsert-changeset\" s\n",
    "  ON t.\"__time\"=s.\"__time\"\n",
    "  AND t.\"airline\"=s.\"airline\"\n",
    "  AND t.\"flight_number\"=s.\"flight_number\" \n",
    "WHERE t.\"__time\" IS NULL OR TIME_IN_INTERVAL(t.\"__time\", '2005-11-03T00:00:00.000Z/P1D') \n",
    "PARTITIONED BY DAY    -- replacing a whole day so partition by day\n",
    "'''\n",
    "req = sql_client.sql_request(sql)\n",
    "req.add_context(\"sqlJoinAlgorithm\", 'sortMerge')\n",
    "display.run_task(req)\n",
    "sql_client.wait_until_ready('example-flights-updates')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf24eea-956e-4531-8708-f2e4064757fa",
   "metadata": {},
   "source": [
    "Check the data changes and new rows with the same SQL as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b62872f-9ee6-4ab7-afdc-43d91c522215",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql='''\n",
    "SELECT min(\"flight_number\") as \"min_flight\", max(\"flight_number\") as \"max_flight\", \n",
    "       count(*) \"total_flights_day\", \n",
    "       SUM(\"departure_delay\") \"total_time_lost\" \n",
    "FROM \"example-flights-updates\"\n",
    "WHERE TIME_IN_INTERVAL(\"__time\", '2005-11-03T00:00:00.000Z/P1D')  \n",
    "  AND \"airline\"='TZ'\n",
    "'''\n",
    "display.sql(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9721e4f0-a208-47e0-8dad-da86b36185f7",
   "metadata": {},
   "source": [
    "Notice in the result above that:\n",
    "- there are now 9 new rows\n",
    "- that the `departure_delay` values have been updated producing the `total_time_lost` = 0.\n",
    "\n",
    "Just as a little extra fun:\n",
    "At first the result seems surprising because some of the flights were left as is, the ones with flight numbers between 4901 amd 4999 were replaced with 5000, so those rows would not have been touched. It's an exercise for the student to verify it. I did verify it by checking that the flights in the 9 original unchanged rows all had zero delay values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4078c260-7e34-452d-b234-12d8d19908c1",
   "metadata": {},
   "source": [
    "## Revisionist history update\n",
    "Imagine for example, that you have credit transaction activity data over a years of history and for a period of a few months a person's identity had been stolen. The person worked it all out with the banks and now there is new validated data for what their transactions were. So we need to do an update across a large portion of the timeline, removing the rows for this person and inserting the new ones across the same period of time.\n",
    "\n",
    "Run the following cell to create a change dataset that replaces all history for an airline. \n",
    "\n",
    "This SQL creates a change data set that replaces the history of `airline`=`'TZ'` flights by using the history of flights from `airline` = `'HA'` and just replacing the \"airline\" value with `'TZ'`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb9b1ae-402e-454e-9b78-f5ab161320ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql='''\n",
    "REPLACE INTO \"example-replace-history\" OVERWRITE ALL\n",
    "WITH \"ext\" AS (SELECT *\n",
    "FROM TABLE(\n",
    "  EXTERN(\n",
    "    '{\"type\":\"http\",\"uris\":[\"https://static.imply.io/example-data/flight_on_time/flights/On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2005_11.csv.zip\"]}',\n",
    "    '{\"type\":\"csv\",\"findColumnsFromHeader\":true}'\n",
    "  )\n",
    ") EXTEND (\"depaturetime\" VARCHAR, \"arrivalime\" VARCHAR, \"Year\" BIGINT, \"Quarter\" BIGINT, \"Month\" BIGINT, \"DayofMonth\" BIGINT, \"DayOfWeek\" BIGINT, \"FlightDate\" VARCHAR, \"Reporting_Airline\" VARCHAR, \"DOT_ID_Reporting_Airline\" BIGINT, \"IATA_CODE_Reporting_Airline\" VARCHAR, \"Tail_Number\" VARCHAR, \"Flight_Number_Reporting_Airline\" BIGINT, \"OriginAirportID\" BIGINT, \"OriginAirportSeqID\" BIGINT, \"OriginCityMarketID\" BIGINT, \"Origin\" VARCHAR, \"OriginCityName\" VARCHAR, \"OriginState\" VARCHAR, \"OriginStateFips\" BIGINT, \"OriginStateName\" VARCHAR, \"OriginWac\" BIGINT, \"DestAirportID\" BIGINT, \"DestAirportSeqID\" BIGINT, \"DestCityMarketID\" BIGINT, \"Dest\" VARCHAR, \"DestCityName\" VARCHAR, \"DestState\" VARCHAR, \"DestStateFips\" BIGINT, \"DestStateName\" VARCHAR, \"DestWac\" BIGINT, \"CRSDepTime\" BIGINT, \"DepTime\" BIGINT, \"DepDelay\" BIGINT, \"DepDelayMinutes\" BIGINT, \"DepDel15\" BIGINT, \"DepartureDelayGroups\" BIGINT, \"DepTimeBlk\" VARCHAR, \"TaxiOut\" BIGINT, \"WheelsOff\" BIGINT, \"WheelsOn\" BIGINT, \"TaxiIn\" BIGINT, \"CRSArrTime\" BIGINT, \"ArrTime\" BIGINT, \"ArrDelay\" BIGINT, \"ArrDelayMinutes\" BIGINT, \"ArrDel15\" BIGINT, \"ArrivalDelayGroups\" BIGINT, \"ArrTimeBlk\" VARCHAR, \"Cancelled\" BIGINT, \"CancellationCode\" VARCHAR, \"Diverted\" BIGINT, \"CRSElapsedTime\" BIGINT, \"ActualElapsedTime\" BIGINT, \"AirTime\" BIGINT, \"Flights\" BIGINT, \"Distance\" BIGINT, \"DistanceGroup\" BIGINT, \"CarrierDelay\" BIGINT, \"WeatherDelay\" BIGINT, \"NASDelay\" BIGINT, \"SecurityDelay\" BIGINT, \"LateAircraftDelay\" BIGINT, \"FirstDepTime\" VARCHAR, \"TotalAddGTime\" VARCHAR, \"LongestAddGTime\" VARCHAR, \"DivAirportLandings\" VARCHAR, \"DivReachedDest\" VARCHAR, \"DivActualElapsedTime\" VARCHAR, \"DivArrDelay\" VARCHAR, \"DivDistance\" VARCHAR, \"Div1Airport\" VARCHAR, \"Div1AirportID\" VARCHAR, \"Div1AirportSeqID\" VARCHAR, \"Div1WheelsOn\" VARCHAR, \"Div1TotalGTime\" VARCHAR, \"Div1LongestGTime\" VARCHAR, \"Div1WheelsOff\" VARCHAR, \"Div1TailNum\" VARCHAR, \"Div2Airport\" VARCHAR, \"Div2AirportID\" VARCHAR, \"Div2AirportSeqID\" VARCHAR, \"Div2WheelsOn\" VARCHAR, \"Div2TotalGTime\" VARCHAR, \"Div2LongestGTime\" VARCHAR, \"Div2WheelsOff\" VARCHAR, \"Div2TailNum\" VARCHAR, \"Div3Airport\" VARCHAR, \"Div3AirportID\" VARCHAR, \"Div3AirportSeqID\" VARCHAR, \"Div3WheelsOn\" VARCHAR, \"Div3TotalGTime\" VARCHAR, \"Div3LongestGTime\" VARCHAR, \"Div3WheelsOff\" VARCHAR, \"Div3TailNum\" VARCHAR, \"Div4Airport\" VARCHAR, \"Div4AirportID\" VARCHAR, \"Div4AirportSeqID\" VARCHAR, \"Div4WheelsOn\" VARCHAR, \"Div4TotalGTime\" VARCHAR, \"Div4LongestGTime\" VARCHAR, \"Div4WheelsOff\" VARCHAR, \"Div4TailNum\" VARCHAR, \"Div5Airport\" VARCHAR, \"Div5AirportID\" VARCHAR, \"Div5AirportSeqID\" VARCHAR, \"Div5WheelsOn\" VARCHAR, \"Div5TotalGTime\" VARCHAR, \"Div5LongestGTime\" VARCHAR, \"Div5WheelsOff\" VARCHAR, \"Div5TailNum\" VARCHAR, \"Unnamed: 109\" VARCHAR))\n",
    "SELECT\n",
    "  TIME_PARSE(\"depaturetime\") AS \"__time\",\n",
    "  'TZ' as \"airline\",                                                -- replace airline with TZ\n",
    "  \"Flight_Number_Reporting_Airline\" as \"flight_number\", \n",
    "  \"arrivalime\" as \"arrival_time\",                                \n",
    "  \"Tail_Number\" as \"tail_number\", \n",
    "  \"Origin\" as \"origin\", \n",
    "  \"Dest\" as \"destination\", \n",
    "  \"DepDelayMinutes\" as \"departure_delay\"\n",
    "FROM \"ext\"\n",
    "WHERE \"Cancelled\" = 0  AND \"IATA_CODE_Reporting_Airline\"='HA'       --  filtering for airline = 'HA' flights\n",
    "PARTITIONED BY DAY'''\n",
    "\n",
    "display.run_task(sql)\n",
    "sql_client.wait_until_ready('example-replace-history')\n",
    "display.table('example-replace-history')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88d54c0-ba81-4c7c-b30f-472fa6f3c2b9",
   "metadata": {},
   "source": [
    "Take a look at the change set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f63f8be-b364-475f-89d3-73baf1c130db",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql='''\n",
    "SELECT \"airline\", \n",
    "        min(\"__time\") first_flight, max(\"__time\") last_flight, \n",
    "        min(\"flight_number\") as \"min_flight_n\", max(\"flight_number\") as \"max_flight_n\", \n",
    "       count(*) \"total_flights\", \n",
    "       SUM(\"departure_delay\") \"total_time_lost\" \n",
    "FROM \"example-replace-history\"\n",
    "WHERE  \"airline\" in ('TZ', 'HA')\n",
    "GROUP BY 1\n",
    "'''\n",
    "display.sql(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b728aa-1926-4d6a-a431-71a30fa8ed16",
   "metadata": {},
   "source": [
    "...and check the target table before you change it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f61e2a6-8b76-48a5-a0c6-5ffa2a080149",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql='''\n",
    "SELECT \"airline\", \n",
    "        min(\"__time\") first_flight, max(\"__time\") last_flight, \n",
    "        min(\"flight_number\") as \"min_flight_n\", max(\"flight_number\") as \"max_flight_n\", \n",
    "       count(*) \"total_flights\", \n",
    "       SUM(\"departure_delay\") \"total_time_lost\" \n",
    "FROM \"example-flights-updates\"\n",
    "WHERE \"airline\" in ('TZ', 'HA')\n",
    "GROUP BY 1\n",
    "'''\n",
    "display.sql(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df5d57a-fded-4137-988c-905e75364453",
   "metadata": {},
   "source": [
    "In traditional SQL this might look like:\n",
    "```\n",
    "   DELETE \"example-flights-updates\"\n",
    "   WHERE \"airline\" = 'TZ'\n",
    "   ;\n",
    "   INSERT INTO \"example-flights-updates\"\n",
    "   SELECT * FROM \"example-replace-history\"\n",
    ";\n",
    "```\n",
    "\n",
    "You can achieve this effect with a single REPLACE using the existing data combined with the new data to replace the portion of time affected by the change set. You need to exclude rows from existing data for the entity being replaced and use a UNION ALL to merge with the new data. So for this REPLACE:\n",
    "-  Use a REPLACE statement that overwrites the portion of the time line that you have new history for. In our example it is ALL:\n",
    "\n",
    "   ```\n",
    "   OVERWRITE ALL\n",
    "   ```\n",
    "   \n",
    "- The request uses a FULL OUTER JOIN between the target table and the change set so that you can include existing rows excluding rows for the key that is being replace in a subquery with a FULL OUTER JOIN to the replacement rows. In the following SQL that is:\n",
    "\n",
    "   ```\n",
    "   FROM ( SELECT * FROM \"example-flights-updates\" WHERE \"airline\"!='TZ' ) t\n",
    "   FULL OUTER JOIN\n",
    "        \"example-replace-history\" s\n",
    "     ON t.\"__time\"=s.\"__time\"\n",
    "    AND t.\"airline\"=s.\"airline\"\n",
    "    AND t.\"flight_number\"=s.\"flight_number\" \n",
    "   ```\n",
    "   \n",
    "- Given the content of the tables and the FULL OUTER JOIN, the values will either be on the target table or the source table, there is no overlap, so the column expressions for the key columns in the SELECT use a COALESCE:\n",
    "\n",
    "   ```\n",
    "   COALESCE(t.\"__time\", s.\"__time\") as \"__time\",\n",
    "   COALESCE(t.\"airline\", s.\"airline\") as \"airline\",\n",
    "   COALESCE(t.\"flight_number\", s.\"flight_number\") as \"flight_number\"\n",
    "   ```\n",
    "   \n",
    "- For non-key columns use a CASE expression that checks the key column to determine if this is an existing or new row and assigned the corresponding value from the target or source tables:\n",
    "\n",
    "   ```\n",
    "   CASE WHEN t.\"__time\" IS NULL THEN s.\"arrival_time\"      -- new rows get new value                                  \n",
    "        ELSE t.\"arrival_time                               -- existing rows get existing value   \n",
    "   END AS \"arrival_time\" \n",
    "   ```\n",
    "- Set the [context parameter to use `sqlJoinAlgorithm=sortMerge`](https://druid.apache.org/docs/28.0.0/multi-stage-query/reference#sort-merge) to enable the FULL OUTER JOIN.\n",
    "\n",
    "Run the following SQL to apply the upsert operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c0f8c5-a664-4b53-ba0f-e8f077ccd667",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql='''\n",
    "REPLACE INTO \"example-flights-updates\" OVERWRITE ALL\n",
    "SELECT \n",
    "      COALESCE(t.\"__time\",       s.\"__time\"        ) as \"__time\",\n",
    "      COALESCE(t.\"airline\",       s.\"airline\"       ) as \"airline\",\n",
    "      COALESCE(t.\"flight_number\", s.\"flight_number\" ) as \"flight_number\",\n",
    "      CASE WHEN t.\"__time\" IS NULL THEN s.\"arrival_time\"    ELSE t.\"arrival_time\"    END  as \"arrival_time\",\n",
    "      CASE WHEN t.\"__time\" IS NULL THEN s.\"tail_number\"     ELSE t.\"tail_number\"     END  as \"tail_number\", \n",
    "      CASE WHEN t.\"__time\" IS NULL THEN s.\"origin\"          ELSE t.\"origin\"          END  as \"origin\", \n",
    "      CASE WHEN t.\"__time\" IS NULL THEN s.\"destination\"     ELSE t.\"destination\"     END  as \"destination\", \n",
    "      CASE WHEN t.\"__time\" IS NULL THEN s.\"departure_delay\" ELSE t.\"departure_delay\" END  as \"departure_delay\" \n",
    "FROM ( SELECT * FROM \"example-flights-updates\" WHERE \"airline\"!='TZ' ) t\n",
    "  FULL OUTER JOIN\n",
    "    \"example-replace-history\" s\n",
    "  ON t.\"__time\"=s.\"__time\"\n",
    "  AND t.\"airline\"=s.\"airline\"\n",
    "  AND t.\"flight_number\"=s.\"flight_number\" \n",
    "PARTITIONED BY DAY    \n",
    "'''\n",
    "req = sql_client.sql_request(sql)\n",
    "req.add_context(\"sqlJoinAlgorithm\", 'sortMerge')\n",
    "display.run_task(req)\n",
    "sql_client.wait_until_ready('example-flights-updates')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e183a307-00d0-459c-b00c-402a383a4231",
   "metadata": {},
   "source": [
    "Look at the data now, given that the changeset was created by copying the history of flights from airline `HA`, the aggregate results for both airlines should now match: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47263395-3359-4cc9-8199-daef579ec71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql='''\n",
    "SELECT \"airline\", \n",
    "        min(\"__time\") first_flight, max(\"__time\") last_flight, \n",
    "        min(\"flight_number\") as \"min_flight_n\", max(\"flight_number\") as \"max_flight_n\", \n",
    "       count(*) \"total_flights\", \n",
    "       SUM(\"departure_delay\") \"total_time_lost\" \n",
    "FROM \"example-flights-updates\"\n",
    "WHERE \"airline\" in ('TZ', 'HA')\n",
    "GROUP BY 1\n",
    "'''\n",
    "display.sql(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44738d6d-cec2-40ad-aaba-998c758c63f4",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "\n",
    "Run the following cell to remove the table from the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8082b545-ba7f-4ede-bb6e-2a6dd62ba0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "druid.datasources.drop(\"example-flights-updates\")\n",
    "druid.datasources.drop(\"example-upsert-changeset\")\n",
    "druid.datasources.drop(\"example-changeset-day\")\n",
    "druid.datasources.drop(\"example-replace-history\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b8d5fe-ba85-4b5b-9669-0dd47dfbccd1",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You learned that using REPLACE you can:\n",
    "* UPDATE rows using granular segment overlays\n",
    "* DELETE rows\n",
    "* UPDATE whole timeframes of data with newer data\n",
    "* UPSERT rows like MERGE does in traditional SQL\n",
    "* Replace the history of an entity across a broad timeframe.\n",
    "\n",
    "## Learn more\n",
    "\n",
    "* Use [Compaction or Auto-compaction](https://druid.apache.org/docs/28.0.0/data-management/compaction) to merge small granularity update segments with the larger base segments after doing small updates and deletes.\n",
    "* Check out [SQL Based Ingestion docs](https://druid.apache.org/docs/28.0.0/multi-stage-query/) for everything you want to know about the REPLACE statement."
   ]
  }
 ],
 "metadata": {
  "execution": {
   "allow_errors": true,
   "timeout": 300
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

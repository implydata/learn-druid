{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cb3b009-ebde-4d56-9d59-a028d66d8309",
   "metadata": {},
   "source": [
    "# Filtering incoming stream data using native functions\n",
    "<!--\n",
    "  ~ Licensed to the Apache Software Foundation (ASF) under one\n",
    "  ~ or more contributor license agreements.  See the NOTICE file\n",
    "  ~ distributed with this work for additional information\n",
    "  ~ regarding copyright ownership.  The ASF licenses this file\n",
    "  ~ to you under the Apache License, Version 2.0 (the\n",
    "  ~ \"License\"); you may not use this file except in compliance\n",
    "  ~ with the License.  You may obtain a copy of the License at\n",
    "  ~\n",
    "  ~   http://www.apache.org/licenses/LICENSE-2.0\n",
    "  ~\n",
    "  ~ Unless required by applicable law or agreed to in writing,\n",
    "  ~ software distributed under the License is distributed on an\n",
    "  ~ \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n",
    "  ~ KIND, either express or implied.  See the License for the\n",
    "  ~ specific language governing permissions and limitations\n",
    "  ~ under the License.\n",
    "  -->\n",
    "\n",
    "During streaming ingestion, you can filter incoming data using Apache Druid native filters within the ingestion spec. This tutorial demonstrates how to apply native [filters](https://druid.apache.org/docs/latest/querying/filters) to a stream of events.\n",
    "\n",
    "In this tutorial you perform the following tasks:\n",
    "\n",
    "- Set up a streaming ingestion from Apache Kafka.\n",
    "- Create two alternative tables from the same topic that contain filtered versions of the source data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdbf6ad-ca7b-40f5-8ca3-1070f4a3ee42",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "This tutorial works with Druid 29.0.0 or later.\n",
    "\n",
    "Launch this tutorial and all prerequisites using the `all-services` profile of the Docker Compose file for Jupyter-based Druid tutorials. For more information, see the Learn Druid repository [readme](https://github.com/implydata/learn-druid).\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5007a243-b81a-4601-8f57-5b14940abbff",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "\n",
    "The following cells set up the notebook and learning environment ready for use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4439783f-16cc-4f67-bd50-bdfd4539e9b0",
   "metadata": {},
   "source": [
    "### Set up a connection to Apache Druid\n",
    "\n",
    "Run the next cell to set up the Druid Python client's connection to Apache Druid.\n",
    "\n",
    "If successful, the Druid version number will be shown in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ec783b-df3f-4168-9be2-cdc6ad3e33c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import druidapi\n",
    "import os\n",
    "\n",
    "druid_headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "if 'DRUID_HOST' not in os.environ.keys():\n",
    "    druid_host=f\"http://localhost:8888\"\n",
    "else:\n",
    "    druid_host=f\"http://{os.environ['DRUID_HOST']}:8888\"\n",
    "\n",
    "print(f\"Opening a connection to {druid_host}.\")\n",
    "druid = druidapi.jupyter_client(druid_host)\n",
    "display = druid.display\n",
    "sql_client = druid.sql\n",
    "status_client = druid.status\n",
    "\n",
    "status_client.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872dd1b5-419d-4201-8061-5339c8462386",
   "metadata": {},
   "source": [
    "###Â Set up a connection to Apache Kafka\n",
    "\n",
    "Run the next cell to set up the connection to Apache Kafka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358b18a2-1aea-4538-a711-476877417509",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'KAFKA_HOST' not in os.environ.keys():\n",
    "   kafka_host=f\"http://localhost:9092\"\n",
    "else:\n",
    "    kafka_host=f\"{os.environ['KAFKA_HOST']}:9092\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efdbee0-62da-4fd3-84e1-f66b8c0150b3",
   "metadata": {},
   "source": [
    "### Set up a connection to the data generator\n",
    "\n",
    "Run the next cell to set up the connection to the data generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c075de81-04c9-4b23-8253-20a15d46252e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "datagen_host = \"http://datagen:9999\"\n",
    "datagen_headers = {'Content-Type': 'application/json'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa44175-44f9-4c47-aa0c-7b7b011ff442",
   "metadata": {},
   "source": [
    "## Create a table using streaming ingestion\n",
    "\n",
    "In this section, you use the data generator to generate a stream of messages into a Kafka topic. Next, you set up an on-going ingestion into Druid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7b7439-ad21-4808-96b1-8e3c992fa51e",
   "metadata": {},
   "source": [
    "### Use the data generator to populate a Kafka topic\n",
    "\n",
    "Run the following cell to instruct the data generator to start producing data.\n",
    "\n",
    "This creates clickstream sample data for an hour and publishes the data to a Kafka topic for Druid to consume from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897ec019-7145-4005-bb85-ea25eda7bf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen_topic = \"example-clickstream-filters\"\n",
    "datagen_job = datagen_topic\n",
    "datagen_config = \"clickstream/clickstream.json\"\n",
    "\n",
    "datagen_request = {\n",
    "    \"name\": datagen_job,\n",
    "    \"target\": { \"type\": \"kafka\", \"endpoint\": kafka_host, \"topic\": datagen_topic  },\n",
    "    \"config_file\": datagen_config,\n",
    "    \"concurrency\":10,\n",
    "    \"time_type\": \"REAL\"\n",
    "}\n",
    "\n",
    "requests.post(f\"{datagen_host}/start\", json.dumps(datagen_request), headers=datagen_headers)\n",
    "requests.get(f\"{datagen_host}/status/{datagen_job}\").json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dde5e8-237e-4531-84c2-8647d92ceaea",
   "metadata": {},
   "source": [
    "### Use streaming ingestion to populate the table\n",
    "\n",
    "Ingest data from the Kafka topic into Druid by submitting an [ingestion specification](https://druid.apache.org/docs/latest/ingestion/ingestion-spec.html) to the [streaming ingestion supervisor API](https://druid.apache.org/docs/latest/api-reference/supervisor-api).\n",
    "\n",
    "Run the next cell to set up the [`ioConfig`](https://druid.apache.org/docs/latest/ingestion/ingestion-spec#ioconfig), [`tuningConfig`](https://druid.apache.org/docs/latest/ingestion/ingestion-spec#tuningconfig), and [`dataSchema`](https://druid.apache.org/docs/latest/ingestion/ingestion-spec#dataschema) components of the ingestion spec and submit it to Druid to start the ingestion.\n",
    "\n",
    "When finished, you will see the table description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb89079-7e2a-404b-be85-d9fc7c97d0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ioConfig = {\n",
    "    \"type\": \"kafka\",\n",
    "    \"consumerProperties\": { \"bootstrap.servers\": kafka_host },\n",
    "    \"topic\": datagen_topic,\n",
    "    \"inputFormat\": { \"type\": \"json\" },\n",
    "    \"useEarliestOffset\": \"false\" }\n",
    "\n",
    "tuningConfig = { \"type\": \"kafka\" }\n",
    "\n",
    "table_name = datagen_topic\n",
    "\n",
    "dataSchema = {\n",
    "    \"dataSource\": table_name,\n",
    "    \"timestampSpec\": { \"column\": \"time\", \"format\": \"iso\" },\n",
    "    \"granularitySpec\": { \"rollup\": \"false\", \"segmentGranularity\": \"hour\" },\n",
    "    \"dimensionsSpec\": { \"useSchemaDiscovery\" : \"true\"}\n",
    "    }\n",
    "\n",
    "ingestion_spec = {\n",
    "    \"type\": \"kafka\",\n",
    "    \"spec\": {\n",
    "        \"ioConfig\": ioConfig,\n",
    "        \"tuningConfig\": tuningConfig,\n",
    "        \"dataSchema\": dataSchema\n",
    "    }\n",
    "}\n",
    "\n",
    "requests.post(f\"{druid_host}/druid/indexer/v1/supervisor\", json.dumps(ingestion_spec), headers=druid_headers)\n",
    "sql_client.wait_until_ready(table_name, verify_load_status=False)\n",
    "display.table(table_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472589e4-1026-4b3b-bb79-eedabb2b44c4",
   "metadata": {},
   "source": [
    "## Filter data using an equality filter\n",
    "\n",
    "In this section, you use an [equality filter](https://druid.apache.org/docs/latest/querying/filters#equality-filter) to create a table that only contains records for where someone searches for a product.\n",
    "\n",
    "Run the following cell to get a preview of the data that we want to have in our new table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32bed8e-bc49-4ba8-85d2-8a9bfa9232f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql=f'''\n",
    "SELECT\n",
    "  \"event_type\",\n",
    "  COUNT(*) AS events\n",
    "FROM \"{table_name}\"\n",
    "GROUP BY 1\n",
    "'''\n",
    "\n",
    "display.sql(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c81b63-777b-414f-81a9-2b9ccee214e5",
   "metadata": {},
   "source": [
    "Run the next cell to create a new object that represents the [`transformSpec`](https://druid.apache.org/docs/latest/ingestion/ingestion-spec#transformspec). This will be added to the `dataSchema` in the ingestion specification, instructing Druid to apply a filter to the incoming data as it arrives.\n",
    "\n",
    "Here, only one [filter](https://druid.apache.org/docs/latest/ingestion/ingestion-spec#filter) will be applied to the data as it arrives.\n",
    "\n",
    "* The `type` of `selector` looks for an exact match.\n",
    "* The check will be against the `dimension` of `event_type`, looking for a `value` of \"search\".\n",
    "\n",
    "Only rows that pass this test will be added to the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f562b1f3-4265-4553-aabe-7e7d30b21ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSchema_transformSpec = {\n",
    "    \"filter\":\n",
    "        {\n",
    "            \"type\": \"selector\",\n",
    "            \"dimension\": \"event_type\",\n",
    "            \"value\": \"search\"\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b37edb9-d891-4c1a-8223-fcfd7d5e3d16",
   "metadata": {},
   "source": [
    "Run the next cell to build a new ingestion specification.\n",
    "\n",
    "Notice the new table name, `table_searches`, and that while the `timestampSpec`, `granularitySpec`, and `dimensionsSpec` remain the same, the `transformSpec` is updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a6503f-d0d3-41ae-a0d5-b55d6e05e78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_searches = table_name + \"-search\"\n",
    "\n",
    "dataSchema = {\n",
    "    \"dataSource\": table_searches,\n",
    "    \"timestampSpec\": { \"column\": \"time\", \"format\": \"iso\" },\n",
    "    \"granularitySpec\": { \"rollup\": \"false\", \"segmentGranularity\": \"hour\" },\n",
    "    \"dimensionsSpec\": { \"useSchemaDiscovery\" : \"true\"},\n",
    "    \"transformSpec\" : dataSchema_transformSpec\n",
    "    }\n",
    "\n",
    "ingestion_spec = {\n",
    "  \"type\": \"kafka\",\n",
    "  \"spec\": {\n",
    "    \"ioConfig\": ioConfig,\n",
    "    \"tuningConfig\": tuningConfig,\n",
    "    \"dataSchema\": dataSchema\n",
    "  }\n",
    "}\n",
    "\n",
    "print(json.dumps(ingestion_spec, indent=5))\n",
    "\n",
    "requests.post(f\"{druid_host}/druid/indexer/v1/supervisor\", json.dumps(ingestion_spec), headers=druid_headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e776f9b9-527f-4a17-bc6a-4c6b34f7353e",
   "metadata": {},
   "source": [
    "Review the output above to see where `transforms` have been added inside the `dataSchema`.\n",
    "\n",
    "Run the next cell to confirm the table has been populated before moving on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c488ec1-e107-4fa1-8cb5-711150069a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_client.wait_until_ready(table_searches, verify_load_status=False)\n",
    "display.table(table_searches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4124ea80-4faa-4d16-82a8-d509e3733fa1",
   "metadata": {},
   "source": [
    "Run the cell below a few times.\n",
    "\n",
    "You will see that events continue being ingested into the original table, but that the new table only contains new events that match the filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740c1228-70ed-47d8-bf24-35f6d7323f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "time_now = datetime.now().strftime('%Y-%m-%dT%H:%M:%S')\n",
    "\n",
    "sql=f'''\n",
    "SELECT\n",
    "  \"__time\",\n",
    "  \"event_type\",\n",
    "  \"client_ip\",\n",
    "  \"client_device\",\n",
    "  \"client_lang\",\n",
    "  \"client_country\"\n",
    "FROM \"{table_searches}\"\n",
    "WHERE TIME_IN_INTERVAL(__time,'PT15S/{time_now}')\n",
    "ORDER BY __time DESC\n",
    "'''\n",
    "\n",
    "print(\"This data is being filtered at ingestion time:\")\n",
    "display.sql(sql)\n",
    "\n",
    "sql=f'''\n",
    "SELECT\n",
    "  \"__time\",\n",
    "  \"event_type\",\n",
    "  \"client_ip\",\n",
    "  \"client_device\",\n",
    "  \"client_lang\",\n",
    "  \"client_country\"\n",
    "FROM \"{table_name}\"\n",
    "WHERE TIME_IN_INTERVAL(__time,'PT15S/{time_now}')\n",
    "ORDER BY __time DESC\n",
    "'''\n",
    "\n",
    "print(\"This data is not being filtered:\")\n",
    "display.sql(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac90546-2355-4396-8a95-ca0f5394f783",
   "metadata": {},
   "source": [
    "Run the next cell to stop the ingestion job and drop the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e40b62-c74e-4cbd-8de9-8dbaac5def81",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = druid.tasks.tasks(state='running', table=table_searches)\n",
    "while len(tasks)>0:\n",
    "    for task in tasks:\n",
    "        print(f\"...stopping task [{task['id']}]\")\n",
    "        druid.tasks.shut_down_task(task['id'])\n",
    "    tasks = druid.tasks.tasks(state='running', table=table_searches)\n",
    "        \n",
    "print(f'Reset offsets for re-runnability: [{requests.post(f\"{druid_host}/druid/indexer/v1/supervisor/{table_searches}/reset\",\"\")}]')\n",
    "print(f'Terminate streaming ingestion: [{requests.post(f\"{druid_host}/druid/indexer/v1/supervisor/{table_searches}/terminate\",\"\")}]')\n",
    "print(f\"Drop datasource: [{druid.datasources.drop(table_searches)}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c09a052-180d-4cb4-80a7-32b746642ee7",
   "metadata": {},
   "source": [
    "## Filter data using an in filter\n",
    "\n",
    "In this section, you use an [in filter](https://druid.apache.org/docs/latest/querying/filters#equality-filter) to create a table that only contains actions where someone adds or drops an item from their cart.\n",
    "\n",
    "Run the following cell which executes SQL to give a preview of the data destined for the new table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52a94fb-d2e4-403f-ab10-84d3af7bf2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql=f'''\n",
    "SELECT\n",
    "  \"__time\",\n",
    "  \"event_type\"\n",
    "FROM \"{table_name}\"\n",
    "WHERE \"event_type\" IN ('add_to_cart', 'view_cart')\n",
    "LIMIT 10\n",
    "'''\n",
    "\n",
    "display.sql(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab94579c-b84e-43ae-89af-e1e0fb2d7da3",
   "metadata": {},
   "source": [
    "Using [EXPLAIN PLAN](https://druid.apache.org/docs/latest/querying/sql#explain-plan), it's possible to see the native representation of any Druid SQL statement, allowing you to pinpoint reusable elements for native queries or ingestion.\n",
    "\n",
    "Run the next cell to use the Druid API to execute an EXPLAIN PLAN function for the SQL query above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367aabe5-9b37-4dd2-a5c1-960ba849b164",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(json.loads(sql_client.explain_sql(sql)['PLAN']), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00032a2e-1d73-4dbd-88ff-697db342ecdc",
   "metadata": {},
   "source": [
    "Leveraging the `filter` section above, run the next cell to create a new [`transformSpec`](https://druid.apache.org/docs/latest/ingestion/ingestion-spec#transformspec) that contains this filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7094b74f-4e1d-43af-8c77-74d3bca82630",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSchema_transformSpec = {\n",
    "    \"filter\": {\n",
    "        \"type\": \"in\",\n",
    "        \"dimension\": \"event_type\",\n",
    "        \"values\": [\n",
    "          \"add_to_cart\",\n",
    "          \"view_cart\"\n",
    "        ]\n",
    "      }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d3921d-d771-46f3-a295-38bf7beb74d1",
   "metadata": {},
   "source": [
    "Run this cell to build an `ingestion_spec` object, this time including the `transformSpec` above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1d911e-ecf2-4461-9c24-84168b0f7860",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_cart = table_name + \"-cart\"\n",
    "\n",
    "dataSchema = {\n",
    "    \"dataSource\": table_cart,\n",
    "    \"timestampSpec\": { \"column\": \"time\", \"format\": \"iso\" },\n",
    "    \"granularitySpec\": { \"rollup\": \"false\", \"segmentGranularity\": \"hour\" },\n",
    "    \"dimensionsSpec\": { \"useSchemaDiscovery\" : \"true\"},\n",
    "    \"transformSpec\" : dataSchema_transformSpec\n",
    "    }\n",
    "\n",
    "ingestion_spec = {\n",
    "  \"type\": \"kafka\",\n",
    "  \"spec\": {\n",
    "    \"ioConfig\": ioConfig,\n",
    "    \"tuningConfig\": tuningConfig,\n",
    "    \"dataSchema\": dataSchema\n",
    "  }\n",
    "}\n",
    "\n",
    "requests.post(f\"{druid_host}/druid/indexer/v1/supervisor\", json.dumps(ingestion_spec), headers=druid_headers)\n",
    "sql_client.wait_until_ready(table_cart, verify_load_status=False)\n",
    "display.table(table_cart)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780708a3-da27-4195-a450-f53007a4f289",
   "metadata": {},
   "source": [
    "Run the query below to see the effect this has had on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6cf5ab-cba3-43d4-a43d-9b095311d05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_now = datetime.now().strftime('%Y-%m-%dT%H:%M:%S')\n",
    "print(time_now)\n",
    "\n",
    "sql=f'''\n",
    "SELECT\n",
    "  \"__time\",\n",
    "  \"event_type\",\n",
    "  \"client_ip\",\n",
    "  \"client_device\",\n",
    "  \"client_lang\",\n",
    "  \"client_country\"\n",
    "FROM \"{table_cart}\"\n",
    "WHERE TIME_IN_INTERVAL(__time,'PT15S/{time_now}')\n",
    "ORDER BY __time DESC\n",
    "'''\n",
    "\n",
    "print(\"This data is being filtered at ingestion time:\")\n",
    "display.sql(sql)\n",
    "\n",
    "sql=f'''\n",
    "SELECT\n",
    "  \"__time\",\n",
    "  \"event_type\",\n",
    "  \"client_ip\",\n",
    "  \"client_device\",\n",
    "  \"client_lang\",\n",
    "  \"client_country\"\n",
    "FROM \"{table_name}\"\n",
    "WHERE TIME_IN_INTERVAL(__time,'PT15S/{time_now}')\n",
    "ORDER BY __time DESC\n",
    "'''\n",
    "\n",
    "print(\"This data is not being filtered:\")\n",
    "display.sql(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5ceca5-cecc-4710-8092-9aa0f41488af",
   "metadata": {},
   "source": [
    "Taking a look back at the original data, you may notice we have missed an event type!\n",
    "\n",
    "Run the following cell to switch from an \"in\" type filter to a \"[like](https://druid.apache.org/docs/29.0.1/querying/filters/#like-filter)\" filter to catch the missing event_type: \"drop_from_cart\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91c0fda-6905-474d-9549-10b6672f533e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSchema_transformSpec = {\n",
    "    \"filter\": {\n",
    "        \"type\": \"like\",\n",
    "        \"dimension\": \"event_type\",\n",
    "        \"pattern\" : \"%cart%\"\n",
    "      }\n",
    "}\n",
    "\n",
    "dataSchema = {\n",
    "    \"dataSource\": table_cart,\n",
    "    \"timestampSpec\": { \"column\": \"time\", \"format\": \"iso\" },\n",
    "    \"granularitySpec\": { \"rollup\": \"false\", \"segmentGranularity\": \"hour\" },\n",
    "    \"dimensionsSpec\": { \"useSchemaDiscovery\" : \"true\"},\n",
    "    \"transformSpec\" : dataSchema_transformSpec\n",
    "    }\n",
    "\n",
    "ingestion_spec = {\n",
    "  \"type\": \"kafka\",\n",
    "  \"spec\": {\n",
    "    \"ioConfig\": ioConfig,\n",
    "    \"tuningConfig\": tuningConfig,\n",
    "    \"dataSchema\": dataSchema\n",
    "  }\n",
    "}\n",
    "\n",
    "requests.post(f\"{druid_host}/druid/indexer/v1/supervisor\", json.dumps(ingestion_spec), headers=druid_headers)\n",
    "sql_client.wait_until_ready(table_cart, verify_load_status=False)\n",
    "display.table(table_cart)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83b8ac5-59fd-43c1-8547-03c98a8ae5d1",
   "metadata": {},
   "source": [
    "Wait for a few moments for the old consumers to [stop and hand off their data](https://druid.apache.org/docs/latest/design/storage#indexing-and-handoff), and for the supervisor to start new consumer tasks with the new configuration.\n",
    "\n",
    "Run the next cell to see the effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005c82bc-0f18-444e-979c-a794f2d69c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_now = datetime.now().strftime('%Y-%m-%dT%H:%M:%S')\n",
    "\n",
    "sql=f'''\n",
    "SELECT\n",
    "  \"__time\",\n",
    "  \"event_type\",\n",
    "  \"client_ip\",\n",
    "  \"client_device\",\n",
    "  \"client_lang\",\n",
    "  \"client_country\"\n",
    "FROM \"{table_cart}\"\n",
    "WHERE TIME_IN_INTERVAL(__time,'PT15S/''' + time_now + '''')\n",
    "ORDER BY __time DESC\n",
    "'''\n",
    "\n",
    "print(\"This data is filtered at ingestion time:\")\n",
    "display.sql(sql)\n",
    "\n",
    "sql=f'''\n",
    "SELECT\n",
    "  \"__time\",\n",
    "  \"event_type\",\n",
    "  \"client_ip\",\n",
    "  \"client_device\",\n",
    "  \"client_lang\",\n",
    "  \"client_country\"\n",
    "FROM \"{table_name}\"\n",
    "WHERE TIME_IN_INTERVAL(__time,'PT15S/''' + time_now + '''')\n",
    "ORDER BY __time DESC\n",
    "'''\n",
    "\n",
    "print(\"This data is unfiltered:\")\n",
    "display.sql(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93270a7f-0785-45a1-a556-414a6ac4d4d6",
   "metadata": {},
   "source": [
    "Adjust the TIME_IN_INTERVAL filters above to cover different time periods.\n",
    "\n",
    "Notice that, in the method used in this example, the filter takes effect from this point forward - historical \"drop from cart\" events are not captured."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44738d6d-cec2-40ad-aaba-998c758c63f4",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "\n",
    "Run the following cell to stop the data generator, stop ingestion from the topic, and remove the table used in this notebook from the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8082b545-ba7f-4ede-bb6e-2a6dd62ba0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Stop streaming generator: [{requests.post(f'{druid_host}/stop/{datagen_topic}','')}]\")\n",
    "print(f'Pause streaming ingestion: [{requests.post(f\"{druid_host}/druid/indexer/v1/supervisor/{datagen_topic}/suspend\",\"\")}]')\n",
    "\n",
    "print(f'Shutting down running tasks ...')\n",
    "\n",
    "tasks = druid.tasks.tasks(state='running', table=table_name)\n",
    "while len(tasks)>0:\n",
    "    for task in tasks:\n",
    "        print(f\"...stopping task [{task['id']}]\")\n",
    "        druid.tasks.shut_down_task(task['id'])\n",
    "    tasks = druid.tasks.tasks(state='running', table=table_name)\n",
    "        \n",
    "print(f'Reset offsets for re-runnability: [{requests.post(f\"{druid_host}/druid/indexer/v1/supervisor/{table_name}/reset\",\"\")}]')\n",
    "print(f'Terminate streaming ingestion: [{requests.post(f\"{druid_host}/druid/indexer/v1/supervisor/{table_name}/terminate\",\"\")}]')\n",
    "print(f\"Drop datasource: [{druid.datasources.drop(table_name)}]\")\n",
    "\n",
    "tasks = druid.tasks.tasks(state='running', table=table_cart)\n",
    "while len(tasks)>0:\n",
    "    for task in tasks:\n",
    "        print(f\"...stopping task [{task['id']}]\")\n",
    "        druid.tasks.shut_down_task(task['id'])\n",
    "    tasks = druid.tasks.tasks(state='running', table=table_cart)\n",
    "\n",
    "print(f'Reset offsets for re-runnability: [{requests.post(f\"{druid_host}/druid/indexer/v1/supervisor/{table_cart}/reset\",\"\")}]')\n",
    "print(f'Terminate streaming ingestion: [{requests.post(f\"{druid_host}/druid/indexer/v1/supervisor/{table_cart}/terminate\",\"\")}]')\n",
    "print(f\"Drop datasource: [{druid.datasources.drop(table_cart)}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b8d5fe-ba85-4b5b-9669-0dd47dfbccd1",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "* Filters can be applied to data from Apache Kafka as soon as it arrives.\n",
    "* Typical SQL WHERE filtering has native counterparts that you can use as a filter in the `transformSpec`.\n",
    "* Unless the topic offset is reset manually, expressions only apply to new data as it arrives.\n",
    "\n",
    "## Learn more\n",
    "\n",
    "* Try using [logical expression filters](https://druid.apache.org/docs/latest/querying/filters#logical-expression-filters) to add AND and OR conditions in your filters.\n",
    "* Read about more advanced filters, such as [regular expression](https://druid.apache.org/docs/latest/querying/filters#regular-expression-filter) and [expression](https://druid.apache.org/docs/latest/querying/filters#expression-filter) filters.\n",
    "* Check out the notebook on transforming data at ingestion time using [expressions](13-native-transforms.ipynb) and then combine what you've learned here with an [extraction filter](https://druid.apache.org/docs/latest/querying/filters#extraction-filter).\n",
    "* Re-run this notebook, but manually hard reset the supervisor between posting a new ingestion specification. You can do this either with a [POST](https://druid.apache.org/docs/latest/api-reference/supervisor-api#reset-a-supervisor) request or [through the console](https://druid.apache.org/docs/latest/operations/web-console#supervisors). What do you expect to happen?\n",
    "* Review to the documentation on [native transform expressions](https://druid.apache.org/docs/latest/querying/math-expr)."
   ]
  }
 ],
 "metadata": {
  "execution": {
   "allow_errors": true,
   "timeout": 300
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cb3b009-ebde-4d56-9d59-a028d66d8309",
   "metadata": {},
   "source": [
    "# Define schemas for incoming stream data\n",
    "<!--\n",
    "  ~ Licensed to the Apache Software Foundation (ASF) under one\n",
    "  ~ or more contributor license agreements.  See the NOTICE file\n",
    "  ~ distributed with this work for additional information\n",
    "  ~ regarding copyright ownership.  The ASF licenses this file\n",
    "  ~ to you under the Apache License, Version 2.0 (the\n",
    "  ~ \"License\"); you may not use this file except in compliance\n",
    "  ~ with the License.  You may obtain a copy of the License at\n",
    "  ~\n",
    "  ~   http://www.apache.org/licenses/LICENSE-2.0\n",
    "  ~\n",
    "  ~ Unless required by applicable law or agreed to in writing,\n",
    "  ~ software distributed under the License is distributed on an\n",
    "  ~ \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n",
    "  ~ KIND, either express or implied.  See the License for the\n",
    "  ~ specific language governing permissions and limitations\n",
    "  ~ under the License.\n",
    "  -->\n",
    "\n",
    "During streaming ingestion, the schema for events written into a table from a stream are set in the `dimensionsSpec`. This tutorial demonstrates various ways to work with the [dimensionsSpec](https://druid.apache.org/docs/latest/ingestion/ingestion-spec#dimensionsspec) against an example stream of events.\n",
    "\n",
    "In this tutorial you perform the following tasks:\n",
    "\n",
    "- Set up a streaming ingestion from Apache Kafka.\n",
    "- Start an ingestion that consumes specific dimensions and writes them into a table.\n",
    "- Update the ingestion to set the specific data type for some of the dimensions.\n",
    "- Amend the ingestion to consume all but specific dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdbf6ad-ca7b-40f5-8ca3-1070f4a3ee42",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "This tutorial works with Druid 29.0.0 or later.\n",
    "\n",
    "#### Run with Docker\n",
    "\n",
    "Launch this tutorial and all prerequisites using the `all-services` profile of the Docker Compose file for Jupyter-based Druid tutorials. For more information, see the Learn Druid repository [readme](https://github.com/implydata/learn-druid).\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5007a243-b81a-4601-8f57-5b14940abbff",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "\n",
    "The following cells set up the notebook and learning environment ready for use.\n",
    "\n",
    "### Set up and connect to the learning environment\n",
    "\n",
    "Run the next cell to set up the Druid Python client's connection to Apache Druid.\n",
    "\n",
    "If successful, the Druid version number will be shown in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1ec783b-df3f-4168-9be2-cdc6ad3e33c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening a connection to http://router:8888.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'29.0.1'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import druidapi\n",
    "import os\n",
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "if 'DRUID_HOST' not in os.environ.keys():\n",
    "    druid_host=f\"http://localhost:8888\"\n",
    "else:\n",
    "    druid_host=f\"http://{os.environ['DRUID_HOST']}:8888\"\n",
    "    \n",
    "print(f\"Opening a connection to {druid_host}.\")\n",
    "druid = druidapi.jupyter_client(druid_host)\n",
    "\n",
    "display = druid.display\n",
    "sql_client = druid.sql\n",
    "status_client = druid.status\n",
    "\n",
    "status_client.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efdbee0-62da-4fd3-84e1-f66b8c0150b3",
   "metadata": {},
   "source": [
    "Run the next cell to set up the connection to Apache Kafka and to the Data Generator, and to import some helper functions for later in the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c075de81-04c9-4b23-8253-20a15d46252e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import kafka\n",
    "from kafka import KafkaConsumer\n",
    "\n",
    "datagenUrl = \"http://datagen:9999\"\n",
    "\n",
    "generalHeaders = {'Content-Type': 'application/json'}\n",
    "\n",
    "if (os.environ['KAFKA_HOST'] == None):\n",
    "    kafka_host=f\"kafka:9092\"\n",
    "else:\n",
    "    kafka_host=f\"{os.environ['KAFKA_HOST']}:9092\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7b7439-ad21-4808-96b1-8e3c992fa51e",
   "metadata": {},
   "source": [
    "### Start a data stream\n",
    "\n",
    "Run the following cell to use the learn-druid Data Generator to create a stream that we can consume from.\n",
    "\n",
    "This will create clickstream sample data for an hour and publish it to a topic in Apache Kafka for Apache Druid to consume from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "897ec019-7145-4005-bb85-ea25eda7bf5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_name=\"example-social-dimensions\"\n",
    "topic_name = job_name\n",
    "\n",
    "target = {\n",
    "    \"type\":\"kafka\",\n",
    "    \"endpoint\": kafka_host,\n",
    "    \"topic\": topic_name\n",
    "}\n",
    "\n",
    "datagen_request = {\n",
    "    \"name\": topic_name,\n",
    "    \"target\": target,\n",
    "    \"config_file\": \"social/social_posts.json\",\n",
    "    \"time\": \"1h\",\n",
    "    \"concurrency\":10,\n",
    "    \"time_type\": \"REAL\"\n",
    "}\n",
    "\n",
    "requests.post(f\"{datagenUrl}/start\", json.dumps(datagen_request), headers=generalHeaders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dde5e8-237e-4531-84c2-8647d92ceaea",
   "metadata": {},
   "source": [
    "## Set up ingestion specification basics\n",
    "\n",
    "Run the following cell to create an [ioConfig](https://druid.apache.org/docs/latest/ingestion/ingestion-spec#ioconfig) object that sets the connection to the topic from Apache Druid along with a very simple [tuningConfig](https://druid.apache.org/docs/latest/ingestion/ingestion-spec#tuningconfig) object for the tuning configuration for the ingestion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4fb89079-7e2a-404b-be85-d9fc7c97d0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ioConfig = {\n",
    "  \"type\": \"kafka\",\n",
    "  \"consumerProperties\": {\n",
    "    \"bootstrap.servers\": \"kafka:9092\"\n",
    "  },\n",
    "  \"topic\": topic_name,\n",
    "  \"inputFormat\": {\n",
    "    \"type\": \"json\"\n",
    "  },\n",
    "  \"useEarliestOffset\": \"false\"\n",
    "}\n",
    "\n",
    "tuningConfig = { \"type\": \"kafka\" }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ee01e6-d620-4ca7-9f2b-d49ab839ca5a",
   "metadata": {},
   "source": [
    "The third part of the ingestion specification defines the [dataSchema](https://druid.apache.org/docs/latest/ingestion/ingestion-spec#dataschema). In the cells that follow, you will define all three parts:\n",
    "\n",
    "* A [timestampSpec](https://druid.apache.org/docs/latest/ingestion/ingestion-spec#timestampspec) which uses the `time` column from the generated data as the primary timestamp.\n",
    "* A [granularitySpec](https://druid.apache.org/docs/latest/ingestion/ingestion-spec#granularityspec) which uses the primary timestamp to write data into daily partitions.\n",
    "* A [dimensionsSpec](https://druid.apache.org/docs/latest/ingestion/ingestion-spec#dimensionsspec) which defines what data to create inside the target table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284bc813-dd75-49aa-bac2-10d1016fff46",
   "metadata": {},
   "source": [
    "### Set the timestamp and partitioning scheme\n",
    "\n",
    "Run the next cell to see a sample of the raw data being emitted from the Data Generator.\n",
    "\n",
    "This cell uses a simple consumer to subscribe to the topic and to show the first 5 rows that appear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7128c2a4-588b-4bf6-a0f9-2f002f0ecdbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:435: v=b'{\"time\":\"2024-06-27T08:49:31.204\",\"username\":\"willow\",\"post_title\":\"KLj.fQGv::O1Mieg7GEjjfWbWuBITuqs\\'G,3adPcVfdJFnl:FwX6GC!1p4qpCpcd9FD2T9hBNbtVLcxyVyfj_KGfzhmOQlfm5,IJsrfCc\\'ua,woNtt\",\"views\":659,\"upvotes\":64,\"comments\":10,\"edited\":\"True\"}'\n",
      "0:436: v=b'{\"time\":\"2024-06-27T08:49:31.205\",\"username\":\"gus\",\"post_title\":\"k,NL1Uj,WhdMLkthsBoYdqHvOv7G4wy5r64W3z9uxvCntc;SMthPsJadr9z\\'C_kuCJpgtODG\",\"views\":27479,\"upvotes\":79,\"comments\":18,\"edited\":\"True\"}'\n",
      "0:437: v=b'{\"time\":\"2024-06-27T08:49:31.205\",\"username\":\"gus\",\"post_title\":\"Jp1XyghfyiLxpC:yZjXrEhGCreZ0kVWf2uGG:CpYMgfVLOKVp;oOrE!dW,b!DU2fs\\'5plYxjZiqR2u1RS1W2cn_8\",\"views\":758,\"upvotes\":51,\"comments\":14,\"edited\":\"False\"}'\n",
      "0:438: v=b'{\"time\":\"2024-06-27T08:49:31.206\",\"username\":\"miette\",\"post_title\":\"Qpb8vzW6tcqddGP,acKDhS09J5yQZNeUL,\\'uQ6I!SOK;\\'nDKUcRVubYDH49sxJhNrK7elAju;Q3\\'uKkMFftH\\'rWRP1YNSNS!WZrrnT4sI.y_A!7O.EjYV\\'y7LLx\",\"views\":21242,\"upvotes\":53,\"comments\":-1,\"edited\":\"False\"}'\n"
     ]
    }
   ],
   "source": [
    "consumer = KafkaConsumer(\n",
    " bootstrap_servers=kafka_host\n",
    ")\n",
    "\n",
    "consumer.subscribe(topics=topic_name)\n",
    "count = 0\n",
    "\n",
    "for message in consumer:\n",
    "    count += 1\n",
    "    if count == 5:\n",
    "        break\n",
    "    print (\"%d:%d: v=%s\" % (message.partition,\n",
    "                            message.offset,\n",
    "                            message.value))\n",
    "\n",
    "consumer.unsubscribe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6693b19-be98-4a8b-b3a5-737823175f1d",
   "metadata": {},
   "source": [
    "Each event appears to include a timestamp in the `time` field in ISO standard format.\n",
    "\n",
    "Run the following cell to set the primary timestamp to this field with the [format](https://druid.apache.org/docs/latest/ingestion/ingestion-spec#timestampspec) set as \"iso\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49d6b53a-d1f8-4f9a-9f54-14ccdf423b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSchema_timestampSpec = {\n",
    "    \"column\": \"time\",\n",
    "    \"format\": \"iso\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecd2912-553f-466c-a3ee-f5b793aee22e",
   "metadata": {},
   "source": [
    "For the purposes of this notebook, set the primary partitioning for your table using the `granularitySpec` to `HOUR` by running the next cell.\n",
    "\n",
    "Read more about this important design consideration in the official documentation on [partitioning](https://druid.apache.org/docs/latest/ingestion/partitioning) and [segments size optimization](https://druid.apache.org/docs/latest/operations/segment-optimization).\n",
    "\n",
    "Notice that you also disable ingestion-time aggregation ([rollup](https://druid.apache.org/docs/latest/ingestion/rollup)), behaviour for which is also defined inside the `granularitySpec`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b804095a-1b9f-48dd-9c13-11c1c083e8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSchema_granularitySpec = {\n",
    "    \"rollup\": \"false\",\n",
    "    \"segmentGranularity\": \"hour\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b79aee4-9dcf-4963-ab06-9086bc0604ff",
   "metadata": {},
   "source": [
    "You have now created the first two parts of the `dataSchema` that deal with treatment and use of a primary timestamp.\n",
    "\n",
    "Reviewing the sample data, we can now turn our attention to the options for the final part of the `dataSchema`: the `dimensionsSpec`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02beae03-25e9-4ce0-a785-ccfb13ec36cb",
   "metadata": {},
   "source": [
    "## Explicitly set dimensions\n",
    "\n",
    "Run the next cell to create a `dimensionsSpec` object that uses the \"explicit\" method for ingesting events.\n",
    "\n",
    "Notice that it is made up of [dimension objects](https://druid.apache.org/docs/latest/ingestion/ingestion-spec#dimension-objects) inside a `dimensions` list - the \"edited\" field has been left out intentionally.\n",
    "\n",
    "There are two flavors of dimension object:\n",
    "\n",
    "* Dimensions that ingested using all defaults, bringing in data as a string with a bitmap index.\n",
    "* Dimensions that have specific types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1987c712-8670-4fbd-b3c6-d072efb439a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSchema_dimensionsSpec = {\n",
    "    \"dimensions\": [\n",
    "        \"username\",\n",
    "        \"post_title\",\n",
    "        {\n",
    "            \"name\" : \"views\",\n",
    "            \"type\" : \"long\" },\n",
    "        {\n",
    "            \"name\" : \"upvotes\",\n",
    "            \"type\" : \"long\" },\n",
    "        {\n",
    "            \"name\" : \"comments\",\n",
    "            \"type\" : \"long\" }\n",
    "        ]\n",
    "      }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e24a56-3d9e-4589-8d0c-113a5b5ec8e9",
   "metadata": {},
   "source": [
    "Run the next cell to create the final `dataSchema`. Notice that the table name is also defined here.\n",
    "\n",
    "Beneath this it is combined with the `ioConfig` and `tuningConfig` to create a native [ingestion specification](https://druid.apache.org/docs/latest/ingestion/ingestion-spec)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c69af4ad-00e2-4d9b-b7fc-5725dfe9e040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "     \"type\": \"kafka\",\n",
      "     \"spec\": {\n",
      "          \"ioConfig\": {\n",
      "               \"type\": \"kafka\",\n",
      "               \"consumerProperties\": {\n",
      "                    \"bootstrap.servers\": \"kafka:9092\"\n",
      "               },\n",
      "               \"topic\": \"example-social-dimensions\",\n",
      "               \"inputFormat\": {\n",
      "                    \"type\": \"json\"\n",
      "               },\n",
      "               \"useEarliestOffset\": \"false\"\n",
      "          },\n",
      "          \"tuningConfig\": {\n",
      "               \"type\": \"kafka\"\n",
      "          },\n",
      "          \"dataSchema\": {\n",
      "               \"dataSource\": \"example-social-dimensions\",\n",
      "               \"timestampSpec\": {\n",
      "                    \"column\": \"time\",\n",
      "                    \"format\": \"iso\"\n",
      "               },\n",
      "               \"dimensionsSpec\": {\n",
      "                    \"dimensions\": [\n",
      "                         \"username\",\n",
      "                         \"post_title\",\n",
      "                         {\n",
      "                              \"name\": \"views\",\n",
      "                              \"type\": \"long\"\n",
      "                         },\n",
      "                         {\n",
      "                              \"name\": \"upvotes\",\n",
      "                              \"type\": \"long\"\n",
      "                         },\n",
      "                         {\n",
      "                              \"name\": \"comments\",\n",
      "                              \"type\": \"long\"\n",
      "                         }\n",
      "                    ]\n",
      "               },\n",
      "               \"granularitySpec\": {\n",
      "                    \"rollup\": \"false\",\n",
      "                    \"segmentGranularity\": \"hour\"\n",
      "               }\n",
      "          }\n",
      "     }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "table_name = topic_name\n",
    "\n",
    "dataSchema = {\n",
    "      \"dataSource\": table_name,\n",
    "      \"timestampSpec\": dataSchema_timestampSpec,\n",
    "      \"dimensionsSpec\": dataSchema_dimensionsSpec,\n",
    "      \"granularitySpec\": dataSchema_granularitySpec\n",
    "    }\n",
    "\n",
    "ingestionSpec = {\n",
    "  \"type\": \"kafka\",\n",
    "  \"spec\": {\n",
    "    \"ioConfig\": ioConfig,\n",
    "    \"tuningConfig\": tuningConfig,\n",
    "    \"dataSchema\": dataSchema\n",
    "  }\n",
    "}\n",
    "\n",
    "print(json.dumps(ingestionSpec, indent=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe50d1bb-1bc9-4ef1-a1a7-637cc3bb4616",
   "metadata": {},
   "source": [
    "Start the ingestion of the raw data from Apache Kafka by submitting this object to Apache Druid by running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "92aa5125-1096-462a-a637-cd8f438a2074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "supervisor = requests.post(f\"{druid_host}/druid/indexer/v1/supervisor\", json.dumps(ingestionSpec), headers=generalHeaders)\n",
    "print(supervisor.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc897578-48d7-4b8c-9ece-dab4390e2336",
   "metadata": {},
   "source": [
    "Run the following cell to wait until the ingestion has started and the new table is ready for query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e830e767-ad9a-47c0-80e2-4f19cd4a20bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to go!\n"
     ]
    }
   ],
   "source": [
    "druid.sql.wait_until_ready(table_name, verify_load_status=False)\n",
    "print(\"Ready to go!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bb27ed-c812-402e-90da-9ffc1a163228",
   "metadata": {},
   "outputs": [],
   "source": [
    "Run the following cell to get detail about the table you have created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0e17dd96-cf4b-44ab-bed4-cfa43fd67f3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"druid\"><table>\n",
       "<tr><th>COLUMN_NAME</th><th>ORDINAL_POSITION</th><th>DATA_TYPE</th><th>NUMERIC_PRECISION</th><th>NUMERIC_PRECISION_RADIX</th><th>DATETIME_PRECISION</th><th>CHARACTER_SET_NAME</th><th>JDBC_TYPE</th></tr>\n",
       "<tr><td>__time</td><td>1</td><td>TIMESTAMP</td><td></td><td></td><td>3</td><td></td><td>93</td></tr>\n",
       "<tr><td>username</td><td>2</td><td>VARCHAR</td><td></td><td></td><td></td><td>UTF-16LE</td><td>12</td></tr>\n",
       "<tr><td>post_title</td><td>3</td><td>VARCHAR</td><td></td><td></td><td></td><td>UTF-16LE</td><td>12</td></tr>\n",
       "<tr><td>views</td><td>4</td><td>BIGINT</td><td>19</td><td>10</td><td></td><td></td><td>-5</td></tr>\n",
       "<tr><td>upvotes</td><td>5</td><td>BIGINT</td><td>19</td><td>10</td><td></td><td></td><td>-5</td></tr>\n",
       "<tr><td>comments</td><td>6</td><td>BIGINT</td><td>19</td><td>10</td><td></td><td></td><td>-5</td></tr>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sql=f'''\n",
    "SELECT\n",
    "  \"COLUMN_NAME\",\n",
    "  \"ORDINAL_POSITION\",\n",
    "  \"DATA_TYPE\",\n",
    "  \"NUMERIC_PRECISION\",\n",
    "  \"NUMERIC_PRECISION_RADIX\",\n",
    "  \"DATETIME_PRECISION\",\n",
    "  \"CHARACTER_SET_NAME\",\n",
    "  \"JDBC_TYPE\"\n",
    "FROM \"INFORMATION_SCHEMA\".\"COLUMNS\"\n",
    "WHERE \"TABLE_NAME\" = '{table_name}'\n",
    "'''\n",
    "\n",
    "display.sql(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2654936f-8288-4fd5-a4ad-1f94267e43ae",
   "metadata": {},
   "source": [
    "The type shown in the `DATA_TYPE` column tells you how Druid will interpret the data in SQL. Notice that the `dimensionsSpec` has caused Druid to apply a type of BIGINT to `views`, `upvotes`, and `comments`.\n",
    "\n",
    "> As shown in [documentation](https://druid.apache.org/docs/latest/querying/sql-data-types), these SQL types map to more fundamental types inside Druid itself. Take a moment to review the [documentation](https://druid.apache.org/docs/latest/querying/sql-data-types#standard-types) to understand how each `DATA_TYPE` in the `example-flights-types-1` TABLE maps to an internal Druid runtime type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca324d3-26c5-4033-a102-4f73a80401d1",
   "metadata": {},
   "source": [
    "### Explicitly exclude dimensions\n",
    "\n",
    "Run the next cell to create a `dimensionsSpec` object that uses the \"exclusion\" method for ingesting events.\n",
    "\n",
    "Notice that it is made up of the names of dimensions to exclude from the incoming data inside `dimensionExclusions` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c727467c-e6af-4879-80e1-c2cac368d6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSchema_dimensionsSpec = {\n",
    "    \"dimensionExclusions\": [\n",
    "        \"username\",\n",
    "        \"edited\"\n",
    "        ]\n",
    "      }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23d7546-8e58-473a-b482-37ed8176c88f",
   "metadata": {},
   "source": [
    "Now incorporate this adaptation into the overall ingestion specification by running the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "21542771-2f28-4ca3-8bb6-f051f66b5cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "     \"type\": \"kafka\",\n",
      "     \"spec\": {\n",
      "          \"ioConfig\": {\n",
      "               \"type\": \"kafka\",\n",
      "               \"consumerProperties\": {\n",
      "                    \"bootstrap.servers\": \"kafka:9092\"\n",
      "               },\n",
      "               \"topic\": \"example-social-dimensions\",\n",
      "               \"inputFormat\": {\n",
      "                    \"type\": \"json\"\n",
      "               },\n",
      "               \"useEarliestOffset\": \"false\"\n",
      "          },\n",
      "          \"tuningConfig\": {\n",
      "               \"type\": \"kafka\"\n",
      "          },\n",
      "          \"dataSchema\": {\n",
      "               \"dataSource\": \"example-social-dimensions\",\n",
      "               \"timestampSpec\": {\n",
      "                    \"column\": \"time\",\n",
      "                    \"format\": \"iso\"\n",
      "               },\n",
      "               \"dimensionsSpec\": {\n",
      "                    \"dimensionExclusions\": [\n",
      "                         \"username\",\n",
      "                         \"edited\"\n",
      "                    ]\n",
      "               },\n",
      "               \"granularitySpec\": {\n",
      "                    \"rollup\": \"false\",\n",
      "                    \"segmentGranularity\": \"hour\"\n",
      "               }\n",
      "          }\n",
      "     }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "dataSchema = {\n",
    "      \"dataSource\": table_name,\n",
    "      \"timestampSpec\": dataSchema_timestampSpec,\n",
    "      \"dimensionsSpec\": dataSchema_dimensionsSpec,\n",
    "      \"granularitySpec\": dataSchema_granularitySpec\n",
    "    }\n",
    "\n",
    "ingestionSpec = {\n",
    "  \"type\": \"kafka\",\n",
    "  \"spec\": {\n",
    "    \"ioConfig\": ioConfig,\n",
    "    \"tuningConfig\": tuningConfig,\n",
    "    \"dataSchema\": dataSchema\n",
    "  }\n",
    "}\n",
    "\n",
    "print(json.dumps(ingestionSpec, indent=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef19f727-67ed-4090-b83a-5fefb2d7bd89",
   "metadata": {},
   "source": [
    "Submit the revised specification for this table to Druid by running the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c877e620-0558-4e58-b799-5ddc5e5862af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "supervisor = requests.post(f\"{druid_host}/druid/indexer/v1/supervisor\", json.dumps(ingestionSpec), headers=generalHeaders)\n",
    "print(supervisor.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70eb3e45-e89c-4e62-9bd7-61d2c2d57013",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "69a97ba1-d576-425a-84ca-db01c974b940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This data is filtered at ingestion time:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"druid\"><table>\n",
       "<tr><th>__time</th><th>username</th><th>views</th><th>upvotes</th><th>comments</th></tr>\n",
       "<tr><td>2024-06-27T09:09:36.906Z</td><td></td><td>1389</td><td>68</td><td>4</td></tr>\n",
       "<tr><td>2024-06-27T09:09:36.905Z</td><td></td><td>7311</td><td>66</td><td>16</td></tr>\n",
       "<tr><td>2024-06-27T09:09:36.904Z</td><td></td><td>2278</td><td>69</td><td>6</td></tr>\n",
       "<tr><td>2024-06-27T09:09:36.904Z</td><td></td><td>1520</td><td>38</td><td>0</td></tr>\n",
       "<tr><td>2024-06-27T09:09:36.904Z</td><td></td><td>1622</td><td>56</td><td>5</td></tr>\n",
       "<tr><td>2024-06-27T09:09:36.903Z</td><td></td><td>11258</td><td>44</td><td>12</td></tr>\n",
       "<tr><td>2024-06-27T09:09:36.903Z</td><td></td><td>34264</td><td>62</td><td>4</td></tr>\n",
       "<tr><td>2024-06-27T09:09:36.903Z</td><td></td><td>955</td><td>78</td><td>9</td></tr>\n",
       "<tr><td>2024-06-27T09:09:36.903Z</td><td></td><td>849</td><td>80</td><td>11</td></tr>\n",
       "<tr><td>2024-06-27T09:09:36.900Z</td><td></td><td>1353</td><td>69</td><td>11</td></tr>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This data is unfiltered:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"druid\"><table>\n",
       "<tr><th>__time</th><th>username</th><th>views</th><th>upvotes</th><th>comments</th></tr>\n",
       "<tr><td>2024-06-27T09:09:36.906Z</td><td></td><td>1389</td><td>68</td><td>4</td></tr>\n",
       "<tr><td>2024-06-27T09:09:36.905Z</td><td></td><td>7311</td><td>66</td><td>16</td></tr>\n",
       "<tr><td>2024-06-27T09:09:36.904Z</td><td></td><td>2278</td><td>69</td><td>6</td></tr>\n",
       "<tr><td>2024-06-27T09:09:36.904Z</td><td></td><td>1520</td><td>38</td><td>0</td></tr>\n",
       "<tr><td>2024-06-27T09:09:36.904Z</td><td></td><td>1622</td><td>56</td><td>5</td></tr>\n",
       "<tr><td>2024-06-27T09:09:36.903Z</td><td></td><td>11258</td><td>44</td><td>12</td></tr>\n",
       "<tr><td>2024-06-27T09:09:36.903Z</td><td></td><td>34264</td><td>62</td><td>4</td></tr>\n",
       "<tr><td>2024-06-27T09:09:36.903Z</td><td></td><td>955</td><td>78</td><td>9</td></tr>\n",
       "<tr><td>2024-06-27T09:09:36.903Z</td><td></td><td>849</td><td>80</td><td>11</td></tr>\n",
       "<tr><td>2024-06-27T09:09:36.900Z</td><td></td><td>1353</td><td>69</td><td>11</td></tr>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "time_now = datetime.now().strftime('%Y-%m-%dT%H:%M:%S')\n",
    "\n",
    "sql=f'''\n",
    "SELECT __time, username, views, upvotes, comments\n",
    "FROM \"{table_name}\"\n",
    "WHERE TIME_IN_INTERVAL(__time,'PT1S/''' + time_now + '''')\n",
    "ORDER BY __time DESC\n",
    "'''\n",
    "\n",
    "print(\"This data is filtered at ingestion time:\")\n",
    "display.sql(sql)\n",
    "\n",
    "sql=f'''\n",
    "SELECT __time, username, views, upvotes, comments\n",
    "FROM \"{table_name}\"\n",
    "WHERE TIME_IN_INTERVAL(__time,'PT1S/''' + time_now + '''')\n",
    "ORDER BY __time DESC\n",
    "'''\n",
    "\n",
    "print(\"This data is unfiltered:\")\n",
    "display.sql(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e30eec5-6a8c-41b4-8d21-4108de48edbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "472589e4-1026-4b3b-bb79-eedabb2b44c4",
   "metadata": {},
   "source": [
    "## Filter data using an equality filter\n",
    "\n",
    "In this section you will use a [equality filter](https://druid.apache.org/docs/latest/querying/filters#equality-filter) to create a table that only contains records for where someone searches for a product.\n",
    "\n",
    "Run the following cell to get a preview of the data that we want to have in our new table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32bed8e-bc49-4ba8-85d2-8a9bfa9232f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql=f'''\n",
    "SELECT\n",
    "  \"__time\",\n",
    "  \"event_type\",\n",
    "  \"client_ip\",\n",
    "  \"client_device\",\n",
    "  \"client_lang\",\n",
    "  \"client_country\"\n",
    "FROM \"{table_name}\"\n",
    "WHERE \"event_type\" = 'search'\n",
    "LIMIT 10\n",
    "'''\n",
    "\n",
    "print(sql)\n",
    "\n",
    "display.sql(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c81b63-777b-414f-81a9-2b9ccee214e5",
   "metadata": {},
   "source": [
    "Run the next cell to create a new object that represents the [`transformSpec`](https://druid.apache.org/docs/latest/ingestion/ingestion-spec#transformspec). This will be added to the dataSchema in the ingestion specification, instructing Druid to apply a filter to the incoming data as it arrives.\n",
    "\n",
    "Here, only one [filter](https://druid.apache.org/docs/latest/ingestion/ingestion-spec#filter) will be applied to the data as it arrives.\n",
    "\n",
    "* The `type` of `selector` looks for an exact match.\n",
    "* The check will be against the `dimension` of `event_type`, looking for a `value` of \"search\".\n",
    "\n",
    "Only rows that pass this test will be added to the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f562b1f3-4265-4553-aabe-7e7d30b21ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSchema_transformSpec = {\n",
    "    \"filter\":\n",
    "    {\n",
    "              \"type\": \"selector\",\n",
    "              \"dimension\": \"event_type\",\n",
    "              \"value\": \"search\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b37edb9-d891-4c1a-8223-fcfd7d5e3d16",
   "metadata": {},
   "source": [
    "Now run the following cell to build a new ingestion specification:\n",
    "\n",
    "* A new table will be created, as set in `table_searches` and then used in the `dataSource` name in the `dataSchema`.\n",
    "* The `dataSchema` is updated using the new table name, `timestampSpec` and `granularitySpec` and the updated `dimensionsSpec`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a6503f-d0d3-41ae-a0d5-b55d6e05e78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_searches = topic_name + \"-search\"\n",
    "\n",
    "dataSchema = {\n",
    "    \"dataSource\": table_searches,\n",
    "    \"timestampSpec\": dataSchema_timestampSpec,\n",
    "    \"transformSpec\" : dataSchema_transformSpec,\n",
    "    \"dimensionsSpec\": dataSchema_dimensionsSpec,\n",
    "    \"granularitySpec\": dataSchema_granularitySpec\n",
    "    }\n",
    "\n",
    "ingestionSpec = {\n",
    "  \"type\": \"kafka\",\n",
    "  \"spec\": {\n",
    "    \"ioConfig\": ioConfig,\n",
    "    \"tuningConfig\": tuningConfig,\n",
    "    \"dataSchema\": dataSchema\n",
    "  }\n",
    "}\n",
    "\n",
    "print(json.dumps(ingestionSpec, indent=5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e776f9b9-527f-4a17-bc6a-4c6b34f7353e",
   "metadata": {},
   "source": [
    "Review the output above and you will see where the `transforms` have been added inside the `dataSchema`.\n",
    "\n",
    "Submit the new specification for ingestions from this Apache Kafka topic by running the cell below. As well as submitting the new ingestion task, it will print \"ready to go\" when the table is ready for querying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c488ec1-e107-4fa1-8cb5-711150069a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "supervisor = requests.post(f\"{druid_host}/druid/indexer/v1/supervisor\", json.dumps(ingestionSpec), headers=generalHeaders)\n",
    "print(supervisor.status_code)\n",
    "\n",
    "druid.sql.wait_until_ready(table_searches, verify_load_status=False)\n",
    "print(\"Ready to go!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4124ea80-4faa-4d16-82a8-d509e3733fa1",
   "metadata": {},
   "source": [
    "Run the query below to see the effect this has had on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "740c1228-70ed-47d8-bf24-35f6d7323f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-27T09:08:58\n",
      "This data is filtered at ingestion time:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"druid\"><table>\n",
       "<tr><th>__time</th><th>username</th><th>views</th><th>upvotes</th><th>comments</th></tr>\n",
       "<tr><td>2024-06-27T09:08:57.534Z</td><td></td><td>25487</td><td>71</td><td>6</td></tr>\n",
       "<tr><td>2024-06-27T09:08:57.533Z</td><td></td><td>5500</td><td>44</td><td>4</td></tr>\n",
       "<tr><td>2024-06-27T09:08:57.533Z</td><td></td><td>2837</td><td>82</td><td>7</td></tr>\n",
       "<tr><td>2024-06-27T09:08:57.532Z</td><td></td><td>4926</td><td>53</td><td>5</td></tr>\n",
       "<tr><td>2024-06-27T09:08:57.532Z</td><td></td><td>2351</td><td>55</td><td>14</td></tr>\n",
       "<tr><td>2024-06-27T09:08:57.531Z</td><td></td><td>6086</td><td>70</td><td>7</td></tr>\n",
       "<tr><td>2024-06-27T09:08:57.530Z</td><td></td><td>8124</td><td>75</td><td>9</td></tr>\n",
       "<tr><td>2024-06-27T09:08:57.529Z</td><td></td><td>513</td><td>78</td><td>14</td></tr>\n",
       "<tr><td>2024-06-27T09:08:57.529Z</td><td></td><td>5850</td><td>100</td><td>11</td></tr>\n",
       "<tr><td>2024-06-27T09:08:57.528Z</td><td></td><td>2879</td><td>66</td><td>9</td></tr>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This data is unfiltered:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"druid\"><table>\n",
       "<tr><th>__time</th><th>username</th><th>views</th><th>upvotes</th><th>comments</th></tr>\n",
       "<tr><td>2024-06-27T09:08:57.534Z</td><td></td><td>25487</td><td>71</td><td>6</td></tr>\n",
       "<tr><td>2024-06-27T09:08:57.533Z</td><td></td><td>5500</td><td>44</td><td>4</td></tr>\n",
       "<tr><td>2024-06-27T09:08:57.533Z</td><td></td><td>2837</td><td>82</td><td>7</td></tr>\n",
       "<tr><td>2024-06-27T09:08:57.532Z</td><td></td><td>4926</td><td>53</td><td>5</td></tr>\n",
       "<tr><td>2024-06-27T09:08:57.532Z</td><td></td><td>2351</td><td>55</td><td>14</td></tr>\n",
       "<tr><td>2024-06-27T09:08:57.531Z</td><td></td><td>6086</td><td>70</td><td>7</td></tr>\n",
       "<tr><td>2024-06-27T09:08:57.530Z</td><td></td><td>8124</td><td>75</td><td>9</td></tr>\n",
       "<tr><td>2024-06-27T09:08:57.529Z</td><td></td><td>513</td><td>78</td><td>14</td></tr>\n",
       "<tr><td>2024-06-27T09:08:57.529Z</td><td></td><td>5850</td><td>100</td><td>11</td></tr>\n",
       "<tr><td>2024-06-27T09:08:57.528Z</td><td></td><td>2879</td><td>66</td><td>9</td></tr>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "time_now = datetime.now().strftime('%Y-%m-%dT%H:%M:%S')\n",
    "\n",
    "sql=f'''\n",
    "SELECT __time, username, views, upvotes, comments\n",
    "FROM \"{table_name}\"\n",
    "WHERE TIME_IN_INTERVAL(__time,'PT1S/''' + time_now + '''')\n",
    "ORDER BY __time DESC\n",
    "'''\n",
    "\n",
    "print(\"This data is filtered at ingestion time:\")\n",
    "display.sql(sql)\n",
    "\n",
    "sql=f'''\n",
    "SELECT __time, username, views, upvotes, comments\n",
    "FROM \"{table_name}\"\n",
    "WHERE TIME_IN_INTERVAL(__time,'PT1S/''' + time_now + '''')\n",
    "ORDER BY __time DESC\n",
    "'''\n",
    "\n",
    "print(\"This data is unfiltered:\")\n",
    "display.sql(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c09a052-180d-4cb4-80a7-32b746642ee7",
   "metadata": {},
   "source": [
    "## Filter data using an in filter\n",
    "\n",
    "In this section you will use a [in filter](https://druid.apache.org/docs/latest/querying/filters#equality-filter) to create a table that only contains actions where someone adds or drops an item from their cart.\n",
    "\n",
    "Run the following cell which executes SQL to give a preview of the data destined for the new table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52a94fb-d2e4-403f-ab10-84d3af7bf2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql=f'''\n",
    "SELECT\n",
    "  \"__time\",\n",
    "  \"event_type\"\n",
    "FROM \"{table_name}\"\n",
    "WHERE \"event_type\" IN ('add_to_cart', 'drop_from_cart')\n",
    "LIMIT 10\n",
    "'''\n",
    "\n",
    "display.sql(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab94579c-b84e-43ae-89af-e1e0fb2d7da3",
   "metadata": {},
   "source": [
    "Use an \"explain\" against a Druid SQL statement to view the native representation of the query. From here, you are able to pinpoint the specific filter that has been applied. You can use the Druid console to \"explain\" an SQL statement in the query tab.\n",
    "\n",
    "Run the following cell to use the druid API to explain the SQL query above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367aabe5-9b37-4dd2-a5c1-960ba849b164",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(json.loads(sql_client.explain_sql(sql)['PLAN']), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00032a2e-1d73-4dbd-88ff-697db342ecdc",
   "metadata": {},
   "source": [
    "Leveraging the `filter` section above, run the next cell to create a new [`transformSpec`](https://druid.apache.org/docs/latest/ingestion/ingestion-spec#transformspec) that contains this filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7094b74f-4e1d-43af-8c77-74d3bca82630",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSchema_transformSpec = {\n",
    "    \"filter\": {\n",
    "        \"type\": \"in\",\n",
    "        \"dimension\": \"event_type\",\n",
    "        \"values\": [\n",
    "          \"add_to_cart\",\n",
    "          \"drop_from_cart\"\n",
    "        ]\n",
    "      }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d3921d-d771-46f3-a295-38bf7beb74d1",
   "metadata": {},
   "source": [
    "Run this cell to build an `ingestionSpec` object, this time including the `transformSpec` above. It will also resurrect the `event_type` column to enable add and drop actions to be differentiated in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1d911e-ecf2-4461-9c24-84168b0f7860",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_cart = topic_name + \"-cart\"\n",
    "\n",
    "dataSchema_dimensionsSpec = {\n",
    "        \"dimensions\": [\n",
    "          \"user_id\",\n",
    "          \"event_type\",\n",
    "          \"client_ip\",\n",
    "          \"client_device\",\n",
    "          \"client_lang\",\n",
    "          \"client_country\",\n",
    "          \"referrer\",\n",
    "          \"keyword\",\n",
    "          \"product\"\n",
    "        ]\n",
    "      }\n",
    "\n",
    "dataSchema = {\n",
    "    \"dataSource\": table_cart,\n",
    "    \"timestampSpec\": dataSchema_timestampSpec,\n",
    "    \"transformSpec\" : dataSchema_transformSpec,\n",
    "    \"dimensionsSpec\": dataSchema_dimensionsSpec,\n",
    "    \"granularitySpec\": dataSchema_granularitySpec\n",
    "    }\n",
    "\n",
    "ingestionSpec = {\n",
    "  \"type\": \"kafka\",\n",
    "  \"spec\": {\n",
    "    \"ioConfig\": ioConfig,\n",
    "    \"tuningConfig\": tuningConfig,\n",
    "    \"dataSchema\": dataSchema\n",
    "  }\n",
    "}\n",
    "\n",
    "print(json.dumps(ingestionSpec, indent=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf892a9-b180-4db0-9e15-ca8f1f6c436e",
   "metadata": {},
   "source": [
    "Submit the new specification for ingestions from this Apache Kafka topic by running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c93431-4418-4bfd-b970-b0354e728849",
   "metadata": {},
   "outputs": [],
   "source": [
    "supervisor = requests.post(f\"{druid_host}/druid/indexer/v1/supervisor\", json.dumps(ingestionSpec), headers=generalHeaders)\n",
    "print(supervisor.status_code)\n",
    "\n",
    "druid.sql.wait_until_ready(table_cart, verify_load_status=False)\n",
    "print(\"Ready to go!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780708a3-da27-4195-a450-f53007a4f289",
   "metadata": {},
   "source": [
    "Run the query below to see the effect this has had on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6cf5ab-cba3-43d4-a43d-9b095311d05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_now = datetime.now().strftime('%Y-%m-%dT%H:%M:%S')\n",
    "print(time_now)\n",
    "\n",
    "sql=f'''\n",
    "SELECT\n",
    "  \"__time\",\n",
    "  \"event_type\",\n",
    "  \"client_ip\",\n",
    "  \"client_device\",\n",
    "  \"client_lang\",\n",
    "  \"client_country\"\n",
    "FROM \"{table_cart}\"\n",
    "WHERE TIME_IN_INTERVAL(__time,'PT1M/''' + time_now + '''')\n",
    "ORDER BY __time DESC\n",
    "'''\n",
    "\n",
    "print(\"This data is filtered at ingestion time:\")\n",
    "display.sql(sql)\n",
    "\n",
    "sql=f'''\n",
    "SELECT\n",
    "  \"__time\",\n",
    "  \"event_type\",\n",
    "  \"client_ip\",\n",
    "  \"client_device\",\n",
    "  \"client_lang\",\n",
    "  \"client_country\"\n",
    "FROM \"{table_name}\"\n",
    "WHERE TIME_IN_INTERVAL(__time,'PT1M/''' + time_now + '''')\n",
    "ORDER BY __time DESC\n",
    "'''\n",
    "\n",
    "print(\"This data is unfiltered:\")\n",
    "display.sql(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5ceca5-cecc-4710-8092-9aa0f41488af",
   "metadata": {},
   "source": [
    "Notice above that \"view_cart\" is not being ingested into the table.\n",
    "\n",
    "Run the following cell to switch from an \"in\" type filter to a \"[like](https://druid.apache.org/docs/29.0.1/querying/filters/#like-filter)\" filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91c0fda-6905-474d-9549-10b6672f533e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSchema_transformSpec = {\n",
    "    \"filter\": {\n",
    "        \"type\": \"like\",\n",
    "        \"dimension\": \"event_type\",\n",
    "        \"pattern\" : \"%cart%\"\n",
    "      }\n",
    "}\n",
    "\n",
    "dataSchema = {\n",
    "    \"dataSource\": table_cart,\n",
    "    \"timestampSpec\": dataSchema_timestampSpec,\n",
    "    \"transformSpec\" : dataSchema_transformSpec,\n",
    "    \"dimensionsSpec\": dataSchema_dimensionsSpec,\n",
    "    \"granularitySpec\": dataSchema_granularitySpec\n",
    "    }\n",
    "\n",
    "ingestionSpec = {\n",
    "  \"type\": \"kafka\",\n",
    "  \"spec\": {\n",
    "    \"ioConfig\": ioConfig,\n",
    "    \"tuningConfig\": tuningConfig,\n",
    "    \"dataSchema\": dataSchema\n",
    "  }\n",
    "}\n",
    "\n",
    "supervisor = requests.post(f\"{druid_host}/druid/indexer/v1/supervisor\", json.dumps(ingestionSpec), headers=generalHeaders)\n",
    "print(supervisor.status_code)\n",
    "\n",
    "druid.sql.wait_until_ready(table_cart, verify_load_status=False)\n",
    "print(\"Ready to go!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83b8ac5-59fd-43c1-8547-03c98a8ae5d1",
   "metadata": {},
   "source": [
    "Wait for a few moments for the old tasks to terminate, and for new tasks to start using this new configuration.\n",
    "\n",
    "When done, run the next cell to see the effect.\n",
    "\n",
    "Notice that, in the method used in this example, \"view cart\" actions are only included from this point forward in the stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005c82bc-0f18-444e-979c-a794f2d69c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_now = datetime.now().strftime('%Y-%m-%dT%H:%M:%S')\n",
    "print(time_now)\n",
    "\n",
    "sql=f'''\n",
    "SELECT\n",
    "  \"__time\",\n",
    "  \"event_type\",\n",
    "  \"client_ip\",\n",
    "  \"client_device\",\n",
    "  \"client_lang\",\n",
    "  \"client_country\"\n",
    "FROM \"{table_cart}\"\n",
    "WHERE TIME_IN_INTERVAL(__time,'PT1M/''' + time_now + '''')\n",
    "ORDER BY __time DESC\n",
    "'''\n",
    "\n",
    "print(\"This data is filtered at ingestion time:\")\n",
    "display.sql(sql)\n",
    "\n",
    "sql=f'''\n",
    "SELECT\n",
    "  \"__time\",\n",
    "  \"event_type\",\n",
    "  \"client_ip\",\n",
    "  \"client_device\",\n",
    "  \"client_lang\",\n",
    "  \"client_country\"\n",
    "FROM \"{table_name}\"\n",
    "WHERE TIME_IN_INTERVAL(__time,'PT1M/''' + time_now + '''')\n",
    "ORDER BY __time DESC\n",
    "'''\n",
    "\n",
    "print(\"This data is unfiltered:\")\n",
    "display.sql(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44738d6d-cec2-40ad-aaba-998c758c63f4",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "\n",
    "Run the following cell to stop the data generator, stop ingestion from the topic, and to remove the table used in this notebook from the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8082b545-ba7f-4ede-bb6e-2a6dd62ba0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop streaming generator: [<Response [404]>]\n",
      "Pause streaming ingestion: [<Response [404]>]\n",
      "Shutting down running tasks ...\n",
      "Reset offsets for re-runnability: [<Response [404]>]\n",
      "Terminate streaming ingestion: [<Response [404]>]\n",
      "Drop datasource: [None]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'table_searches' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTerminate streaming ingestion: [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrequests\u001b[38;5;241m.\u001b[39mpost(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdruid_host\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/druid/indexer/v1/supervisor/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtable_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/terminate\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDrop datasource: [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdruid\u001b[38;5;241m.\u001b[39mdatasources\u001b[38;5;241m.\u001b[39mdrop(table_name)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m tasks \u001b[38;5;241m=\u001b[39m druid\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mtasks(state\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrunning\u001b[39m\u001b[38;5;124m'\u001b[39m, table\u001b[38;5;241m=\u001b[39m\u001b[43mtable_searches\u001b[49m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tasks)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m tasks:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'table_searches' is not defined"
     ]
    }
   ],
   "source": [
    "print(f\"Stop streaming generator: [{requests.post(f'{druid_host}/stop/{topic_name}','')}]\")\n",
    "print(f'Pause streaming ingestion: [{requests.post(f\"{druid_host}/druid/indexer/v1/supervisor/{topic_name}/suspend\",\"\")}]')\n",
    "\n",
    "print(f'Shutting down running tasks ...')\n",
    "\n",
    "tasks = druid.tasks.tasks(state='running', table=table_name)\n",
    "while len(tasks)>0:\n",
    "    for task in tasks:\n",
    "        print(f\"...stopping task [{task['id']}]\")\n",
    "        druid.tasks.shut_down_task(task['id'])\n",
    "    tasks = druid.tasks.tasks(state='running', table=table_name)\n",
    "        \n",
    "print(f'Reset offsets for re-runnability: [{requests.post(f\"{druid_host}/druid/indexer/v1/supervisor/{table_name}/reset\",\"\")}]')\n",
    "print(f'Terminate streaming ingestion: [{requests.post(f\"{druid_host}/druid/indexer/v1/supervisor/{table_name}/terminate\",\"\")}]')\n",
    "print(f\"Drop datasource: [{druid.datasources.drop(table_name)}]\")\n",
    "\n",
    "tasks = druid.tasks.tasks(state='running', table=table_searches)\n",
    "while len(tasks)>0:\n",
    "    for task in tasks:\n",
    "        print(f\"...stopping task [{task['id']}]\")\n",
    "        druid.tasks.shut_down_task(task['id'])\n",
    "    tasks = druid.tasks.tasks(state='running', table=table_searches)\n",
    "        \n",
    "print(f'Reset offsets for re-runnability: [{requests.post(f\"{druid_host}/druid/indexer/v1/supervisor/{table_searches}/reset\",\"\")}]')\n",
    "print(f'Terminate streaming ingestion: [{requests.post(f\"{druid_host}/druid/indexer/v1/supervisor/{table_searches}/terminate\",\"\")}]')\n",
    "print(f\"Drop datasource: [{druid.datasources.drop(table_searches)}]\")\n",
    "\n",
    "tasks = druid.tasks.tasks(state='running', table=table_cart)\n",
    "while len(tasks)>0:\n",
    "    for task in tasks:\n",
    "        print(f\"...stopping task [{task['id']}]\")\n",
    "        druid.tasks.shut_down_task(task['id'])\n",
    "    tasks = druid.tasks.tasks(state='running', table=table_cart)\n",
    "\n",
    "print(f'Reset offsets for re-runnability: [{requests.post(f\"{druid_host}/druid/indexer/v1/supervisor/{table_cart}/reset\",\"\")}]')\n",
    "print(f'Terminate streaming ingestion: [{requests.post(f\"{druid_host}/druid/indexer/v1/supervisor/{table_cart}/terminate\",\"\")}]')\n",
    "print(f\"Drop datasource: [{druid.datasources.drop(table_cart)}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b8d5fe-ba85-4b5b-9669-0dd47dfbccd1",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "* Filters can be applied to data from Apache Kafka as soon as it arrives.\n",
    "* Typical SQL WHERE filtering has native counterparts that you can use as a filter in the `transformSpec`.\n",
    "* Unless the topic offset is reset manually, expressions only apply to new data as it arrives.\n",
    "\n",
    "## Learn more\n",
    "\n",
    "* Try using [logical expression filters](https://druid.apache.org/docs/latest/querying/filters#logical-expression-filters) to add AND and OR conditions in your filters.\n",
    "* Read about more advanced filters, such as [regular expression](https://druid.apache.org/docs/latest/querying/filters#regular-expression-filter) and [expression](https://druid.apache.org/docs/latest/querying/filters#expression-filter) filters.\n",
    "* Check out the notebook on transforming data at ingestion time using [expressions](13-native-transforms.ipynb) and then combine what you've learned here with an [extraction filter](https://druid.apache.org/docs/latest/querying/filters#extraction-filter).\n",
    "* Re-run this notebook, but manually hard reset the supervisor between posting a new ingestion specification. You can do this either with a [POST](https://druid.apache.org/docs/latest/api-reference/supervisor-api#reset-a-supervisor) or [through the console](https://druid.apache.org/docs/latest/operations/web-console#supervisors). What do you expect to happen?\n",
    "* Refer to the documentation on [native transform expressions](https://druid.apache.org/docs/latest/querying/math-expr)."
   ]
  }
 ],
 "metadata": {
  "execution": {
   "allow_errors": true,
   "timeout": 300
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
